2026-01-11 15:14:15 | INFO | Starting training
2026-01-11 15:14:15 | INFO | Device: cpu
2026-01-11 15:14:18 | INFO | Train batches: 1169, Val batches: 174
2026-01-11 15:14:18 | INFO | Model parameters: 106,369
2026-01-11 15:14:21 | INFO | Epoch 1 | Batch 0/1169 | Loss: 0.0765
2026-01-11 15:14:23 | INFO | Epoch 1 | Batch 100/1169 | Loss: 0.0437
2026-01-11 15:14:26 | INFO | Epoch 1 | Batch 200/1169 | Loss: 0.0441
2026-01-11 15:14:28 | INFO | Epoch 1 | Batch 300/1169 | Loss: 0.0430
2026-01-11 15:14:30 | INFO | Epoch 1 | Batch 400/1169 | Loss: 0.0439
2026-01-11 15:14:33 | INFO | Epoch 1 | Batch 500/1169 | Loss: 0.0391
2026-01-11 15:14:35 | INFO | Epoch 1 | Batch 600/1169 | Loss: 0.0395
2026-01-11 15:14:37 | INFO | Epoch 1 | Batch 700/1169 | Loss: 0.0419
2026-01-11 15:14:40 | INFO | Epoch 1 | Batch 800/1169 | Loss: 0.0401
2026-01-11 15:14:42 | INFO | Epoch 1 | Batch 900/1169 | Loss: 0.0361
2026-01-11 15:14:44 | INFO | Epoch 1 | Batch 1000/1169 | Loss: 0.0342
2026-01-11 15:14:47 | INFO | Epoch 1 | Batch 1100/1169 | Loss: 0.0406
2026-01-11 15:14:50 | INFO | Epoch 1 | Train Loss: 0.0433 | Val Loss: 0.0284
2026-01-11 15:14:50 | INFO | Val F1: 0.2257 | Precision: 0.1311 | Recall: 0.8126
2026-01-11 15:14:50 | INFO | New best model saved (F1: 0.2257)
2026-01-11 15:14:51 | INFO | Epoch 2 | Batch 0/1169 | Loss: 0.0375
2026-01-11 15:14:53 | INFO | Epoch 2 | Batch 100/1169 | Loss: 0.0340
2026-01-11 15:14:56 | INFO | Epoch 2 | Batch 200/1169 | Loss: 0.0377
2026-01-11 15:14:58 | INFO | Epoch 2 | Batch 300/1169 | Loss: 0.0360
2026-01-11 15:15:01 | INFO | Epoch 2 | Batch 400/1169 | Loss: 0.0309
2026-01-11 15:15:03 | INFO | Epoch 2 | Batch 500/1169 | Loss: 0.0307
2026-01-11 15:15:05 | INFO | Epoch 2 | Batch 600/1169 | Loss: 0.0381
2026-01-11 15:15:08 | INFO | Epoch 2 | Batch 700/1169 | Loss: 0.0348
2026-01-11 15:15:10 | INFO | Epoch 2 | Batch 800/1169 | Loss: 0.0329
2026-01-11 15:15:12 | INFO | Epoch 2 | Batch 900/1169 | Loss: 0.0357
2026-01-11 15:15:14 | INFO | Epoch 2 | Batch 1000/1169 | Loss: 0.0296
2026-01-11 15:15:17 | INFO | Epoch 2 | Batch 1100/1169 | Loss: 0.0295
2026-01-11 15:15:20 | INFO | Epoch 2 | Train Loss: 0.0353 | Val Loss: 0.0245
2026-01-11 15:15:20 | INFO | Val F1: 0.2523 | Precision: 0.1493 | Recall: 0.8119
2026-01-11 15:15:20 | INFO | New best model saved (F1: 0.2523)
2026-01-11 15:15:21 | INFO | Epoch 3 | Batch 0/1169 | Loss: 0.0307
2026-01-11 15:15:23 | INFO | Epoch 3 | Batch 100/1169 | Loss: 0.0372
2026-01-11 15:15:25 | INFO | Epoch 3 | Batch 200/1169 | Loss: 0.0281
2026-01-11 15:15:28 | INFO | Epoch 3 | Batch 300/1169 | Loss: 0.0338
2026-01-11 15:15:30 | INFO | Epoch 3 | Batch 400/1169 | Loss: 0.0277
2026-01-11 15:15:32 | INFO | Epoch 3 | Batch 500/1169 | Loss: 0.0340
2026-01-11 15:15:35 | INFO | Epoch 3 | Batch 600/1169 | Loss: 0.0343
2026-01-11 15:15:37 | INFO | Epoch 3 | Batch 700/1169 | Loss: 0.0313
2026-01-11 15:15:40 | INFO | Epoch 3 | Batch 800/1169 | Loss: 0.0319
2026-01-11 15:15:42 | INFO | Epoch 3 | Batch 900/1169 | Loss: 0.0302
2026-01-11 15:15:45 | INFO | Epoch 3 | Batch 1000/1169 | Loss: 0.0265
2026-01-11 15:15:47 | INFO | Epoch 3 | Batch 1100/1169 | Loss: 0.0289
2026-01-11 15:15:51 | INFO | Epoch 3 | Train Loss: 0.0317 | Val Loss: 0.0239
2026-01-11 15:15:51 | INFO | Val F1: 0.2607 | Precision: 0.1555 | Recall: 0.8045
2026-01-11 15:15:51 | INFO | New best model saved (F1: 0.2607)
2026-01-11 15:15:51 | INFO | Epoch 4 | Batch 0/1169 | Loss: 0.0287
2026-01-11 15:15:53 | INFO | Epoch 4 | Batch 100/1169 | Loss: 0.0298
2026-01-11 15:15:56 | INFO | Epoch 4 | Batch 200/1169 | Loss: 0.0281
2026-01-11 15:15:58 | INFO | Epoch 4 | Batch 300/1169 | Loss: 0.0295
2026-01-11 15:16:00 | INFO | Epoch 4 | Batch 400/1169 | Loss: 0.0257
2026-01-11 15:16:03 | INFO | Epoch 4 | Batch 500/1169 | Loss: 0.0309
2026-01-11 15:16:05 | INFO | Epoch 4 | Batch 600/1169 | Loss: 0.0282
2026-01-11 15:16:07 | INFO | Epoch 4 | Batch 700/1169 | Loss: 0.0322
2026-01-11 15:16:10 | INFO | Epoch 4 | Batch 800/1169 | Loss: 0.0329
2026-01-11 15:16:12 | INFO | Epoch 4 | Batch 900/1169 | Loss: 0.0285
2026-01-11 15:16:14 | INFO | Epoch 4 | Batch 1000/1169 | Loss: 0.0279
2026-01-11 15:16:17 | INFO | Epoch 4 | Batch 1100/1169 | Loss: 0.0283
2026-01-11 15:16:20 | INFO | Epoch 4 | Train Loss: 0.0295 | Val Loss: 0.0227
2026-01-11 15:16:20 | INFO | Val F1: 0.2683 | Precision: 0.1610 | Recall: 0.8052
2026-01-11 15:16:20 | INFO | New best model saved (F1: 0.2683)
2026-01-11 15:16:21 | INFO | Epoch 5 | Batch 0/1169 | Loss: 0.0278
2026-01-11 15:16:23 | INFO | Epoch 5 | Batch 100/1169 | Loss: 0.0275
2026-01-11 15:16:25 | INFO | Epoch 5 | Batch 200/1169 | Loss: 0.0275
2026-01-11 15:16:28 | INFO | Epoch 5 | Batch 300/1169 | Loss: 0.0278
2026-01-11 15:16:30 | INFO | Epoch 5 | Batch 400/1169 | Loss: 0.0320
2026-01-11 15:16:33 | INFO | Epoch 5 | Batch 500/1169 | Loss: 0.0270
2026-01-11 15:16:35 | INFO | Epoch 5 | Batch 600/1169 | Loss: 0.0283
2026-01-11 15:16:37 | INFO | Epoch 5 | Batch 700/1169 | Loss: 0.0268
2026-01-11 15:16:40 | INFO | Epoch 5 | Batch 800/1169 | Loss: 0.0284
2026-01-11 15:16:42 | INFO | Epoch 5 | Batch 900/1169 | Loss: 0.0261
2026-01-11 15:16:44 | INFO | Epoch 5 | Batch 1000/1169 | Loss: 0.0269
2026-01-11 15:16:47 | INFO | Epoch 5 | Batch 1100/1169 | Loss: 0.0326
2026-01-11 15:16:50 | INFO | Epoch 5 | Train Loss: 0.0276 | Val Loss: 0.0210
2026-01-11 15:16:50 | INFO | Val F1: 0.2958 | Precision: 0.1825 | Recall: 0.7803
2026-01-11 15:16:50 | INFO | New best model saved (F1: 0.2958)
2026-01-11 15:16:51 | INFO | Epoch 6 | Batch 0/1169 | Loss: 0.0272
2026-01-11 15:16:53 | INFO | Epoch 6 | Batch 100/1169 | Loss: 0.0295
2026-01-11 15:16:55 | INFO | Epoch 6 | Batch 200/1169 | Loss: 0.0256
2026-01-11 15:16:58 | INFO | Epoch 6 | Batch 300/1169 | Loss: 0.0290
2026-01-11 15:17:00 | INFO | Epoch 6 | Batch 400/1169 | Loss: 0.0282
2026-01-11 15:17:02 | INFO | Epoch 6 | Batch 500/1169 | Loss: 0.0280
2026-01-11 15:17:05 | INFO | Epoch 6 | Batch 600/1169 | Loss: 0.0245
2026-01-11 15:17:07 | INFO | Epoch 6 | Batch 700/1169 | Loss: 0.0268
2026-01-11 15:17:09 | INFO | Epoch 6 | Batch 800/1169 | Loss: 0.0230
2026-01-11 15:17:12 | INFO | Epoch 6 | Batch 900/1169 | Loss: 0.0280
2026-01-11 15:17:14 | INFO | Epoch 6 | Batch 1000/1169 | Loss: 0.0241
2026-01-11 15:17:16 | INFO | Epoch 6 | Batch 1100/1169 | Loss: 0.0251
2026-01-11 15:17:20 | INFO | Epoch 6 | Train Loss: 0.0262 | Val Loss: 0.0187
2026-01-11 15:17:20 | INFO | Val F1: 0.3308 | Precision: 0.2120 | Recall: 0.7529
2026-01-11 15:17:20 | INFO | New best model saved (F1: 0.3308)
2026-01-11 15:17:20 | INFO | Epoch 7 | Batch 0/1169 | Loss: 0.0243
2026-01-11 15:17:23 | INFO | Epoch 7 | Batch 100/1169 | Loss: 0.0252
2026-01-11 15:17:25 | INFO | Epoch 7 | Batch 200/1169 | Loss: 0.0287
2026-01-11 15:17:27 | INFO | Epoch 7 | Batch 300/1169 | Loss: 0.0300
2026-01-11 15:17:30 | INFO | Epoch 7 | Batch 400/1169 | Loss: 0.0251
2026-01-11 15:17:32 | INFO | Epoch 7 | Batch 500/1169 | Loss: 0.0252
2026-01-11 15:17:35 | INFO | Epoch 7 | Batch 600/1169 | Loss: 0.0254
2026-01-11 15:17:37 | INFO | Epoch 7 | Batch 700/1169 | Loss: 0.0281
2026-01-11 15:17:39 | INFO | Epoch 7 | Batch 800/1169 | Loss: 0.0209
2026-01-11 15:17:42 | INFO | Epoch 7 | Batch 900/1169 | Loss: 0.0248
2026-01-11 15:17:44 | INFO | Epoch 7 | Batch 1000/1169 | Loss: 0.0264
2026-01-11 15:17:46 | INFO | Epoch 7 | Batch 1100/1169 | Loss: 0.0264
2026-01-11 15:17:50 | INFO | Epoch 7 | Train Loss: 0.0251 | Val Loss: 0.0195
2026-01-11 15:17:50 | INFO | Val F1: 0.3152 | Precision: 0.1983 | Recall: 0.7681
2026-01-11 15:17:50 | INFO | Epoch 8 | Batch 0/1169 | Loss: 0.0207
2026-01-11 15:17:52 | INFO | Epoch 8 | Batch 100/1169 | Loss: 0.0244
2026-01-11 15:17:55 | INFO | Epoch 8 | Batch 200/1169 | Loss: 0.0260
2026-01-11 15:17:57 | INFO | Epoch 8 | Batch 300/1169 | Loss: 0.0203
2026-01-11 15:17:59 | INFO | Epoch 8 | Batch 400/1169 | Loss: 0.0226
2026-01-11 15:18:02 | INFO | Epoch 8 | Batch 500/1169 | Loss: 0.0307
2026-01-11 15:18:04 | INFO | Epoch 8 | Batch 600/1169 | Loss: 0.0208
2026-01-11 15:18:06 | INFO | Epoch 8 | Batch 700/1169 | Loss: 0.0250
2026-01-11 15:18:09 | INFO | Epoch 8 | Batch 800/1169 | Loss: 0.0298
2026-01-11 15:18:11 | INFO | Epoch 8 | Batch 900/1169 | Loss: 0.0240
2026-01-11 15:18:13 | INFO | Epoch 8 | Batch 1000/1169 | Loss: 0.0219
2026-01-11 15:18:16 | INFO | Epoch 8 | Batch 1100/1169 | Loss: 0.0219
2026-01-11 15:18:19 | INFO | Epoch 8 | Train Loss: 0.0243 | Val Loss: 0.0213
2026-01-11 15:18:19 | INFO | Val F1: 0.2900 | Precision: 0.1775 | Recall: 0.7932
2026-01-11 15:18:19 | INFO | Epoch 9 | Batch 0/1169 | Loss: 0.0253
2026-01-11 15:18:22 | INFO | Epoch 9 | Batch 100/1169 | Loss: 0.0195
2026-01-11 15:18:24 | INFO | Epoch 9 | Batch 200/1169 | Loss: 0.0243
2026-01-11 15:18:27 | INFO | Epoch 9 | Batch 300/1169 | Loss: 0.0223
2026-01-11 15:18:29 | INFO | Epoch 9 | Batch 400/1169 | Loss: 0.0266
2026-01-11 15:18:31 | INFO | Epoch 9 | Batch 500/1169 | Loss: 0.0215
2026-01-11 15:18:33 | INFO | Epoch 9 | Batch 600/1169 | Loss: 0.0228
2026-01-11 15:18:36 | INFO | Epoch 9 | Batch 700/1169 | Loss: 0.0174
2026-01-11 15:18:38 | INFO | Epoch 9 | Batch 800/1169 | Loss: 0.0189
2026-01-11 15:18:40 | INFO | Epoch 9 | Batch 900/1169 | Loss: 0.0218
2026-01-11 15:18:43 | INFO | Epoch 9 | Batch 1000/1169 | Loss: 0.0201
2026-01-11 15:18:45 | INFO | Epoch 9 | Batch 1100/1169 | Loss: 0.0202
2026-01-11 15:18:48 | INFO | Epoch 9 | Train Loss: 0.0234 | Val Loss: 0.0187
2026-01-11 15:18:48 | INFO | Val F1: 0.3270 | Precision: 0.2076 | Recall: 0.7706
2026-01-11 15:18:49 | INFO | Epoch 10 | Batch 0/1169 | Loss: 0.0228
2026-01-11 15:18:51 | INFO | Epoch 10 | Batch 100/1169 | Loss: 0.0239
2026-01-11 15:18:53 | INFO | Epoch 10 | Batch 200/1169 | Loss: 0.0207
2026-01-11 15:18:55 | INFO | Epoch 10 | Batch 300/1169 | Loss: 0.0204
2026-01-11 15:18:58 | INFO | Epoch 10 | Batch 400/1169 | Loss: 0.0210
2026-01-11 15:19:00 | INFO | Epoch 10 | Batch 500/1169 | Loss: 0.0196
2026-01-11 15:19:03 | INFO | Epoch 10 | Batch 600/1169 | Loss: 0.0220
2026-01-11 15:19:05 | INFO | Epoch 10 | Batch 700/1169 | Loss: 0.0202
2026-01-11 15:19:07 | INFO | Epoch 10 | Batch 800/1169 | Loss: 0.0182
2026-01-11 15:19:09 | INFO | Epoch 10 | Batch 900/1169 | Loss: 0.0185
2026-01-11 15:19:12 | INFO | Epoch 10 | Batch 1000/1169 | Loss: 0.0218
2026-01-11 15:19:14 | INFO | Epoch 10 | Batch 1100/1169 | Loss: 0.0207
2026-01-11 15:19:18 | INFO | Epoch 10 | Train Loss: 0.0228 | Val Loss: 0.0182
2026-01-11 15:19:18 | INFO | Val F1: 0.3462 | Precision: 0.2246 | Recall: 0.7555
2026-01-11 15:19:18 | INFO | New best model saved (F1: 0.3462)
2026-01-11 15:19:18 | INFO | Epoch 11 | Batch 0/1169 | Loss: 0.0217
2026-01-11 15:19:20 | INFO | Epoch 11 | Batch 100/1169 | Loss: 0.0222
2026-01-11 15:19:23 | INFO | Epoch 11 | Batch 200/1169 | Loss: 0.0229
2026-01-11 15:19:25 | INFO | Epoch 11 | Batch 300/1169 | Loss: 0.0248
2026-01-11 15:19:27 | INFO | Epoch 11 | Batch 400/1169 | Loss: 0.0209
2026-01-11 15:19:30 | INFO | Epoch 11 | Batch 500/1169 | Loss: 0.0221
2026-01-11 15:19:32 | INFO | Epoch 11 | Batch 600/1169 | Loss: 0.0216
2026-01-11 15:19:34 | INFO | Epoch 11 | Batch 700/1169 | Loss: 0.0181
2026-01-11 15:19:37 | INFO | Epoch 11 | Batch 800/1169 | Loss: 0.0222
2026-01-11 15:19:39 | INFO | Epoch 11 | Batch 900/1169 | Loss: 0.0234
2026-01-11 15:19:41 | INFO | Epoch 11 | Batch 1000/1169 | Loss: 0.0209
2026-01-11 15:19:44 | INFO | Epoch 11 | Batch 1100/1169 | Loss: 0.0206
2026-01-11 15:19:48 | INFO | Epoch 11 | Train Loss: 0.0222 | Val Loss: 0.0186
2026-01-11 15:19:48 | INFO | Val F1: 0.3447 | Precision: 0.2232 | Recall: 0.7568
2026-01-11 15:19:48 | INFO | Epoch 12 | Batch 0/1169 | Loss: 0.0213
2026-01-11 15:19:50 | INFO | Epoch 12 | Batch 100/1169 | Loss: 0.0219
2026-01-11 15:19:52 | INFO | Epoch 12 | Batch 200/1169 | Loss: 0.0252
2026-01-11 15:19:55 | INFO | Epoch 12 | Batch 300/1169 | Loss: 0.0241
2026-01-11 15:19:57 | INFO | Epoch 12 | Batch 400/1169 | Loss: 0.0216
2026-01-11 15:20:00 | INFO | Epoch 12 | Batch 500/1169 | Loss: 0.0254
2026-01-11 15:20:02 | INFO | Epoch 12 | Batch 600/1169 | Loss: 0.0235
2026-01-11 15:20:05 | INFO | Epoch 12 | Batch 700/1169 | Loss: 0.0228
2026-01-11 15:20:07 | INFO | Epoch 12 | Batch 800/1169 | Loss: 0.0191
2026-01-11 15:20:09 | INFO | Epoch 12 | Batch 900/1169 | Loss: 0.0192
2026-01-11 15:20:12 | INFO | Epoch 12 | Batch 1000/1169 | Loss: 0.0188
2026-01-11 15:20:14 | INFO | Epoch 12 | Batch 1100/1169 | Loss: 0.0189
2026-01-11 15:20:18 | INFO | Epoch 12 | Train Loss: 0.0215 | Val Loss: 0.0182
2026-01-11 15:20:18 | INFO | Val F1: 0.3543 | Precision: 0.2320 | Recall: 0.7494
2026-01-11 15:20:18 | INFO | New best model saved (F1: 0.3543)
2026-01-11 15:20:18 | INFO | Epoch 13 | Batch 0/1169 | Loss: 0.0185
2026-01-11 15:20:20 | INFO | Epoch 13 | Batch 100/1169 | Loss: 0.0201
2026-01-11 15:20:23 | INFO | Epoch 13 | Batch 200/1169 | Loss: 0.0190
2026-01-11 15:20:25 | INFO | Epoch 13 | Batch 300/1169 | Loss: 0.0196
2026-01-11 15:20:27 | INFO | Epoch 13 | Batch 400/1169 | Loss: 0.0227
2026-01-11 15:20:30 | INFO | Epoch 13 | Batch 500/1169 | Loss: 0.0229
2026-01-11 15:20:32 | INFO | Epoch 13 | Batch 600/1169 | Loss: 0.0204
2026-01-11 15:20:34 | INFO | Epoch 13 | Batch 700/1169 | Loss: 0.0194
2026-01-11 15:20:37 | INFO | Epoch 13 | Batch 800/1169 | Loss: 0.0207
2026-01-11 15:20:39 | INFO | Epoch 13 | Batch 900/1169 | Loss: 0.0230
2026-01-11 15:20:41 | INFO | Epoch 13 | Batch 1000/1169 | Loss: 0.0205
2026-01-11 15:20:44 | INFO | Epoch 13 | Batch 1100/1169 | Loss: 0.0191
2026-01-11 15:20:48 | INFO | Epoch 13 | Train Loss: 0.0211 | Val Loss: 0.0173
2026-01-11 15:20:48 | INFO | Val F1: 0.3739 | Precision: 0.2505 | Recall: 0.7365
2026-01-11 15:20:48 | INFO | New best model saved (F1: 0.3739)
2026-01-11 15:20:48 | INFO | Epoch 14 | Batch 0/1169 | Loss: 0.0199
2026-01-11 15:20:50 | INFO | Epoch 14 | Batch 100/1169 | Loss: 0.0213
2026-01-11 15:20:52 | INFO | Epoch 14 | Batch 200/1169 | Loss: 0.0258
2026-01-11 15:20:55 | INFO | Epoch 14 | Batch 300/1169 | Loss: 0.0280
2026-01-11 15:20:57 | INFO | Epoch 14 | Batch 400/1169 | Loss: 0.0174
2026-01-11 15:20:59 | INFO | Epoch 14 | Batch 500/1169 | Loss: 0.0168
2026-01-11 15:21:02 | INFO | Epoch 14 | Batch 600/1169 | Loss: 0.0214
2026-01-11 15:21:04 | INFO | Epoch 14 | Batch 700/1169 | Loss: 0.0196
2026-01-11 15:21:06 | INFO | Epoch 14 | Batch 800/1169 | Loss: 0.0199
2026-01-11 15:21:09 | INFO | Epoch 14 | Batch 900/1169 | Loss: 0.0179
2026-01-11 15:21:11 | INFO | Epoch 14 | Batch 1000/1169 | Loss: 0.0226
2026-01-11 15:21:13 | INFO | Epoch 14 | Batch 1100/1169 | Loss: 0.0211
2026-01-11 15:21:17 | INFO | Epoch 14 | Train Loss: 0.0207 | Val Loss: 0.0177
2026-01-11 15:21:17 | INFO | Val F1: 0.3586 | Precision: 0.2364 | Recall: 0.7423
2026-01-11 15:21:17 | INFO | Epoch 15 | Batch 0/1169 | Loss: 0.0180
2026-01-11 15:21:19 | INFO | Epoch 15 | Batch 100/1169 | Loss: 0.0181
2026-01-11 15:21:22 | INFO | Epoch 15 | Batch 200/1169 | Loss: 0.0231
2026-01-11 15:21:24 | INFO | Epoch 15 | Batch 300/1169 | Loss: 0.0207
2026-01-11 15:21:26 | INFO | Epoch 15 | Batch 400/1169 | Loss: 0.0176
2026-01-11 15:21:29 | INFO | Epoch 15 | Batch 500/1169 | Loss: 0.0227
2026-01-11 15:21:31 | INFO | Epoch 15 | Batch 600/1169 | Loss: 0.0207
2026-01-11 15:21:34 | INFO | Epoch 15 | Batch 700/1169 | Loss: 0.0211
2026-01-11 15:21:36 | INFO | Epoch 15 | Batch 800/1169 | Loss: 0.0197
2026-01-11 15:21:38 | INFO | Epoch 15 | Batch 900/1169 | Loss: 0.0177
2026-01-11 15:21:41 | INFO | Epoch 15 | Batch 1000/1169 | Loss: 0.0216
2026-01-11 15:21:43 | INFO | Epoch 15 | Batch 1100/1169 | Loss: 0.0238
2026-01-11 15:21:46 | INFO | Epoch 15 | Train Loss: 0.0203 | Val Loss: 0.0178
2026-01-11 15:21:46 | INFO | Val F1: 0.3568 | Precision: 0.2347 | Recall: 0.7442
2026-01-11 15:21:46 | INFO | Epoch 16 | Batch 0/1169 | Loss: 0.0254
2026-01-11 15:21:49 | INFO | Epoch 16 | Batch 100/1169 | Loss: 0.0179
2026-01-11 15:21:51 | INFO | Epoch 16 | Batch 200/1169 | Loss: 0.0288
2026-01-11 15:21:53 | INFO | Epoch 16 | Batch 300/1169 | Loss: 0.0219
2026-01-11 15:21:56 | INFO | Epoch 16 | Batch 400/1169 | Loss: 0.0204
2026-01-11 15:21:58 | INFO | Epoch 16 | Batch 500/1169 | Loss: 0.0191
2026-01-11 15:22:00 | INFO | Epoch 16 | Batch 600/1169 | Loss: 0.0258
2026-01-11 15:22:03 | INFO | Epoch 16 | Batch 700/1169 | Loss: 0.0175
2026-01-11 15:22:05 | INFO | Epoch 16 | Batch 800/1169 | Loss: 0.0205
2026-01-11 15:22:07 | INFO | Epoch 16 | Batch 900/1169 | Loss: 0.0196
2026-01-11 15:22:09 | INFO | Epoch 16 | Batch 1000/1169 | Loss: 0.0178
2026-01-11 15:22:12 | INFO | Epoch 16 | Batch 1100/1169 | Loss: 0.0301
2026-01-11 15:22:15 | INFO | Epoch 16 | Train Loss: 0.0201 | Val Loss: 0.0178
2026-01-11 15:22:15 | INFO | Val F1: 0.3717 | Precision: 0.2480 | Recall: 0.7416
2026-01-11 15:22:15 | INFO | Epoch 17 | Batch 0/1169 | Loss: 0.0169
2026-01-11 15:22:18 | INFO | Epoch 17 | Batch 100/1169 | Loss: 0.0181
2026-01-11 15:22:20 | INFO | Epoch 17 | Batch 200/1169 | Loss: 0.0212
2026-01-11 15:22:22 | INFO | Epoch 17 | Batch 300/1169 | Loss: 0.0224
2026-01-11 15:22:25 | INFO | Epoch 17 | Batch 400/1169 | Loss: 0.0220
2026-01-11 15:22:27 | INFO | Epoch 17 | Batch 500/1169 | Loss: 0.0195
2026-01-11 15:22:29 | INFO | Epoch 17 | Batch 600/1169 | Loss: 0.0212
2026-01-11 15:22:32 | INFO | Epoch 17 | Batch 700/1169 | Loss: 0.0183
2026-01-11 15:22:34 | INFO | Epoch 17 | Batch 800/1169 | Loss: 0.0204
2026-01-11 15:22:36 | INFO | Epoch 17 | Batch 900/1169 | Loss: 0.0204
2026-01-11 15:22:39 | INFO | Epoch 17 | Batch 1000/1169 | Loss: 0.0226
2026-01-11 15:22:41 | INFO | Epoch 17 | Batch 1100/1169 | Loss: 0.0183
2026-01-11 15:22:45 | INFO | Epoch 17 | Train Loss: 0.0197 | Val Loss: 0.0171
2026-01-11 15:22:45 | INFO | Val F1: 0.3774 | Precision: 0.2543 | Recall: 0.7316
2026-01-11 15:22:45 | INFO | New best model saved (F1: 0.3774)
2026-01-11 15:22:45 | INFO | Epoch 18 | Batch 0/1169 | Loss: 0.0216
2026-01-11 15:22:47 | INFO | Epoch 18 | Batch 100/1169 | Loss: 0.0203
2026-01-11 15:22:50 | INFO | Epoch 18 | Batch 200/1169 | Loss: 0.0214
2026-01-11 15:22:52 | INFO | Epoch 18 | Batch 300/1169 | Loss: 0.0222
2026-01-11 15:22:55 | INFO | Epoch 18 | Batch 400/1169 | Loss: 0.0171
2026-01-11 15:22:56 | INFO | Epoch 18 | Batch 500/1169 | Loss: 0.0201
2026-01-11 15:22:58 | INFO | Epoch 18 | Batch 600/1169 | Loss: 0.0199
2026-01-11 15:23:00 | INFO | Epoch 18 | Batch 700/1169 | Loss: 0.0211
2026-01-11 15:23:02 | INFO | Epoch 18 | Batch 800/1169 | Loss: 0.0254
2026-01-11 15:23:04 | INFO | Epoch 18 | Batch 900/1169 | Loss: 0.0182
2026-01-11 15:23:06 | INFO | Epoch 18 | Batch 1000/1169 | Loss: 0.0237
2026-01-11 15:23:08 | INFO | Epoch 18 | Batch 1100/1169 | Loss: 0.0180
2026-01-11 15:23:11 | INFO | Epoch 18 | Train Loss: 0.0193 | Val Loss: 0.0175
2026-01-11 15:23:11 | INFO | Val F1: 0.3780 | Precision: 0.2546 | Recall: 0.7332
2026-01-11 15:23:11 | INFO | New best model saved (F1: 0.3780)
2026-01-11 15:23:11 | INFO | Epoch 19 | Batch 0/1169 | Loss: 0.0166
2026-01-11 15:23:13 | INFO | Epoch 19 | Batch 100/1169 | Loss: 0.0207
2026-01-11 15:23:15 | INFO | Epoch 19 | Batch 200/1169 | Loss: 0.0203
2026-01-11 15:23:17 | INFO | Epoch 19 | Batch 300/1169 | Loss: 0.0198
2026-01-11 15:23:19 | INFO | Epoch 19 | Batch 400/1169 | Loss: 0.0204
2026-01-11 15:23:22 | INFO | Epoch 19 | Batch 500/1169 | Loss: 0.0189
2026-01-11 15:23:25 | INFO | Epoch 19 | Batch 600/1169 | Loss: 0.0216
2026-01-11 15:23:28 | INFO | Epoch 19 | Batch 700/1169 | Loss: 0.0201
2026-01-11 15:23:30 | INFO | Epoch 19 | Batch 800/1169 | Loss: 0.0177
2026-01-11 15:23:33 | INFO | Epoch 19 | Batch 900/1169 | Loss: 0.0170
2026-01-11 15:23:35 | INFO | Epoch 19 | Batch 1000/1169 | Loss: 0.0203
2026-01-11 15:23:38 | INFO | Epoch 19 | Batch 1100/1169 | Loss: 0.0206
2026-01-11 15:23:41 | INFO | Epoch 19 | Train Loss: 0.0192 | Val Loss: 0.0177
2026-01-11 15:23:41 | INFO | Val F1: 0.3815 | Precision: 0.2581 | Recall: 0.7310
2026-01-11 15:23:41 | INFO | New best model saved (F1: 0.3815)
2026-01-11 15:23:41 | INFO | Epoch 20 | Batch 0/1169 | Loss: 0.0213
2026-01-11 15:23:44 | INFO | Epoch 20 | Batch 100/1169 | Loss: 0.0196
2026-01-11 15:23:46 | INFO | Epoch 20 | Batch 200/1169 | Loss: 0.0210
2026-01-11 15:23:48 | INFO | Epoch 20 | Batch 300/1169 | Loss: 0.0134
2026-01-11 15:23:50 | INFO | Epoch 20 | Batch 400/1169 | Loss: 0.0203
2026-01-11 15:23:53 | INFO | Epoch 20 | Batch 500/1169 | Loss: 0.0189
2026-01-11 15:23:55 | INFO | Epoch 20 | Batch 600/1169 | Loss: 0.0206
2026-01-11 15:23:58 | INFO | Epoch 20 | Batch 700/1169 | Loss: 0.0231
2026-01-11 15:24:00 | INFO | Epoch 20 | Batch 800/1169 | Loss: 0.0197
2026-01-11 15:24:02 | INFO | Epoch 20 | Batch 900/1169 | Loss: 0.0199
2026-01-11 15:24:05 | INFO | Epoch 20 | Batch 1000/1169 | Loss: 0.0181
2026-01-11 15:24:08 | INFO | Epoch 20 | Batch 1100/1169 | Loss: 0.0188
2026-01-11 15:24:11 | INFO | Epoch 20 | Train Loss: 0.0188 | Val Loss: 0.0180
2026-01-11 15:24:11 | INFO | Val F1: 0.3781 | Precision: 0.2543 | Recall: 0.7365
2026-01-11 15:24:11 | INFO | Epoch 21 | Batch 0/1169 | Loss: 0.0163
2026-01-11 15:24:13 | INFO | Epoch 21 | Batch 100/1169 | Loss: 0.0219
2026-01-11 15:24:15 | INFO | Epoch 21 | Batch 200/1169 | Loss: 0.0189
2026-01-11 15:24:17 | INFO | Epoch 21 | Batch 300/1169 | Loss: 0.0180
2026-01-11 15:24:19 | INFO | Epoch 21 | Batch 400/1169 | Loss: 0.0219
2026-01-11 15:24:21 | INFO | Epoch 21 | Batch 500/1169 | Loss: 0.0209
2026-01-11 15:24:22 | INFO | Epoch 21 | Batch 600/1169 | Loss: 0.0170
2026-01-11 15:24:24 | INFO | Epoch 21 | Batch 700/1169 | Loss: 0.0180
2026-01-11 15:24:26 | INFO | Epoch 21 | Batch 800/1169 | Loss: 0.0210
2026-01-11 15:24:28 | INFO | Epoch 21 | Batch 900/1169 | Loss: 0.0181
2026-01-11 15:24:30 | INFO | Epoch 21 | Batch 1000/1169 | Loss: 0.0202
2026-01-11 15:24:32 | INFO | Epoch 21 | Batch 1100/1169 | Loss: 0.0171
2026-01-11 15:24:35 | INFO | Epoch 21 | Train Loss: 0.0186 | Val Loss: 0.0175
2026-01-11 15:24:35 | INFO | Val F1: 0.3742 | Precision: 0.2501 | Recall: 0.7426
2026-01-11 15:24:35 | INFO | Epoch 22 | Batch 0/1169 | Loss: 0.0173
2026-01-11 15:24:37 | INFO | Epoch 22 | Batch 100/1169 | Loss: 0.0206
2026-01-11 15:24:39 | INFO | Epoch 22 | Batch 200/1169 | Loss: 0.0195
2026-01-11 15:24:40 | INFO | Epoch 22 | Batch 300/1169 | Loss: 0.0180
2026-01-11 15:24:43 | INFO | Epoch 22 | Batch 400/1169 | Loss: 0.0175
2026-01-11 15:24:45 | INFO | Epoch 22 | Batch 500/1169 | Loss: 0.0253
2026-01-11 15:24:47 | INFO | Epoch 22 | Batch 600/1169 | Loss: 0.0167
2026-01-11 15:24:49 | INFO | Epoch 22 | Batch 700/1169 | Loss: 0.0161
2026-01-11 15:24:51 | INFO | Epoch 22 | Batch 800/1169 | Loss: 0.0233
2026-01-11 15:24:53 | INFO | Epoch 22 | Batch 900/1169 | Loss: 0.0195
2026-01-11 15:24:55 | INFO | Epoch 22 | Batch 1000/1169 | Loss: 0.0174
2026-01-11 15:24:58 | INFO | Epoch 22 | Batch 1100/1169 | Loss: 0.0196
2026-01-11 15:25:02 | INFO | Epoch 22 | Train Loss: 0.0184 | Val Loss: 0.0177
2026-01-11 15:25:02 | INFO | Val F1: 0.3885 | Precision: 0.2645 | Recall: 0.7319
2026-01-11 15:25:02 | INFO | New best model saved (F1: 0.3885)
2026-01-11 15:25:02 | INFO | Epoch 23 | Batch 0/1169 | Loss: 0.0180
2026-01-11 15:25:06 | INFO | Epoch 23 | Batch 100/1169 | Loss: 0.0183
2026-01-11 15:25:08 | INFO | Epoch 23 | Batch 200/1169 | Loss: 0.0178
2026-01-11 15:25:10 | INFO | Epoch 23 | Batch 300/1169 | Loss: 0.0168
2026-01-11 15:25:12 | INFO | Epoch 23 | Batch 400/1169 | Loss: 0.0178
2026-01-11 15:25:14 | INFO | Epoch 23 | Batch 500/1169 | Loss: 0.0166
2026-01-11 15:25:17 | INFO | Epoch 23 | Batch 600/1169 | Loss: 0.0170
2026-01-11 15:25:19 | INFO | Epoch 23 | Batch 700/1169 | Loss: 0.0152
2026-01-11 15:25:21 | INFO | Epoch 23 | Batch 800/1169 | Loss: 0.0184
2026-01-11 15:25:23 | INFO | Epoch 23 | Batch 900/1169 | Loss: 0.0203
2026-01-11 15:25:25 | INFO | Epoch 23 | Batch 1000/1169 | Loss: 0.0171
2026-01-11 15:25:26 | INFO | Epoch 23 | Batch 1100/1169 | Loss: 0.0190
2026-01-11 15:25:30 | INFO | Epoch 23 | Train Loss: 0.0182 | Val Loss: 0.0182
2026-01-11 15:25:30 | INFO | Val F1: 0.3854 | Precision: 0.2604 | Recall: 0.7416
2026-01-11 15:25:30 | INFO | Epoch 24 | Batch 0/1169 | Loss: 0.0183
2026-01-11 15:25:32 | INFO | Epoch 24 | Batch 100/1169 | Loss: 0.0193
2026-01-11 15:25:34 | INFO | Epoch 24 | Batch 200/1169 | Loss: 0.0179
2026-01-11 15:25:37 | INFO | Epoch 24 | Batch 300/1169 | Loss: 0.0169
2026-01-11 15:25:40 | INFO | Epoch 24 | Batch 400/1169 | Loss: 0.0161
2026-01-11 15:25:41 | INFO | Epoch 24 | Batch 500/1169 | Loss: 0.0194
2026-01-11 15:25:43 | INFO | Epoch 24 | Batch 600/1169 | Loss: 0.0158
2026-01-11 15:25:45 | INFO | Epoch 24 | Batch 700/1169 | Loss: 0.0159
2026-01-11 15:25:47 | INFO | Epoch 24 | Batch 800/1169 | Loss: 0.0146
2026-01-11 15:25:48 | INFO | Epoch 24 | Batch 900/1169 | Loss: 0.0149
2026-01-11 15:25:50 | INFO | Epoch 24 | Batch 1000/1169 | Loss: 0.0136
2026-01-11 15:25:52 | INFO | Epoch 24 | Batch 1100/1169 | Loss: 0.0150
2026-01-11 15:25:55 | INFO | Epoch 24 | Train Loss: 0.0169 | Val Loss: 0.0175
2026-01-11 15:25:55 | INFO | Val F1: 0.3985 | Precision: 0.2746 | Recall: 0.7268
2026-01-11 15:25:55 | INFO | New best model saved (F1: 0.3985)
2026-01-11 15:25:55 | INFO | Epoch 25 | Batch 0/1169 | Loss: 0.0122
2026-01-11 15:25:56 | INFO | Epoch 25 | Batch 100/1169 | Loss: 0.0124
2026-01-11 15:25:58 | INFO | Epoch 25 | Batch 200/1169 | Loss: 0.0163
2026-01-11 15:26:00 | INFO | Epoch 25 | Batch 300/1169 | Loss: 0.0161
2026-01-11 15:26:01 | INFO | Epoch 25 | Batch 400/1169 | Loss: 0.0204
2026-01-11 15:26:03 | INFO | Epoch 25 | Batch 500/1169 | Loss: 0.0136
2026-01-11 15:26:05 | INFO | Epoch 25 | Batch 600/1169 | Loss: 0.0142
2026-01-11 15:26:07 | INFO | Epoch 25 | Batch 700/1169 | Loss: 0.0154
2026-01-11 15:26:09 | INFO | Epoch 25 | Batch 800/1169 | Loss: 0.0145
2026-01-11 15:26:11 | INFO | Epoch 25 | Batch 900/1169 | Loss: 0.0189
2026-01-11 15:26:13 | INFO | Epoch 25 | Batch 1000/1169 | Loss: 0.0148
2026-01-11 15:26:15 | INFO | Epoch 25 | Batch 1100/1169 | Loss: 0.0130
2026-01-11 15:26:18 | INFO | Epoch 25 | Train Loss: 0.0166 | Val Loss: 0.0170
2026-01-11 15:26:18 | INFO | Val F1: 0.4076 | Precision: 0.2833 | Recall: 0.7268
2026-01-11 15:26:18 | INFO | New best model saved (F1: 0.4076)
2026-01-11 15:26:18 | INFO | Epoch 26 | Batch 0/1169 | Loss: 0.0125
2026-01-11 15:26:20 | INFO | Epoch 26 | Batch 100/1169 | Loss: 0.0209
2026-01-11 15:26:22 | INFO | Epoch 26 | Batch 200/1169 | Loss: 0.0140
2026-01-11 15:26:24 | INFO | Epoch 26 | Batch 300/1169 | Loss: 0.0143
2026-01-11 15:26:26 | INFO | Epoch 26 | Batch 400/1169 | Loss: 0.0138
2026-01-11 15:26:27 | INFO | Epoch 26 | Batch 500/1169 | Loss: 0.0207
2026-01-11 15:26:29 | INFO | Epoch 26 | Batch 600/1169 | Loss: 0.0133
2026-01-11 15:26:31 | INFO | Epoch 26 | Batch 700/1169 | Loss: 0.0158
2026-01-11 15:26:33 | INFO | Epoch 26 | Batch 800/1169 | Loss: 0.0131
2026-01-11 15:26:35 | INFO | Epoch 26 | Batch 900/1169 | Loss: 0.0151
2026-01-11 15:26:37 | INFO | Epoch 26 | Batch 1000/1169 | Loss: 0.0150
2026-01-11 15:26:38 | INFO | Epoch 26 | Batch 1100/1169 | Loss: 0.0186
2026-01-11 15:26:41 | INFO | Epoch 26 | Train Loss: 0.0163 | Val Loss: 0.0183
2026-01-11 15:26:41 | INFO | Val F1: 0.3865 | Precision: 0.2613 | Recall: 0.7419
2026-01-11 15:26:41 | INFO | Epoch 27 | Batch 0/1169 | Loss: 0.0153
2026-01-11 15:26:43 | INFO | Epoch 27 | Batch 100/1169 | Loss: 0.0167
2026-01-11 15:26:45 | INFO | Epoch 27 | Batch 200/1169 | Loss: 0.0160
2026-01-11 15:26:48 | INFO | Epoch 27 | Batch 300/1169 | Loss: 0.0144
2026-01-11 15:26:50 | INFO | Epoch 27 | Batch 400/1169 | Loss: 0.0189
2026-01-11 15:26:52 | INFO | Epoch 27 | Batch 500/1169 | Loss: 0.0151
2026-01-11 15:26:56 | INFO | Epoch 27 | Batch 600/1169 | Loss: 0.0160
2026-01-11 15:26:58 | INFO | Epoch 27 | Batch 700/1169 | Loss: 0.0138
2026-01-11 15:27:00 | INFO | Epoch 27 | Batch 800/1169 | Loss: 0.0130
2026-01-11 15:27:02 | INFO | Epoch 27 | Batch 900/1169 | Loss: 0.0153
2026-01-11 15:27:04 | INFO | Epoch 27 | Batch 1000/1169 | Loss: 0.0143
2026-01-11 15:27:06 | INFO | Epoch 27 | Batch 1100/1169 | Loss: 0.0162
2026-01-11 15:27:09 | INFO | Epoch 27 | Train Loss: 0.0163 | Val Loss: 0.0181
2026-01-11 15:27:09 | INFO | Val F1: 0.3993 | Precision: 0.2752 | Recall: 0.7274
2026-01-11 15:27:09 | INFO | Epoch 28 | Batch 0/1169 | Loss: 0.0125
2026-01-11 15:27:10 | INFO | Epoch 28 | Batch 100/1169 | Loss: 0.0132
2026-01-11 15:27:12 | INFO | Epoch 28 | Batch 200/1169 | Loss: 0.0142
2026-01-11 15:27:14 | INFO | Epoch 28 | Batch 300/1169 | Loss: 0.0189
2026-01-11 15:27:16 | INFO | Epoch 28 | Batch 400/1169 | Loss: 0.0186
2026-01-11 15:27:18 | INFO | Epoch 28 | Batch 500/1169 | Loss: 0.0148
2026-01-11 15:27:20 | INFO | Epoch 28 | Batch 600/1169 | Loss: 0.0175
2026-01-11 15:27:22 | INFO | Epoch 28 | Batch 700/1169 | Loss: 0.0118
2026-01-11 15:27:24 | INFO | Epoch 28 | Batch 800/1169 | Loss: 0.0185
2026-01-11 15:27:26 | INFO | Epoch 28 | Batch 900/1169 | Loss: 0.0164
2026-01-11 15:27:27 | INFO | Epoch 28 | Batch 1000/1169 | Loss: 0.0142
2026-01-11 15:27:29 | INFO | Epoch 28 | Batch 1100/1169 | Loss: 0.0206
2026-01-11 15:27:32 | INFO | Epoch 28 | Train Loss: 0.0161 | Val Loss: 0.0182
2026-01-11 15:27:32 | INFO | Val F1: 0.4018 | Precision: 0.2765 | Recall: 0.7348
2026-01-11 15:27:32 | INFO | Epoch 29 | Batch 0/1169 | Loss: 0.0168
2026-01-11 15:27:34 | INFO | Epoch 29 | Batch 100/1169 | Loss: 0.0225
2026-01-11 15:27:35 | INFO | Epoch 29 | Batch 200/1169 | Loss: 0.0147
2026-01-11 15:27:37 | INFO | Epoch 29 | Batch 300/1169 | Loss: 0.0157
2026-01-11 15:27:39 | INFO | Epoch 29 | Batch 400/1169 | Loss: 0.0128
2026-01-11 15:27:40 | INFO | Epoch 29 | Batch 500/1169 | Loss: 0.0123
2026-01-11 15:27:42 | INFO | Epoch 29 | Batch 600/1169 | Loss: 0.0151
2026-01-11 15:27:44 | INFO | Epoch 29 | Batch 700/1169 | Loss: 0.0213
2026-01-11 15:27:46 | INFO | Epoch 29 | Batch 800/1169 | Loss: 0.0181
2026-01-11 15:27:47 | INFO | Epoch 29 | Batch 900/1169 | Loss: 0.0139
2026-01-11 15:27:49 | INFO | Epoch 29 | Batch 1000/1169 | Loss: 0.0125
2026-01-11 15:27:51 | INFO | Epoch 29 | Batch 1100/1169 | Loss: 0.0184
2026-01-11 15:27:54 | INFO | Epoch 29 | Train Loss: 0.0160 | Val Loss: 0.0186
2026-01-11 15:27:54 | INFO | Val F1: 0.3910 | Precision: 0.2663 | Recall: 0.7355
2026-01-11 15:27:54 | INFO | Epoch 30 | Batch 0/1169 | Loss: 0.0139
2026-01-11 15:27:56 | INFO | Epoch 30 | Batch 100/1169 | Loss: 0.0131
2026-01-11 15:27:57 | INFO | Epoch 30 | Batch 200/1169 | Loss: 0.0151
2026-01-11 15:27:59 | INFO | Epoch 30 | Batch 300/1169 | Loss: 0.0231
2026-01-11 15:28:01 | INFO | Epoch 30 | Batch 400/1169 | Loss: 0.0168
2026-01-11 15:28:02 | INFO | Epoch 30 | Batch 500/1169 | Loss: 0.0149
2026-01-11 15:28:04 | INFO | Epoch 30 | Batch 600/1169 | Loss: 0.0116
2026-01-11 15:28:06 | INFO | Epoch 30 | Batch 700/1169 | Loss: 0.0136
2026-01-11 15:28:08 | INFO | Epoch 30 | Batch 800/1169 | Loss: 0.0139
2026-01-11 15:28:09 | INFO | Epoch 30 | Batch 900/1169 | Loss: 0.0115
2026-01-11 15:28:11 | INFO | Epoch 30 | Batch 1000/1169 | Loss: 0.0164
2026-01-11 15:28:13 | INFO | Epoch 30 | Batch 1100/1169 | Loss: 0.0129
2026-01-11 15:28:15 | INFO | Epoch 30 | Train Loss: 0.0159 | Val Loss: 0.0185
2026-01-11 15:28:15 | INFO | Val F1: 0.3933 | Precision: 0.2690 | Recall: 0.7313
2026-01-11 15:28:15 | INFO | Epoch 31 | Batch 0/1169 | Loss: 0.0160
2026-01-11 15:28:17 | INFO | Epoch 31 | Batch 100/1169 | Loss: 0.0188
2026-01-11 15:28:19 | INFO | Epoch 31 | Batch 200/1169 | Loss: 0.0151
2026-01-11 15:28:20 | INFO | Epoch 31 | Batch 300/1169 | Loss: 0.0177
2026-01-11 15:28:22 | INFO | Epoch 31 | Batch 400/1169 | Loss: 0.0141
2026-01-11 15:28:24 | INFO | Epoch 31 | Batch 500/1169 | Loss: 0.0155
2026-01-11 15:28:26 | INFO | Epoch 31 | Batch 600/1169 | Loss: 0.0163
2026-01-11 15:28:27 | INFO | Epoch 31 | Batch 700/1169 | Loss: 0.0150
2026-01-11 15:28:29 | INFO | Epoch 31 | Batch 800/1169 | Loss: 0.0189
2026-01-11 15:28:31 | INFO | Epoch 31 | Batch 900/1169 | Loss: 0.0177
2026-01-11 15:28:32 | INFO | Epoch 31 | Batch 1000/1169 | Loss: 0.0110
2026-01-11 15:28:34 | INFO | Epoch 31 | Batch 1100/1169 | Loss: 0.0212
2026-01-11 15:28:37 | INFO | Epoch 31 | Train Loss: 0.0158 | Val Loss: 0.0181
2026-01-11 15:28:37 | INFO | Val F1: 0.4106 | Precision: 0.2864 | Recall: 0.7255
2026-01-11 15:28:37 | INFO | New best model saved (F1: 0.4106)
2026-01-11 15:28:37 | INFO | Epoch 32 | Batch 0/1169 | Loss: 0.0162
2026-01-11 15:28:39 | INFO | Epoch 32 | Batch 100/1169 | Loss: 0.0150
2026-01-11 15:28:41 | INFO | Epoch 32 | Batch 200/1169 | Loss: 0.0121
2026-01-11 15:28:42 | INFO | Epoch 32 | Batch 300/1169 | Loss: 0.0135
2026-01-11 15:28:44 | INFO | Epoch 32 | Batch 400/1169 | Loss: 0.0197
2026-01-11 15:28:46 | INFO | Epoch 32 | Batch 500/1169 | Loss: 0.0126
2026-01-11 15:28:48 | INFO | Epoch 32 | Batch 600/1169 | Loss: 0.0171
2026-01-11 15:28:49 | INFO | Epoch 32 | Batch 700/1169 | Loss: 0.0153
2026-01-11 15:28:51 | INFO | Epoch 32 | Batch 800/1169 | Loss: 0.0146
2026-01-11 15:28:53 | INFO | Epoch 32 | Batch 900/1169 | Loss: 0.0175
2026-01-11 15:28:54 | INFO | Epoch 32 | Batch 1000/1169 | Loss: 0.0158
2026-01-11 15:28:56 | INFO | Epoch 32 | Batch 1100/1169 | Loss: 0.0136
2026-01-11 15:28:59 | INFO | Epoch 32 | Train Loss: 0.0152 | Val Loss: 0.0176
2026-01-11 15:28:59 | INFO | Val F1: 0.4146 | Precision: 0.2912 | Recall: 0.7197
2026-01-11 15:28:59 | INFO | New best model saved (F1: 0.4146)
2026-01-11 15:28:59 | INFO | Epoch 33 | Batch 0/1169 | Loss: 0.0120
2026-01-11 15:29:01 | INFO | Epoch 33 | Batch 100/1169 | Loss: 0.0161
2026-01-11 15:29:02 | INFO | Epoch 33 | Batch 200/1169 | Loss: 0.0120
2026-01-11 15:29:04 | INFO | Epoch 33 | Batch 300/1169 | Loss: 0.0175
2026-01-11 15:29:06 | INFO | Epoch 33 | Batch 400/1169 | Loss: 0.0146
2026-01-11 15:29:08 | INFO | Epoch 33 | Batch 500/1169 | Loss: 0.0131
2026-01-11 15:29:09 | INFO | Epoch 33 | Batch 600/1169 | Loss: 0.0142
2026-01-11 15:29:11 | INFO | Epoch 33 | Batch 700/1169 | Loss: 0.0139
2026-01-11 15:29:13 | INFO | Epoch 33 | Batch 800/1169 | Loss: 0.0150
2026-01-11 15:29:14 | INFO | Epoch 33 | Batch 900/1169 | Loss: 0.0137
2026-01-11 15:29:16 | INFO | Epoch 33 | Batch 1000/1169 | Loss: 0.0194
2026-01-11 15:29:18 | INFO | Epoch 33 | Batch 1100/1169 | Loss: 0.0178
2026-01-11 15:29:21 | INFO | Epoch 33 | Train Loss: 0.0148 | Val Loss: 0.0180
2026-01-11 15:29:21 | INFO | Val F1: 0.4168 | Precision: 0.2934 | Recall: 0.7194
2026-01-11 15:29:21 | INFO | New best model saved (F1: 0.4168)
2026-01-11 15:29:21 | INFO | Epoch 34 | Batch 0/1169 | Loss: 0.0158
2026-01-11 15:29:23 | INFO | Epoch 34 | Batch 100/1169 | Loss: 0.0151
2026-01-11 15:29:24 | INFO | Epoch 34 | Batch 200/1169 | Loss: 0.0124
2026-01-11 15:29:26 | INFO | Epoch 34 | Batch 300/1169 | Loss: 0.0129
2026-01-11 15:29:28 | INFO | Epoch 34 | Batch 400/1169 | Loss: 0.0148
2026-01-11 15:29:29 | INFO | Epoch 34 | Batch 500/1169 | Loss: 0.0128
2026-01-11 15:29:31 | INFO | Epoch 34 | Batch 600/1169 | Loss: 0.0155
2026-01-11 15:29:33 | INFO | Epoch 34 | Batch 700/1169 | Loss: 0.0128
2026-01-11 15:29:34 | INFO | Epoch 34 | Batch 800/1169 | Loss: 0.0148
2026-01-11 15:29:36 | INFO | Epoch 34 | Batch 900/1169 | Loss: 0.0143
2026-01-11 15:29:38 | INFO | Epoch 34 | Batch 1000/1169 | Loss: 0.0136
2026-01-11 15:29:40 | INFO | Epoch 34 | Batch 1100/1169 | Loss: 0.0152
2026-01-11 15:29:42 | INFO | Epoch 34 | Train Loss: 0.0148 | Val Loss: 0.0179
2026-01-11 15:29:42 | INFO | Val F1: 0.4214 | Precision: 0.2983 | Recall: 0.7177
2026-01-11 15:29:42 | INFO | New best model saved (F1: 0.4214)
2026-01-11 15:29:42 | INFO | Epoch 35 | Batch 0/1169 | Loss: 0.0106
2026-01-11 15:29:44 | INFO | Epoch 35 | Batch 100/1169 | Loss: 0.0135
2026-01-11 15:29:46 | INFO | Epoch 35 | Batch 200/1169 | Loss: 0.0131
2026-01-11 15:29:47 | INFO | Epoch 35 | Batch 300/1169 | Loss: 0.0183
2026-01-11 15:29:49 | INFO | Epoch 35 | Batch 400/1169 | Loss: 0.0146
2026-01-11 15:29:51 | INFO | Epoch 35 | Batch 500/1169 | Loss: 0.0122
2026-01-11 15:29:53 | INFO | Epoch 35 | Batch 600/1169 | Loss: 0.0213
2026-01-11 15:29:54 | INFO | Epoch 35 | Batch 700/1169 | Loss: 0.0159
2026-01-11 15:29:56 | INFO | Epoch 35 | Batch 800/1169 | Loss: 0.0145
2026-01-11 15:29:58 | INFO | Epoch 35 | Batch 900/1169 | Loss: 0.0141
2026-01-11 15:29:59 | INFO | Epoch 35 | Batch 1000/1169 | Loss: 0.0089
2026-01-11 15:30:01 | INFO | Epoch 35 | Batch 1100/1169 | Loss: 0.0177
2026-01-11 15:30:04 | INFO | Epoch 35 | Train Loss: 0.0148 | Val Loss: 0.0183
2026-01-11 15:30:04 | INFO | Val F1: 0.4224 | Precision: 0.2986 | Recall: 0.7216
2026-01-11 15:30:04 | INFO | New best model saved (F1: 0.4224)
2026-01-11 15:30:04 | INFO | Epoch 36 | Batch 0/1169 | Loss: 0.0156
2026-01-11 15:30:06 | INFO | Epoch 36 | Batch 100/1169 | Loss: 0.0132
2026-01-11 15:30:07 | INFO | Epoch 36 | Batch 200/1169 | Loss: 0.0141
2026-01-11 15:30:09 | INFO | Epoch 36 | Batch 300/1169 | Loss: 0.0142
2026-01-11 15:30:11 | INFO | Epoch 36 | Batch 400/1169 | Loss: 0.0178
2026-01-11 15:30:13 | INFO | Epoch 36 | Batch 500/1169 | Loss: 0.0140
2026-01-11 15:30:14 | INFO | Epoch 36 | Batch 600/1169 | Loss: 0.0152
2026-01-11 15:30:16 | INFO | Epoch 36 | Batch 700/1169 | Loss: 0.0173
2026-01-11 15:30:18 | INFO | Epoch 36 | Batch 800/1169 | Loss: 0.0153
2026-01-11 15:30:19 | INFO | Epoch 36 | Batch 900/1169 | Loss: 0.0196
2026-01-11 15:30:21 | INFO | Epoch 36 | Batch 1000/1169 | Loss: 0.0132
2026-01-11 15:30:23 | INFO | Epoch 36 | Batch 1100/1169 | Loss: 0.0156
2026-01-11 15:30:26 | INFO | Epoch 36 | Train Loss: 0.0146 | Val Loss: 0.0181
2026-01-11 15:30:26 | INFO | Val F1: 0.4316 | Precision: 0.3102 | Recall: 0.7090
2026-01-11 15:30:26 | INFO | New best model saved (F1: 0.4316)
2026-01-11 15:30:26 | INFO | Epoch 37 | Batch 0/1169 | Loss: 0.0132
2026-01-11 15:30:27 | INFO | Epoch 37 | Batch 100/1169 | Loss: 0.0126
2026-01-11 15:30:29 | INFO | Epoch 37 | Batch 200/1169 | Loss: 0.0130
2026-01-11 15:30:31 | INFO | Epoch 37 | Batch 300/1169 | Loss: 0.0104
2026-01-11 15:30:32 | INFO | Epoch 37 | Batch 400/1169 | Loss: 0.0128
2026-01-11 15:30:34 | INFO | Epoch 37 | Batch 500/1169 | Loss: 0.0189
2026-01-11 15:30:36 | INFO | Epoch 37 | Batch 600/1169 | Loss: 0.0175
2026-01-11 15:30:38 | INFO | Epoch 37 | Batch 700/1169 | Loss: 0.0143
2026-01-11 15:30:39 | INFO | Epoch 37 | Batch 800/1169 | Loss: 0.0181
2026-01-11 15:30:41 | INFO | Epoch 37 | Batch 900/1169 | Loss: 0.0135
2026-01-11 15:30:43 | INFO | Epoch 37 | Batch 1000/1169 | Loss: 0.0165
2026-01-11 15:30:44 | INFO | Epoch 37 | Batch 1100/1169 | Loss: 0.0115
2026-01-11 15:30:47 | INFO | Epoch 37 | Train Loss: 0.0146 | Val Loss: 0.0182
2026-01-11 15:30:47 | INFO | Val F1: 0.4307 | Precision: 0.3085 | Recall: 0.7135
2026-01-11 15:30:47 | INFO | Epoch 38 | Batch 0/1169 | Loss: 0.0142
2026-01-11 15:30:49 | INFO | Epoch 38 | Batch 100/1169 | Loss: 0.0161
2026-01-11 15:30:51 | INFO | Epoch 38 | Batch 200/1169 | Loss: 0.0133
2026-01-11 15:30:52 | INFO | Epoch 38 | Batch 300/1169 | Loss: 0.0116
2026-01-11 15:30:54 | INFO | Epoch 38 | Batch 400/1169 | Loss: 0.0130
2026-01-11 15:30:56 | INFO | Epoch 38 | Batch 500/1169 | Loss: 0.0123
2026-01-11 15:30:58 | INFO | Epoch 38 | Batch 600/1169 | Loss: 0.0127
2026-01-11 15:31:01 | INFO | Epoch 38 | Batch 700/1169 | Loss: 0.0139
2026-01-11 15:31:03 | INFO | Epoch 38 | Batch 800/1169 | Loss: 0.0134
2026-01-11 15:31:05 | INFO | Epoch 38 | Batch 900/1169 | Loss: 0.0210
2026-01-11 15:31:07 | INFO | Epoch 38 | Batch 1000/1169 | Loss: 0.0115
2026-01-11 15:31:09 | INFO | Epoch 38 | Batch 1100/1169 | Loss: 0.0145
2026-01-11 15:31:12 | INFO | Epoch 38 | Train Loss: 0.0143 | Val Loss: 0.0186
2026-01-11 15:31:12 | INFO | Val F1: 0.4392 | Precision: 0.3183 | Recall: 0.7081
2026-01-11 15:31:12 | INFO | New best model saved (F1: 0.4392)
2026-01-11 15:31:12 | INFO | Epoch 39 | Batch 0/1169 | Loss: 0.0135
2026-01-11 15:31:14 | INFO | Epoch 39 | Batch 100/1169 | Loss: 0.0126
2026-01-11 15:31:16 | INFO | Epoch 39 | Batch 200/1169 | Loss: 0.0150
2026-01-11 15:31:18 | INFO | Epoch 39 | Batch 300/1169 | Loss: 0.0147
2026-01-11 15:31:20 | INFO | Epoch 39 | Batch 400/1169 | Loss: 0.0122
2026-01-11 15:31:22 | INFO | Epoch 39 | Batch 500/1169 | Loss: 0.0124
2026-01-11 15:31:24 | INFO | Epoch 39 | Batch 600/1169 | Loss: 0.0119
2026-01-11 15:31:26 | INFO | Epoch 39 | Batch 700/1169 | Loss: 0.0137
2026-01-11 15:31:28 | INFO | Epoch 39 | Batch 800/1169 | Loss: 0.0143
2026-01-11 15:31:30 | INFO | Epoch 39 | Batch 900/1169 | Loss: 0.0115
2026-01-11 15:31:33 | INFO | Epoch 39 | Batch 1000/1169 | Loss: 0.0135
2026-01-11 15:31:34 | INFO | Epoch 39 | Batch 1100/1169 | Loss: 0.0136
2026-01-11 15:31:38 | INFO | Epoch 39 | Train Loss: 0.0142 | Val Loss: 0.0184
2026-01-11 15:31:38 | INFO | Val F1: 0.4281 | Precision: 0.3067 | Recall: 0.7084
2026-01-11 15:31:38 | INFO | Epoch 40 | Batch 0/1169 | Loss: 0.0129
2026-01-11 15:31:40 | INFO | Epoch 40 | Batch 100/1169 | Loss: 0.0147
2026-01-11 15:31:42 | INFO | Epoch 40 | Batch 200/1169 | Loss: 0.0114
2026-01-11 15:31:44 | INFO | Epoch 40 | Batch 300/1169 | Loss: 0.0146
2026-01-11 15:31:46 | INFO | Epoch 40 | Batch 400/1169 | Loss: 0.0134
2026-01-11 15:31:48 | INFO | Epoch 40 | Batch 500/1169 | Loss: 0.0113
2026-01-11 15:31:50 | INFO | Epoch 40 | Batch 600/1169 | Loss: 0.0093
2026-01-11 15:31:52 | INFO | Epoch 40 | Batch 700/1169 | Loss: 0.0177
2026-01-11 15:31:55 | INFO | Epoch 40 | Batch 800/1169 | Loss: 0.0156
2026-01-11 15:31:57 | INFO | Epoch 40 | Batch 900/1169 | Loss: 0.0137
2026-01-11 15:32:00 | INFO | Epoch 40 | Batch 1000/1169 | Loss: 0.0167
2026-01-11 15:32:02 | INFO | Epoch 40 | Batch 1100/1169 | Loss: 0.0136
2026-01-11 15:32:06 | INFO | Epoch 40 | Train Loss: 0.0141 | Val Loss: 0.0189
2026-01-11 15:32:06 | INFO | Val F1: 0.4282 | Precision: 0.3068 | Recall: 0.7087
2026-01-11 15:32:06 | INFO | Epoch 41 | Batch 0/1169 | Loss: 0.0173
2026-01-11 15:32:08 | INFO | Epoch 41 | Batch 100/1169 | Loss: 0.0157
2026-01-11 15:32:10 | INFO | Epoch 41 | Batch 200/1169 | Loss: 0.0134
2026-01-11 15:32:12 | INFO | Epoch 41 | Batch 300/1169 | Loss: 0.0114
2026-01-11 15:32:14 | INFO | Epoch 41 | Batch 400/1169 | Loss: 0.0114
2026-01-11 15:32:16 | INFO | Epoch 41 | Batch 500/1169 | Loss: 0.0148
2026-01-11 15:32:19 | INFO | Epoch 41 | Batch 600/1169 | Loss: 0.0169
2026-01-11 15:32:21 | INFO | Epoch 41 | Batch 700/1169 | Loss: 0.0148
2026-01-11 15:32:23 | INFO | Epoch 41 | Batch 800/1169 | Loss: 0.0145
2026-01-11 15:32:25 | INFO | Epoch 41 | Batch 900/1169 | Loss: 0.0168
2026-01-11 15:32:27 | INFO | Epoch 41 | Batch 1000/1169 | Loss: 0.0146
2026-01-11 15:32:29 | INFO | Epoch 41 | Batch 1100/1169 | Loss: 0.0150
2026-01-11 15:32:33 | INFO | Epoch 41 | Train Loss: 0.0141 | Val Loss: 0.0189
2026-01-11 15:32:33 | INFO | Val F1: 0.4306 | Precision: 0.3099 | Recall: 0.7055
2026-01-11 15:32:33 | INFO | Epoch 42 | Batch 0/1169 | Loss: 0.0189
2026-01-11 15:32:36 | INFO | Epoch 42 | Batch 100/1169 | Loss: 0.0129
2026-01-11 15:32:38 | INFO | Epoch 42 | Batch 200/1169 | Loss: 0.0137
2026-01-11 15:32:41 | INFO | Epoch 42 | Batch 300/1169 | Loss: 0.0133
2026-01-11 15:32:44 | INFO | Epoch 42 | Batch 400/1169 | Loss: 0.0141
2026-01-11 15:32:46 | INFO | Epoch 42 | Batch 500/1169 | Loss: 0.0101
2026-01-11 15:32:48 | INFO | Epoch 42 | Batch 600/1169 | Loss: 0.0131
2026-01-11 15:32:50 | INFO | Epoch 42 | Batch 700/1169 | Loss: 0.0134
2026-01-11 15:32:53 | INFO | Epoch 42 | Batch 800/1169 | Loss: 0.0139
2026-01-11 15:32:55 | INFO | Epoch 42 | Batch 900/1169 | Loss: 0.0137
2026-01-11 15:32:57 | INFO | Epoch 42 | Batch 1000/1169 | Loss: 0.0147
2026-01-11 15:33:00 | INFO | Epoch 42 | Batch 1100/1169 | Loss: 0.0122
2026-01-11 15:33:03 | INFO | Epoch 42 | Train Loss: 0.0141 | Val Loss: 0.0184
2026-01-11 15:33:03 | INFO | Val F1: 0.4281 | Precision: 0.3078 | Recall: 0.7029
2026-01-11 15:33:03 | INFO | Epoch 43 | Batch 0/1169 | Loss: 0.0139
2026-01-11 15:33:05 | INFO | Epoch 43 | Batch 100/1169 | Loss: 0.0134
2026-01-11 15:33:07 | INFO | Epoch 43 | Batch 200/1169 | Loss: 0.0132
2026-01-11 15:33:09 | INFO | Epoch 43 | Batch 300/1169 | Loss: 0.0099
2026-01-11 15:33:11 | INFO | Epoch 43 | Batch 400/1169 | Loss: 0.0163
2026-01-11 15:33:13 | INFO | Epoch 43 | Batch 500/1169 | Loss: 0.0139
2026-01-11 15:33:15 | INFO | Epoch 43 | Batch 600/1169 | Loss: 0.0149
2026-01-11 15:33:18 | INFO | Epoch 43 | Batch 700/1169 | Loss: 0.0113
2026-01-11 15:33:20 | INFO | Epoch 43 | Batch 800/1169 | Loss: 0.0148
2026-01-11 15:33:23 | INFO | Epoch 43 | Batch 900/1169 | Loss: 0.0129
2026-01-11 15:33:25 | INFO | Epoch 43 | Batch 1000/1169 | Loss: 0.0136
2026-01-11 15:33:27 | INFO | Epoch 43 | Batch 1100/1169 | Loss: 0.0150
2026-01-11 15:33:30 | INFO | Epoch 43 | Train Loss: 0.0140 | Val Loss: 0.0188
2026-01-11 15:33:30 | INFO | Val F1: 0.4263 | Precision: 0.3050 | Recall: 0.7081
2026-01-11 15:33:30 | INFO | Epoch 44 | Batch 0/1169 | Loss: 0.0147
2026-01-11 15:33:32 | INFO | Epoch 44 | Batch 100/1169 | Loss: 0.0179
2026-01-11 15:33:34 | INFO | Epoch 44 | Batch 200/1169 | Loss: 0.0128
2026-01-11 15:33:37 | INFO | Epoch 44 | Batch 300/1169 | Loss: 0.0131
2026-01-11 15:33:39 | INFO | Epoch 44 | Batch 400/1169 | Loss: 0.0148
2026-01-11 15:33:41 | INFO | Epoch 44 | Batch 500/1169 | Loss: 0.0128
2026-01-11 15:33:44 | INFO | Epoch 44 | Batch 600/1169 | Loss: 0.0152
2026-01-11 15:33:46 | INFO | Epoch 44 | Batch 700/1169 | Loss: 0.0116
2026-01-11 15:33:48 | INFO | Epoch 44 | Batch 800/1169 | Loss: 0.0090
2026-01-11 15:33:50 | INFO | Epoch 44 | Batch 900/1169 | Loss: 0.0127
2026-01-11 15:33:52 | INFO | Epoch 44 | Batch 1000/1169 | Loss: 0.0139
2026-01-11 15:33:54 | INFO | Epoch 44 | Batch 1100/1169 | Loss: 0.0164
2026-01-11 15:33:58 | INFO | Epoch 44 | Train Loss: 0.0138 | Val Loss: 0.0181
2026-01-11 15:33:58 | INFO | Val F1: 0.4418 | Precision: 0.3233 | Recall: 0.6974
2026-01-11 15:33:58 | INFO | New best model saved (F1: 0.4418)
2026-01-11 15:33:58 | INFO | Epoch 45 | Batch 0/1169 | Loss: 0.0137
2026-01-11 15:34:00 | INFO | Epoch 45 | Batch 100/1169 | Loss: 0.0149
2026-01-11 15:34:03 | INFO | Epoch 45 | Batch 200/1169 | Loss: 0.0142
2026-01-11 15:34:04 | INFO | Epoch 45 | Batch 300/1169 | Loss: 0.0127
2026-01-11 15:34:07 | INFO | Epoch 45 | Batch 400/1169 | Loss: 0.0163
2026-01-11 15:34:09 | INFO | Epoch 45 | Batch 500/1169 | Loss: 0.0144
2026-01-11 15:34:11 | INFO | Epoch 45 | Batch 600/1169 | Loss: 0.0183
2026-01-11 15:34:13 | INFO | Epoch 45 | Batch 700/1169 | Loss: 0.0123
2026-01-11 15:34:15 | INFO | Epoch 45 | Batch 800/1169 | Loss: 0.0111
2026-01-11 15:34:17 | INFO | Epoch 45 | Batch 900/1169 | Loss: 0.0134
2026-01-11 15:34:19 | INFO | Epoch 45 | Batch 1000/1169 | Loss: 0.0155
2026-01-11 15:34:22 | INFO | Epoch 45 | Batch 1100/1169 | Loss: 0.0129
2026-01-11 15:34:25 | INFO | Epoch 45 | Train Loss: 0.0137 | Val Loss: 0.0188
2026-01-11 15:34:25 | INFO | Val F1: 0.4304 | Precision: 0.3097 | Recall: 0.7052
2026-01-11 15:34:25 | INFO | Epoch 46 | Batch 0/1169 | Loss: 0.0128
2026-01-11 15:34:27 | INFO | Epoch 46 | Batch 100/1169 | Loss: 0.0114
2026-01-11 15:34:30 | INFO | Epoch 46 | Batch 200/1169 | Loss: 0.0142
2026-01-11 15:34:32 | INFO | Epoch 46 | Batch 300/1169 | Loss: 0.0147
2026-01-11 15:34:35 | INFO | Epoch 46 | Batch 400/1169 | Loss: 0.0150
2026-01-11 15:34:37 | INFO | Epoch 46 | Batch 500/1169 | Loss: 0.0141
2026-01-11 15:34:39 | INFO | Epoch 46 | Batch 600/1169 | Loss: 0.0105
2026-01-11 15:34:41 | INFO | Epoch 46 | Batch 700/1169 | Loss: 0.0137
2026-01-11 15:34:44 | INFO | Epoch 46 | Batch 800/1169 | Loss: 0.0148
2026-01-11 15:34:46 | INFO | Epoch 46 | Batch 900/1169 | Loss: 0.0121
2026-01-11 15:34:48 | INFO | Epoch 46 | Batch 1000/1169 | Loss: 0.0107
2026-01-11 15:34:51 | INFO | Epoch 46 | Batch 1100/1169 | Loss: 0.0130
2026-01-11 15:34:54 | INFO | Epoch 46 | Train Loss: 0.0137 | Val Loss: 0.0187
2026-01-11 15:34:54 | INFO | Val F1: 0.4372 | Precision: 0.3198 | Recall: 0.6906
2026-01-11 15:34:54 | INFO | Epoch 47 | Batch 0/1169 | Loss: 0.0171
2026-01-11 15:34:56 | INFO | Epoch 47 | Batch 100/1169 | Loss: 0.0136
2026-01-11 15:34:58 | INFO | Epoch 47 | Batch 200/1169 | Loss: 0.0140
2026-01-11 15:35:00 | INFO | Epoch 47 | Batch 300/1169 | Loss: 0.0183
2026-01-11 15:35:02 | INFO | Epoch 47 | Batch 400/1169 | Loss: 0.0135
2026-01-11 15:35:04 | INFO | Epoch 47 | Batch 500/1169 | Loss: 0.0126
2026-01-11 15:35:06 | INFO | Epoch 47 | Batch 600/1169 | Loss: 0.0112
2026-01-11 15:35:08 | INFO | Epoch 47 | Batch 700/1169 | Loss: 0.0115
2026-01-11 15:35:10 | INFO | Epoch 47 | Batch 800/1169 | Loss: 0.0095
2026-01-11 15:35:12 | INFO | Epoch 47 | Batch 900/1169 | Loss: 0.0149
2026-01-11 15:35:14 | INFO | Epoch 47 | Batch 1000/1169 | Loss: 0.0124
2026-01-11 15:35:16 | INFO | Epoch 47 | Batch 1100/1169 | Loss: 0.0160
2026-01-11 15:35:20 | INFO | Epoch 47 | Train Loss: 0.0138 | Val Loss: 0.0190
2026-01-11 15:35:20 | INFO | Val F1: 0.4194 | Precision: 0.2976 | Recall: 0.7103
2026-01-11 15:35:20 | INFO | Epoch 48 | Batch 0/1169 | Loss: 0.0157
2026-01-11 15:35:22 | INFO | Epoch 48 | Batch 100/1169 | Loss: 0.0123
2026-01-11 15:35:24 | INFO | Epoch 48 | Batch 200/1169 | Loss: 0.0107
2026-01-11 15:35:26 | INFO | Epoch 48 | Batch 300/1169 | Loss: 0.0114
2026-01-11 15:35:28 | INFO | Epoch 48 | Batch 400/1169 | Loss: 0.0137
2026-01-11 15:35:31 | INFO | Epoch 48 | Batch 500/1169 | Loss: 0.0147
2026-01-11 15:35:33 | INFO | Epoch 48 | Batch 600/1169 | Loss: 0.0167
2026-01-11 15:35:35 | INFO | Epoch 48 | Batch 700/1169 | Loss: 0.0180
2026-01-11 15:35:38 | INFO | Epoch 48 | Batch 800/1169 | Loss: 0.0136
2026-01-11 15:35:40 | INFO | Epoch 48 | Batch 900/1169 | Loss: 0.0127
2026-01-11 15:35:43 | INFO | Epoch 48 | Batch 1000/1169 | Loss: 0.0124
2026-01-11 15:35:44 | INFO | Epoch 48 | Batch 1100/1169 | Loss: 0.0093
2026-01-11 15:35:48 | INFO | Epoch 48 | Train Loss: 0.0138 | Val Loss: 0.0184
2026-01-11 15:35:48 | INFO | Val F1: 0.4326 | Precision: 0.3129 | Recall: 0.7006
2026-01-11 15:35:48 | INFO | Epoch 49 | Batch 0/1169 | Loss: 0.0100
2026-01-11 15:35:50 | INFO | Epoch 49 | Batch 100/1169 | Loss: 0.0122
2026-01-11 15:35:52 | INFO | Epoch 49 | Batch 200/1169 | Loss: 0.0143
2026-01-11 15:35:54 | INFO | Epoch 49 | Batch 300/1169 | Loss: 0.0143
2026-01-11 15:35:56 | INFO | Epoch 49 | Batch 400/1169 | Loss: 0.0112
2026-01-11 15:35:59 | INFO | Epoch 49 | Batch 500/1169 | Loss: 0.0140
2026-01-11 15:36:01 | INFO | Epoch 49 | Batch 600/1169 | Loss: 0.0103
2026-01-11 15:36:03 | INFO | Epoch 49 | Batch 700/1169 | Loss: 0.0174
2026-01-11 15:36:05 | INFO | Epoch 49 | Batch 800/1169 | Loss: 0.0160
2026-01-11 15:36:07 | INFO | Epoch 49 | Batch 900/1169 | Loss: 0.0144
2026-01-11 15:36:10 | INFO | Epoch 49 | Batch 1000/1169 | Loss: 0.0169
2026-01-11 15:36:12 | INFO | Epoch 49 | Batch 1100/1169 | Loss: 0.0115
2026-01-11 15:36:15 | INFO | Epoch 49 | Train Loss: 0.0138 | Val Loss: 0.0189
2026-01-11 15:36:15 | INFO | Val F1: 0.4210 | Precision: 0.2982 | Recall: 0.7155
2026-01-11 15:36:15 | INFO | Epoch 50 | Batch 0/1169 | Loss: 0.0131
2026-01-11 15:36:17 | INFO | Epoch 50 | Batch 100/1169 | Loss: 0.0142
2026-01-11 15:36:19 | INFO | Epoch 50 | Batch 200/1169 | Loss: 0.0148
2026-01-11 15:36:21 | INFO | Epoch 50 | Batch 300/1169 | Loss: 0.0150
2026-01-11 15:36:24 | INFO | Epoch 50 | Batch 400/1169 | Loss: 0.0131
2026-01-11 15:36:25 | INFO | Epoch 50 | Batch 500/1169 | Loss: 0.0126
2026-01-11 15:36:28 | INFO | Epoch 50 | Batch 600/1169 | Loss: 0.0133
2026-01-11 15:36:30 | INFO | Epoch 50 | Batch 700/1169 | Loss: 0.0122
2026-01-11 15:36:32 | INFO | Epoch 50 | Batch 800/1169 | Loss: 0.0123
2026-01-11 15:36:34 | INFO | Epoch 50 | Batch 900/1169 | Loss: 0.0160
2026-01-11 15:36:36 | INFO | Epoch 50 | Batch 1000/1169 | Loss: 0.0134
2026-01-11 15:36:39 | INFO | Epoch 50 | Batch 1100/1169 | Loss: 0.0098
2026-01-11 15:36:42 | INFO | Epoch 50 | Train Loss: 0.0137 | Val Loss: 0.0189
2026-01-11 15:36:42 | INFO | Val F1: 0.4288 | Precision: 0.3066 | Recall: 0.7132
2026-01-11 15:36:42 | INFO | Epoch 51 | Batch 0/1169 | Loss: 0.0202
2026-01-11 15:36:45 | INFO | Epoch 51 | Batch 100/1169 | Loss: 0.0148
2026-01-11 15:36:47 | INFO | Epoch 51 | Batch 200/1169 | Loss: 0.0140
2026-01-11 15:36:49 | INFO | Epoch 51 | Batch 300/1169 | Loss: 0.0111
2026-01-11 15:36:51 | INFO | Epoch 51 | Batch 400/1169 | Loss: 0.0162
2026-01-11 15:36:53 | INFO | Epoch 51 | Batch 500/1169 | Loss: 0.0144
2026-01-11 15:36:55 | INFO | Epoch 51 | Batch 600/1169 | Loss: 0.0143
2026-01-11 15:36:58 | INFO | Epoch 51 | Batch 700/1169 | Loss: 0.0190
2026-01-11 15:37:00 | INFO | Epoch 51 | Batch 800/1169 | Loss: 0.0139
2026-01-11 15:37:02 | INFO | Epoch 51 | Batch 900/1169 | Loss: 0.0137
2026-01-11 15:37:05 | INFO | Epoch 51 | Batch 1000/1169 | Loss: 0.0134
2026-01-11 15:37:07 | INFO | Epoch 51 | Batch 1100/1169 | Loss: 0.0127
2026-01-11 15:37:10 | INFO | Epoch 51 | Train Loss: 0.0137 | Val Loss: 0.0187
2026-01-11 15:37:10 | INFO | Val F1: 0.4311 | Precision: 0.3107 | Recall: 0.7035
2026-01-11 15:37:10 | INFO | Epoch 52 | Batch 0/1169 | Loss: 0.0096
2026-01-11 15:37:12 | INFO | Epoch 52 | Batch 100/1169 | Loss: 0.0198
2026-01-11 15:37:14 | INFO | Epoch 52 | Batch 200/1169 | Loss: 0.0129
2026-01-11 15:37:16 | INFO | Epoch 52 | Batch 300/1169 | Loss: 0.0109
2026-01-11 15:37:18 | INFO | Epoch 52 | Batch 400/1169 | Loss: 0.0149
2026-01-11 15:37:21 | INFO | Epoch 52 | Batch 500/1169 | Loss: 0.0151
2026-01-11 15:37:23 | INFO | Epoch 52 | Batch 600/1169 | Loss: 0.0135
2026-01-11 15:37:25 | INFO | Epoch 52 | Batch 700/1169 | Loss: 0.0129
2026-01-11 15:37:28 | INFO | Epoch 52 | Batch 800/1169 | Loss: 0.0112
2026-01-11 15:37:30 | INFO | Epoch 52 | Batch 900/1169 | Loss: 0.0162
2026-01-11 15:37:32 | INFO | Epoch 52 | Batch 1000/1169 | Loss: 0.0138
2026-01-11 15:37:34 | INFO | Epoch 52 | Batch 1100/1169 | Loss: 0.0121
2026-01-11 15:37:38 | INFO | Epoch 52 | Train Loss: 0.0137 | Val Loss: 0.0189
2026-01-11 15:37:38 | INFO | Val F1: 0.4186 | Precision: 0.2969 | Recall: 0.7090
2026-01-11 15:37:38 | INFO | Epoch 53 | Batch 0/1169 | Loss: 0.0125
2026-01-11 15:37:41 | INFO | Epoch 53 | Batch 100/1169 | Loss: 0.0170
2026-01-11 15:37:43 | INFO | Epoch 53 | Batch 200/1169 | Loss: 0.0141
2026-01-11 15:37:45 | INFO | Epoch 53 | Batch 300/1169 | Loss: 0.0178
2026-01-11 15:37:47 | INFO | Epoch 53 | Batch 400/1169 | Loss: 0.0106
2026-01-11 15:37:49 | INFO | Epoch 53 | Batch 500/1169 | Loss: 0.0159
2026-01-11 15:37:51 | INFO | Epoch 53 | Batch 600/1169 | Loss: 0.0126
2026-01-11 15:37:53 | INFO | Epoch 53 | Batch 700/1169 | Loss: 0.0123
2026-01-11 15:37:56 | INFO | Epoch 53 | Batch 800/1169 | Loss: 0.0119
2026-01-11 15:37:58 | INFO | Epoch 53 | Batch 900/1169 | Loss: 0.0109
2026-01-11 15:38:00 | INFO | Epoch 53 | Batch 1000/1169 | Loss: 0.0143
2026-01-11 15:38:03 | INFO | Epoch 53 | Batch 1100/1169 | Loss: 0.0105
2026-01-11 15:38:06 | INFO | Epoch 53 | Train Loss: 0.0137 | Val Loss: 0.0189
2026-01-11 15:38:06 | INFO | Val F1: 0.4279 | Precision: 0.3068 | Recall: 0.7068
2026-01-11 15:38:06 | INFO | Epoch 54 | Batch 0/1169 | Loss: 0.0196
2026-01-11 15:38:09 | INFO | Epoch 54 | Batch 100/1169 | Loss: 0.0152
2026-01-11 15:38:11 | INFO | Epoch 54 | Batch 200/1169 | Loss: 0.0097
2026-01-11 15:38:13 | INFO | Epoch 54 | Batch 300/1169 | Loss: 0.0117
2026-01-11 15:38:15 | INFO | Epoch 54 | Batch 400/1169 | Loss: 0.0159
2026-01-11 15:38:17 | INFO | Epoch 54 | Batch 500/1169 | Loss: 0.0115
2026-01-11 15:38:19 | INFO | Epoch 54 | Batch 600/1169 | Loss: 0.0145
2026-01-11 15:38:21 | INFO | Epoch 54 | Batch 700/1169 | Loss: 0.0119
2026-01-11 15:38:24 | INFO | Epoch 54 | Batch 800/1169 | Loss: 0.0146
2026-01-11 15:38:26 | INFO | Epoch 54 | Batch 900/1169 | Loss: 0.0133
2026-01-11 15:38:28 | INFO | Epoch 54 | Batch 1000/1169 | Loss: 0.0157
2026-01-11 15:38:30 | INFO | Epoch 54 | Batch 1100/1169 | Loss: 0.0119
2026-01-11 15:38:33 | INFO | Epoch 54 | Train Loss: 0.0136 | Val Loss: 0.0187
2026-01-11 15:38:33 | INFO | Val F1: 0.4277 | Precision: 0.3064 | Recall: 0.7081
2026-01-11 15:38:33 | INFO | Early stopping at epoch 54
2026-01-11 15:38:36 | INFO | === Test Results ===
2026-01-11 15:38:36 | INFO | F1: 0.4483
2026-01-11 15:38:36 | INFO | Precision: 0.3288
2026-01-11 15:38:36 | INFO | Recall: 0.7041
2026-01-11 15:38:36 | INFO | AUC: 0.8260
