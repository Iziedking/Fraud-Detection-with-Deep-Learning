2026-01-28 16:00:04 | INFO | Starting Sequence LSTM training
2026-01-28 16:00:04 | INFO | Device: cpu
2026-01-28 16:00:11 | INFO | Train batches: 1105
2026-01-28 16:00:11 | INFO | Model parameters: 857,602
2026-01-28 16:00:17 | INFO | Epoch 1 | Batch 0/1105 | Loss: 0.0724
2026-01-28 16:00:35 | INFO | Epoch 1 | Batch 100/1105 | Loss: 0.0518
2026-01-28 16:00:53 | INFO | Epoch 1 | Batch 200/1105 | Loss: 0.0451
2026-01-28 16:01:11 | INFO | Epoch 1 | Batch 300/1105 | Loss: 0.0357
2026-01-28 16:01:29 | INFO | Epoch 1 | Batch 400/1105 | Loss: 0.0312
2026-01-28 16:01:45 | INFO | Epoch 1 | Batch 500/1105 | Loss: 0.0326
2026-01-28 16:01:58 | INFO | Epoch 1 | Batch 600/1105 | Loss: 0.0262
2026-01-28 16:02:11 | INFO | Epoch 1 | Batch 700/1105 | Loss: 0.0294
2026-01-28 16:02:23 | INFO | Epoch 1 | Batch 800/1105 | Loss: 0.0236
2026-01-28 16:02:36 | INFO | Epoch 1 | Batch 900/1105 | Loss: 0.0260
2026-01-28 16:02:49 | INFO | Epoch 1 | Batch 1000/1105 | Loss: 0.0250
2026-01-28 16:03:02 | INFO | Epoch 1 | Batch 1100/1105 | Loss: 0.0260
2026-01-28 16:03:10 | INFO | Epoch 1 | Train Loss: 0.0339 | Val Loss: 0.0257
2026-01-28 16:03:10 | INFO | Val F1: 0.2257 | Prec: 0.1522 | Rec: 0.4367 | AUC: 0.7650
2026-01-28 16:03:10 | INFO | New best model saved (F1: 0.2257)
2026-01-28 16:03:10 | INFO | Epoch 2 | Batch 0/1105 | Loss: 0.0167
2026-01-28 16:03:23 | INFO | Epoch 2 | Batch 100/1105 | Loss: 0.0227
2026-01-28 16:03:36 | INFO | Epoch 2 | Batch 200/1105 | Loss: 0.0200
2026-01-28 16:03:49 | INFO | Epoch 2 | Batch 300/1105 | Loss: 0.0224
2026-01-28 16:04:01 | INFO | Epoch 2 | Batch 400/1105 | Loss: 0.0298
2026-01-28 16:04:14 | INFO | Epoch 2 | Batch 500/1105 | Loss: 0.0218
2026-01-28 16:04:27 | INFO | Epoch 2 | Batch 600/1105 | Loss: 0.0234
2026-01-28 16:04:40 | INFO | Epoch 2 | Batch 700/1105 | Loss: 0.0259
2026-01-28 16:04:53 | INFO | Epoch 2 | Batch 800/1105 | Loss: 0.0213
2026-01-28 16:05:06 | INFO | Epoch 2 | Batch 900/1105 | Loss: 0.0207
2026-01-28 16:05:19 | INFO | Epoch 2 | Batch 1000/1105 | Loss: 0.0205
2026-01-28 16:05:31 | INFO | Epoch 2 | Batch 1100/1105 | Loss: 0.0194
2026-01-28 16:05:39 | INFO | Epoch 2 | Train Loss: 0.0207 | Val Loss: 0.0246
2026-01-28 16:05:39 | INFO | Val F1: 0.2639 | Prec: 0.2019 | Rec: 0.3810 | AUC: 0.7781
2026-01-28 16:05:39 | INFO | New best model saved (F1: 0.2639)
2026-01-28 16:05:39 | INFO | Epoch 3 | Batch 0/1105 | Loss: 0.0168
2026-01-28 16:05:56 | INFO | Epoch 3 | Batch 100/1105 | Loss: 0.0144
2026-01-28 16:06:14 | INFO | Epoch 3 | Batch 200/1105 | Loss: 0.0121
2026-01-28 16:06:33 | INFO | Epoch 3 | Batch 300/1105 | Loss: 0.0173
2026-01-28 16:06:48 | INFO | Epoch 3 | Batch 400/1105 | Loss: 0.0217
2026-01-28 16:07:02 | INFO | Epoch 3 | Batch 500/1105 | Loss: 0.0119
2026-01-28 16:07:15 | INFO | Epoch 3 | Batch 600/1105 | Loss: 0.0173
2026-01-28 16:07:28 | INFO | Epoch 3 | Batch 700/1105 | Loss: 0.0232
2026-01-28 16:07:41 | INFO | Epoch 3 | Batch 800/1105 | Loss: 0.0222
2026-01-28 16:07:53 | INFO | Epoch 3 | Batch 900/1105 | Loss: 0.0128
2026-01-28 16:08:06 | INFO | Epoch 3 | Batch 1000/1105 | Loss: 0.0140
2026-01-28 16:08:19 | INFO | Epoch 3 | Batch 1100/1105 | Loss: 0.0193
2026-01-28 16:08:27 | INFO | Epoch 3 | Train Loss: 0.0162 | Val Loss: 0.0307
2026-01-28 16:08:27 | INFO | Val F1: 0.2648 | Prec: 0.1907 | Rec: 0.4330 | AUC: 0.7748
2026-01-28 16:08:27 | INFO | New best model saved (F1: 0.2648)
2026-01-28 16:08:27 | INFO | Epoch 4 | Batch 0/1105 | Loss: 0.0150
2026-01-28 16:08:45 | INFO | Epoch 4 | Batch 100/1105 | Loss: 0.0146
2026-01-28 16:09:00 | INFO | Epoch 4 | Batch 200/1105 | Loss: 0.0082
2026-01-28 16:09:13 | INFO | Epoch 4 | Batch 300/1105 | Loss: 0.0177
2026-01-28 16:09:26 | INFO | Epoch 4 | Batch 400/1105 | Loss: 0.0128
2026-01-28 16:09:39 | INFO | Epoch 4 | Batch 500/1105 | Loss: 0.0131
2026-01-28 16:09:52 | INFO | Epoch 4 | Batch 600/1105 | Loss: 0.0099
2026-01-28 16:10:06 | INFO | Epoch 4 | Batch 700/1105 | Loss: 0.0145
2026-01-28 16:10:18 | INFO | Epoch 4 | Batch 800/1105 | Loss: 0.0176
2026-01-28 16:10:30 | INFO | Epoch 4 | Batch 900/1105 | Loss: 0.0126
2026-01-28 16:10:38 | INFO | Epoch 4 | Batch 1000/1105 | Loss: 0.0135
2026-01-28 16:10:46 | INFO | Epoch 4 | Batch 1100/1105 | Loss: 0.0141
2026-01-28 16:10:50 | INFO | Epoch 4 | Train Loss: 0.0131 | Val Loss: 0.0274
2026-01-28 16:10:50 | INFO | Val F1: 0.2469 | Prec: 0.1868 | Rec: 0.3642 | AUC: 0.7749
2026-01-28 16:10:50 | INFO | Epoch 5 | Batch 0/1105 | Loss: 0.0125
2026-01-28 16:10:56 | INFO | Epoch 5 | Batch 100/1105 | Loss: 0.0104
2026-01-28 16:11:03 | INFO | Epoch 5 | Batch 200/1105 | Loss: 0.0135
2026-01-28 16:11:10 | INFO | Epoch 5 | Batch 300/1105 | Loss: 0.0117
2026-01-28 16:11:16 | INFO | Epoch 5 | Batch 400/1105 | Loss: 0.0112
2026-01-28 16:11:23 | INFO | Epoch 5 | Batch 500/1105 | Loss: 0.0088
2026-01-28 16:11:31 | INFO | Epoch 5 | Batch 600/1105 | Loss: 0.0108
2026-01-28 16:11:38 | INFO | Epoch 5 | Batch 700/1105 | Loss: 0.0135
2026-01-28 16:11:46 | INFO | Epoch 5 | Batch 800/1105 | Loss: 0.0097
2026-01-28 16:11:55 | INFO | Epoch 5 | Batch 900/1105 | Loss: 0.0142
2026-01-28 16:12:03 | INFO | Epoch 5 | Batch 1000/1105 | Loss: 0.0096
2026-01-28 16:12:11 | INFO | Epoch 5 | Batch 1100/1105 | Loss: 0.0103
2026-01-28 16:12:16 | INFO | Epoch 5 | Train Loss: 0.0110 | Val Loss: 0.0332
2026-01-28 16:12:16 | INFO | Val F1: 0.2471 | Prec: 0.2005 | Rec: 0.3219 | AUC: 0.7616
2026-01-28 16:12:16 | INFO | Epoch 6 | Batch 0/1105 | Loss: 0.0095
2026-01-28 16:12:24 | INFO | Epoch 6 | Batch 100/1105 | Loss: 0.0072
2026-01-28 16:12:31 | INFO | Epoch 6 | Batch 200/1105 | Loss: 0.0135
2026-01-28 16:12:39 | INFO | Epoch 6 | Batch 300/1105 | Loss: 0.0115
2026-01-28 16:12:47 | INFO | Epoch 6 | Batch 400/1105 | Loss: 0.0080
2026-01-28 16:12:54 | INFO | Epoch 6 | Batch 500/1105 | Loss: 0.0084
2026-01-28 16:13:02 | INFO | Epoch 6 | Batch 600/1105 | Loss: 0.0140
2026-01-28 16:13:10 | INFO | Epoch 6 | Batch 700/1105 | Loss: 0.0102
2026-01-28 16:13:18 | INFO | Epoch 6 | Batch 800/1105 | Loss: 0.0078
2026-01-28 16:13:26 | INFO | Epoch 6 | Batch 900/1105 | Loss: 0.0085
2026-01-28 16:13:33 | INFO | Epoch 6 | Batch 1000/1105 | Loss: 0.0099
2026-01-28 16:13:41 | INFO | Epoch 6 | Batch 1100/1105 | Loss: 0.0085
2026-01-28 16:13:46 | INFO | Epoch 6 | Train Loss: 0.0094 | Val Loss: 0.0420
2026-01-28 16:13:46 | INFO | Val F1: 0.2905 | Prec: 0.2563 | Rec: 0.3353 | AUC: 0.7866
2026-01-28 16:13:46 | INFO | New best model saved (F1: 0.2905)
2026-01-28 16:13:46 | INFO | Epoch 7 | Batch 0/1105 | Loss: 0.0050
2026-01-28 16:13:53 | INFO | Epoch 7 | Batch 100/1105 | Loss: 0.0060
2026-01-28 16:14:01 | INFO | Epoch 7 | Batch 200/1105 | Loss: 0.0091
2026-01-28 16:14:09 | INFO | Epoch 7 | Batch 300/1105 | Loss: 0.0075
2026-01-28 16:14:17 | INFO | Epoch 7 | Batch 400/1105 | Loss: 0.0095
2026-01-28 16:14:25 | INFO | Epoch 7 | Batch 500/1105 | Loss: 0.0100
2026-01-28 16:14:33 | INFO | Epoch 7 | Batch 600/1105 | Loss: 0.0092
2026-01-28 16:14:41 | INFO | Epoch 7 | Batch 700/1105 | Loss: 0.0076
2026-01-28 16:14:49 | INFO | Epoch 7 | Batch 800/1105 | Loss: 0.0072
2026-01-28 16:14:57 | INFO | Epoch 7 | Batch 900/1105 | Loss: 0.0088
2026-01-28 16:15:05 | INFO | Epoch 7 | Batch 1000/1105 | Loss: 0.0072
2026-01-28 16:15:14 | INFO | Epoch 7 | Batch 1100/1105 | Loss: 0.0094
2026-01-28 16:15:19 | INFO | Epoch 7 | Train Loss: 0.0083 | Val Loss: 0.0378
2026-01-28 16:15:19 | INFO | Val F1: 0.2784 | Prec: 0.2143 | Rec: 0.3971 | AUC: 0.7783
2026-01-28 16:15:19 | INFO | Epoch 8 | Batch 0/1105 | Loss: 0.0058
2026-01-28 16:15:30 | INFO | Epoch 8 | Batch 100/1105 | Loss: 0.0054
2026-01-28 16:15:41 | INFO | Epoch 8 | Batch 200/1105 | Loss: 0.0066
2026-01-28 16:15:52 | INFO | Epoch 8 | Batch 300/1105 | Loss: 0.0081
2026-01-28 16:16:04 | INFO | Epoch 8 | Batch 400/1105 | Loss: 0.0047
2026-01-28 16:16:15 | INFO | Epoch 8 | Batch 500/1105 | Loss: 0.0133
2026-01-28 16:16:26 | INFO | Epoch 8 | Batch 600/1105 | Loss: 0.0059
2026-01-28 16:16:35 | INFO | Epoch 8 | Batch 700/1105 | Loss: 0.0067
2026-01-28 16:16:43 | INFO | Epoch 8 | Batch 800/1105 | Loss: 0.0065
2026-01-28 16:16:51 | INFO | Epoch 8 | Batch 900/1105 | Loss: 0.0082
2026-01-28 16:16:59 | INFO | Epoch 8 | Batch 1000/1105 | Loss: 0.0057
2026-01-28 16:17:07 | INFO | Epoch 8 | Batch 1100/1105 | Loss: 0.0126
2026-01-28 16:17:13 | INFO | Epoch 8 | Train Loss: 0.0074 | Val Loss: 0.0423
2026-01-28 16:17:13 | INFO | Val F1: 0.2680 | Prec: 0.2004 | Rec: 0.4045 | AUC: 0.7831
2026-01-28 16:17:13 | INFO | Epoch 9 | Batch 0/1105 | Loss: 0.0049
2026-01-28 16:17:21 | INFO | Epoch 9 | Batch 100/1105 | Loss: 0.0037
2026-01-28 16:17:29 | INFO | Epoch 9 | Batch 200/1105 | Loss: 0.0037
2026-01-28 16:17:37 | INFO | Epoch 9 | Batch 300/1105 | Loss: 0.0026
2026-01-28 16:17:45 | INFO | Epoch 9 | Batch 400/1105 | Loss: 0.0039
2026-01-28 16:17:53 | INFO | Epoch 9 | Batch 500/1105 | Loss: 0.0040
2026-01-28 16:18:02 | INFO | Epoch 9 | Batch 600/1105 | Loss: 0.0049
2026-01-28 16:18:10 | INFO | Epoch 9 | Batch 700/1105 | Loss: 0.0050
2026-01-28 16:18:18 | INFO | Epoch 9 | Batch 800/1105 | Loss: 0.0041
2026-01-28 16:18:27 | INFO | Epoch 9 | Batch 900/1105 | Loss: 0.0035
2026-01-28 16:18:35 | INFO | Epoch 9 | Batch 1000/1105 | Loss: 0.0032
2026-01-28 16:18:43 | INFO | Epoch 9 | Batch 1100/1105 | Loss: 0.0039
2026-01-28 16:18:48 | INFO | Epoch 9 | Train Loss: 0.0047 | Val Loss: 0.0661
2026-01-28 16:18:48 | INFO | Val F1: 0.2867 | Prec: 0.2503 | Rec: 0.3357 | AUC: 0.7899
2026-01-28 16:18:48 | INFO | Epoch 10 | Batch 0/1105 | Loss: 0.0026
2026-01-28 16:18:57 | INFO | Epoch 10 | Batch 100/1105 | Loss: 0.0038
2026-01-28 16:19:05 | INFO | Epoch 10 | Batch 200/1105 | Loss: 0.0028
2026-01-28 16:19:14 | INFO | Epoch 10 | Batch 300/1105 | Loss: 0.0024
2026-01-28 16:19:22 | INFO | Epoch 10 | Batch 400/1105 | Loss: 0.0060
2026-01-28 16:19:30 | INFO | Epoch 10 | Batch 500/1105 | Loss: 0.0030
2026-01-28 16:19:38 | INFO | Epoch 10 | Batch 600/1105 | Loss: 0.0056
2026-01-28 16:19:47 | INFO | Epoch 10 | Batch 700/1105 | Loss: 0.0042
2026-01-28 16:19:55 | INFO | Epoch 10 | Batch 800/1105 | Loss: 0.0020
2026-01-28 16:20:04 | INFO | Epoch 10 | Batch 900/1105 | Loss: 0.0033
2026-01-28 16:20:12 | INFO | Epoch 10 | Batch 1000/1105 | Loss: 0.0037
2026-01-28 16:20:20 | INFO | Epoch 10 | Batch 1100/1105 | Loss: 0.0034
2026-01-28 16:20:26 | INFO | Epoch 10 | Train Loss: 0.0040 | Val Loss: 0.0736
2026-01-28 16:20:26 | INFO | Val F1: 0.2765 | Prec: 0.2441 | Rec: 0.3189 | AUC: 0.7814
2026-01-28 16:20:26 | INFO | Epoch 11 | Batch 0/1105 | Loss: 0.0033
2026-01-28 16:20:34 | INFO | Epoch 11 | Batch 100/1105 | Loss: 0.0035
2026-01-28 16:20:42 | INFO | Epoch 11 | Batch 200/1105 | Loss: 0.0019
2026-01-28 16:20:51 | INFO | Epoch 11 | Batch 300/1105 | Loss: 0.0047
2026-01-28 16:20:59 | INFO | Epoch 11 | Batch 400/1105 | Loss: 0.0020
2026-01-28 16:21:07 | INFO | Epoch 11 | Batch 500/1105 | Loss: 0.0041
2026-01-28 16:21:16 | INFO | Epoch 11 | Batch 600/1105 | Loss: 0.0049
2026-01-28 16:21:24 | INFO | Epoch 11 | Batch 700/1105 | Loss: 0.0023
2026-01-28 16:21:32 | INFO | Epoch 11 | Batch 800/1105 | Loss: 0.0072
2026-01-28 16:21:41 | INFO | Epoch 11 | Batch 900/1105 | Loss: 0.0028
2026-01-28 16:21:49 | INFO | Epoch 11 | Batch 1000/1105 | Loss: 0.0022
2026-01-28 16:21:57 | INFO | Epoch 11 | Batch 1100/1105 | Loss: 0.0040
2026-01-28 16:22:02 | INFO | Epoch 11 | Train Loss: 0.0036 | Val Loss: 0.0765
2026-01-28 16:22:02 | INFO | Val F1: 0.2895 | Prec: 0.2692 | Rec: 0.3132 | AUC: 0.7858
2026-01-28 16:22:03 | INFO | Epoch 12 | Batch 0/1105 | Loss: 0.0032
2026-01-28 16:22:11 | INFO | Epoch 12 | Batch 100/1105 | Loss: 0.0032
2026-01-28 16:22:19 | INFO | Epoch 12 | Batch 200/1105 | Loss: 0.0035
2026-01-28 16:22:27 | INFO | Epoch 12 | Batch 300/1105 | Loss: 0.0031
2026-01-28 16:22:36 | INFO | Epoch 12 | Batch 400/1105 | Loss: 0.0033
2026-01-28 16:22:44 | INFO | Epoch 12 | Batch 500/1105 | Loss: 0.0022
2026-01-28 16:22:52 | INFO | Epoch 12 | Batch 600/1105 | Loss: 0.0044
2026-01-28 16:23:01 | INFO | Epoch 12 | Batch 700/1105 | Loss: 0.0026
2026-01-28 16:23:09 | INFO | Epoch 12 | Batch 800/1105 | Loss: 0.0039
2026-01-28 16:23:17 | INFO | Epoch 12 | Batch 900/1105 | Loss: 0.0038
2026-01-28 16:23:26 | INFO | Epoch 12 | Batch 1000/1105 | Loss: 0.0016
2026-01-28 16:23:34 | INFO | Epoch 12 | Batch 1100/1105 | Loss: 0.0042
2026-01-28 16:23:40 | INFO | Epoch 12 | Train Loss: 0.0034 | Val Loss: 0.0737
2026-01-28 16:23:40 | INFO | Val F1: 0.2744 | Prec: 0.2275 | Rec: 0.3458 | AUC: 0.7800
2026-01-28 16:23:40 | INFO | Epoch 13 | Batch 0/1105 | Loss: 0.0033
2026-01-28 16:23:48 | INFO | Epoch 13 | Batch 100/1105 | Loss: 0.0027
2026-01-28 16:23:56 | INFO | Epoch 13 | Batch 200/1105 | Loss: 0.0019
2026-01-28 16:24:05 | INFO | Epoch 13 | Batch 300/1105 | Loss: 0.0031
2026-01-28 16:24:13 | INFO | Epoch 13 | Batch 400/1105 | Loss: 0.0025
2026-01-28 16:24:21 | INFO | Epoch 13 | Batch 500/1105 | Loss: 0.0037
2026-01-28 16:24:29 | INFO | Epoch 13 | Batch 600/1105 | Loss: 0.0036
2026-01-28 16:24:38 | INFO | Epoch 13 | Batch 700/1105 | Loss: 0.0063
2026-01-28 16:24:46 | INFO | Epoch 13 | Batch 800/1105 | Loss: 0.0030
2026-01-28 16:24:54 | INFO | Epoch 13 | Batch 900/1105 | Loss: 0.0042
2026-01-28 16:25:03 | INFO | Epoch 13 | Batch 1000/1105 | Loss: 0.0027
2026-01-28 16:25:11 | INFO | Epoch 13 | Batch 1100/1105 | Loss: 0.0050
2026-01-28 16:25:16 | INFO | Epoch 13 | Train Loss: 0.0032 | Val Loss: 0.0768
2026-01-28 16:25:16 | INFO | Val F1: 0.2879 | Prec: 0.2552 | Rec: 0.3303 | AUC: 0.7845
2026-01-28 16:25:16 | INFO | Epoch 14 | Batch 0/1105 | Loss: 0.0022
2026-01-28 16:25:25 | INFO | Epoch 14 | Batch 100/1105 | Loss: 0.0037
2026-01-28 16:25:33 | INFO | Epoch 14 | Batch 200/1105 | Loss: 0.0023
2026-01-28 16:25:41 | INFO | Epoch 14 | Batch 300/1105 | Loss: 0.0018
2026-01-28 16:25:49 | INFO | Epoch 14 | Batch 400/1105 | Loss: 0.0037
2026-01-28 16:25:58 | INFO | Epoch 14 | Batch 500/1105 | Loss: 0.0025
2026-01-28 16:26:06 | INFO | Epoch 14 | Batch 600/1105 | Loss: 0.0022
2026-01-28 16:26:15 | INFO | Epoch 14 | Batch 700/1105 | Loss: 0.0022
2026-01-28 16:26:23 | INFO | Epoch 14 | Batch 800/1105 | Loss: 0.0015
2026-01-28 16:26:31 | INFO | Epoch 14 | Batch 900/1105 | Loss: 0.0020
2026-01-28 16:26:39 | INFO | Epoch 14 | Batch 1000/1105 | Loss: 0.0021
2026-01-28 16:26:47 | INFO | Epoch 14 | Batch 1100/1105 | Loss: 0.0059
2026-01-28 16:26:52 | INFO | Epoch 14 | Train Loss: 0.0030 | Val Loss: 0.0773
2026-01-28 16:26:52 | INFO | Val F1: 0.2869 | Prec: 0.2576 | Rec: 0.3236 | AUC: 0.7860
2026-01-28 16:26:53 | INFO | Epoch 15 | Batch 0/1105 | Loss: 0.0026
2026-01-28 16:27:01 | INFO | Epoch 15 | Batch 100/1105 | Loss: 0.0026
2026-01-28 16:27:09 | INFO | Epoch 15 | Batch 200/1105 | Loss: 0.0020
2026-01-28 16:27:18 | INFO | Epoch 15 | Batch 300/1105 | Loss: 0.0027
2026-01-28 16:27:26 | INFO | Epoch 15 | Batch 400/1105 | Loss: 0.0034
2026-01-28 16:27:34 | INFO | Epoch 15 | Batch 500/1105 | Loss: 0.0019
2026-01-28 16:27:43 | INFO | Epoch 15 | Batch 600/1105 | Loss: 0.0013
2026-01-28 16:27:51 | INFO | Epoch 15 | Batch 700/1105 | Loss: 0.0012
2026-01-28 16:27:59 | INFO | Epoch 15 | Batch 800/1105 | Loss: 0.0023
2026-01-28 16:28:07 | INFO | Epoch 15 | Batch 900/1105 | Loss: 0.0019
2026-01-28 16:28:16 | INFO | Epoch 15 | Batch 1000/1105 | Loss: 0.0015
2026-01-28 16:28:24 | INFO | Epoch 15 | Batch 1100/1105 | Loss: 0.0020
2026-01-28 16:28:29 | INFO | Epoch 15 | Train Loss: 0.0019 | Val Loss: 0.1013
2026-01-28 16:28:29 | INFO | Val F1: 0.2940 | Prec: 0.2854 | Rec: 0.3031 | AUC: 0.7902
2026-01-28 16:28:29 | INFO | New best model saved (F1: 0.2940)
2026-01-28 16:28:29 | INFO | Epoch 16 | Batch 0/1105 | Loss: 0.0008
2026-01-28 16:28:38 | INFO | Epoch 16 | Batch 100/1105 | Loss: 0.0023
2026-01-28 16:28:46 | INFO | Epoch 16 | Batch 200/1105 | Loss: 0.0010
2026-01-28 16:28:55 | INFO | Epoch 16 | Batch 300/1105 | Loss: 0.0013
2026-01-28 16:29:03 | INFO | Epoch 16 | Batch 400/1105 | Loss: 0.0010
2026-01-28 16:29:11 | INFO | Epoch 16 | Batch 500/1105 | Loss: 0.0018
2026-01-28 16:29:20 | INFO | Epoch 16 | Batch 600/1105 | Loss: 0.0008
2026-01-28 16:29:28 | INFO | Epoch 16 | Batch 700/1105 | Loss: 0.0035
2026-01-28 16:29:37 | INFO | Epoch 16 | Batch 800/1105 | Loss: 0.0016
2026-01-28 16:29:45 | INFO | Epoch 16 | Batch 900/1105 | Loss: 0.0008
2026-01-28 16:29:54 | INFO | Epoch 16 | Batch 1000/1105 | Loss: 0.0022
2026-01-28 16:30:02 | INFO | Epoch 16 | Batch 1100/1105 | Loss: 0.0017
2026-01-28 16:30:07 | INFO | Epoch 16 | Train Loss: 0.0016 | Val Loss: 0.1157
2026-01-28 16:30:07 | INFO | Val F1: 0.2937 | Prec: 0.2882 | Rec: 0.2994 | AUC: 0.7846
2026-01-28 16:30:07 | INFO | Epoch 17 | Batch 0/1105 | Loss: 0.0027
2026-01-28 16:30:16 | INFO | Epoch 17 | Batch 100/1105 | Loss: 0.0015
2026-01-28 16:30:25 | INFO | Epoch 17 | Batch 200/1105 | Loss: 0.0006
2026-01-28 16:30:33 | INFO | Epoch 17 | Batch 300/1105 | Loss: 0.0008
2026-01-28 16:30:41 | INFO | Epoch 17 | Batch 400/1105 | Loss: 0.0013
2026-01-28 16:30:50 | INFO | Epoch 17 | Batch 500/1105 | Loss: 0.0009
2026-01-28 16:30:58 | INFO | Epoch 17 | Batch 600/1105 | Loss: 0.0010
2026-01-28 16:31:06 | INFO | Epoch 17 | Batch 700/1105 | Loss: 0.0004
2026-01-28 16:31:15 | INFO | Epoch 17 | Batch 800/1105 | Loss: 0.0025
2026-01-28 16:31:23 | INFO | Epoch 17 | Batch 900/1105 | Loss: 0.0007
2026-01-28 16:31:31 | INFO | Epoch 17 | Batch 1000/1105 | Loss: 0.0019
2026-01-28 16:31:40 | INFO | Epoch 17 | Batch 1100/1105 | Loss: 0.0016
2026-01-28 16:31:45 | INFO | Epoch 17 | Train Loss: 0.0016 | Val Loss: 0.1209
2026-01-28 16:31:45 | INFO | Val F1: 0.2793 | Prec: 0.2576 | Rec: 0.3051 | AUC: 0.7743
2026-01-28 16:31:45 | INFO | Epoch 18 | Batch 0/1105 | Loss: 0.0011
2026-01-28 16:31:53 | INFO | Epoch 18 | Batch 100/1105 | Loss: 0.0023
2026-01-28 16:32:02 | INFO | Epoch 18 | Batch 200/1105 | Loss: 0.0011
2026-01-28 16:32:10 | INFO | Epoch 18 | Batch 300/1105 | Loss: 0.0010
2026-01-28 16:32:25 | INFO | Epoch 18 | Batch 400/1105 | Loss: 0.0005
2026-01-28 16:32:37 | INFO | Epoch 18 | Batch 500/1105 | Loss: 0.0014
2026-01-28 16:32:52 | INFO | Epoch 18 | Batch 600/1105 | Loss: 0.0019
2026-01-28 16:33:07 | INFO | Epoch 18 | Batch 700/1105 | Loss: 0.0009
2026-01-28 16:33:24 | INFO | Epoch 18 | Batch 800/1105 | Loss: 0.0018
2026-01-28 16:33:40 | INFO | Epoch 18 | Batch 900/1105 | Loss: 0.0009
2026-01-28 16:33:51 | INFO | Epoch 18 | Batch 1000/1105 | Loss: 0.0002
2026-01-28 16:34:04 | INFO | Epoch 18 | Batch 1100/1105 | Loss: 0.0011
2026-01-28 16:34:11 | INFO | Epoch 18 | Train Loss: 0.0014 | Val Loss: 0.1313
2026-01-28 16:34:11 | INFO | Val F1: 0.2902 | Prec: 0.2982 | Rec: 0.2826 | AUC: 0.7839
2026-01-28 16:34:11 | INFO | Epoch 19 | Batch 0/1105 | Loss: 0.0010
2026-01-28 16:34:22 | INFO | Epoch 19 | Batch 100/1105 | Loss: 0.0018
2026-01-28 16:34:30 | INFO | Epoch 19 | Batch 200/1105 | Loss: 0.0013
2026-01-28 16:34:39 | INFO | Epoch 19 | Batch 300/1105 | Loss: 0.0005
2026-01-28 16:34:47 | INFO | Epoch 19 | Batch 400/1105 | Loss: 0.0008
2026-01-28 16:34:54 | INFO | Epoch 19 | Batch 500/1105 | Loss: 0.0011
2026-01-28 16:35:02 | INFO | Epoch 19 | Batch 600/1105 | Loss: 0.0009
2026-01-28 16:35:10 | INFO | Epoch 19 | Batch 700/1105 | Loss: 0.0017
2026-01-28 16:35:19 | INFO | Epoch 19 | Batch 800/1105 | Loss: 0.0005
2026-01-28 16:35:27 | INFO | Epoch 19 | Batch 900/1105 | Loss: 0.0014
2026-01-28 16:35:35 | INFO | Epoch 19 | Batch 1000/1105 | Loss: 0.0016
2026-01-28 16:35:42 | INFO | Epoch 19 | Batch 1100/1105 | Loss: 0.0006
2026-01-28 16:35:47 | INFO | Epoch 19 | Train Loss: 0.0014 | Val Loss: 0.1165
2026-01-28 16:35:47 | INFO | Val F1: 0.2909 | Prec: 0.2814 | Rec: 0.3011 | AUC: 0.7872
2026-01-28 16:35:47 | INFO | Epoch 20 | Batch 0/1105 | Loss: 0.0007
2026-01-28 16:35:55 | INFO | Epoch 20 | Batch 100/1105 | Loss: 0.0020
2026-01-28 16:36:03 | INFO | Epoch 20 | Batch 200/1105 | Loss: 0.0021
2026-01-28 16:36:11 | INFO | Epoch 20 | Batch 300/1105 | Loss: 0.0011
2026-01-28 16:36:19 | INFO | Epoch 20 | Batch 400/1105 | Loss: 0.0011
2026-01-28 16:36:27 | INFO | Epoch 20 | Batch 500/1105 | Loss: 0.0015
2026-01-28 16:36:35 | INFO | Epoch 20 | Batch 600/1105 | Loss: 0.0003
2026-01-28 16:36:43 | INFO | Epoch 20 | Batch 700/1105 | Loss: 0.0017
2026-01-28 16:36:51 | INFO | Epoch 20 | Batch 800/1105 | Loss: 0.0011
2026-01-28 16:36:59 | INFO | Epoch 20 | Batch 900/1105 | Loss: 0.0028
2026-01-28 16:37:07 | INFO | Epoch 20 | Batch 1000/1105 | Loss: 0.0047
2026-01-28 16:37:15 | INFO | Epoch 20 | Batch 1100/1105 | Loss: 0.0013
2026-01-28 16:37:20 | INFO | Epoch 20 | Train Loss: 0.0013 | Val Loss: 0.1343
2026-01-28 16:37:20 | INFO | Val F1: 0.2867 | Prec: 0.2892 | Rec: 0.2843 | AUC: 0.7817
2026-01-28 16:37:20 | INFO | Epoch 21 | Batch 0/1105 | Loss: 0.0008
2026-01-28 16:37:28 | INFO | Epoch 21 | Batch 100/1105 | Loss: 0.0010
2026-01-28 16:37:36 | INFO | Epoch 21 | Batch 200/1105 | Loss: 0.0009
2026-01-28 16:37:44 | INFO | Epoch 21 | Batch 300/1105 | Loss: 0.0013
2026-01-28 16:37:52 | INFO | Epoch 21 | Batch 400/1105 | Loss: 0.0010
2026-01-28 16:38:00 | INFO | Epoch 21 | Batch 500/1105 | Loss: 0.0003
2026-01-28 16:38:09 | INFO | Epoch 21 | Batch 600/1105 | Loss: 0.0003
2026-01-28 16:38:17 | INFO | Epoch 21 | Batch 700/1105 | Loss: 0.0011
2026-01-28 16:38:25 | INFO | Epoch 21 | Batch 800/1105 | Loss: 0.0009
2026-01-28 16:38:34 | INFO | Epoch 21 | Batch 900/1105 | Loss: 0.0006
2026-01-28 16:38:42 | INFO | Epoch 21 | Batch 1000/1105 | Loss: 0.0005
2026-01-28 16:38:50 | INFO | Epoch 21 | Batch 1100/1105 | Loss: 0.0008
2026-01-28 16:38:56 | INFO | Epoch 21 | Train Loss: 0.0009 | Val Loss: 0.1442
2026-01-28 16:38:56 | INFO | Val F1: 0.2896 | Prec: 0.2765 | Rec: 0.3041 | AUC: 0.7844
2026-01-28 16:38:56 | INFO | Epoch 22 | Batch 0/1105 | Loss: 0.0006
2026-01-28 16:39:06 | INFO | Epoch 22 | Batch 100/1105 | Loss: 0.0008
2026-01-28 16:39:17 | INFO | Epoch 22 | Batch 200/1105 | Loss: 0.0005
2026-01-28 16:39:29 | INFO | Epoch 22 | Batch 300/1105 | Loss: 0.0004
2026-01-28 16:39:41 | INFO | Epoch 22 | Batch 400/1105 | Loss: 0.0006
2026-01-28 16:39:53 | INFO | Epoch 22 | Batch 500/1105 | Loss: 0.0020
2026-01-28 16:40:03 | INFO | Epoch 22 | Batch 600/1105 | Loss: 0.0009
2026-01-28 16:40:11 | INFO | Epoch 22 | Batch 700/1105 | Loss: 0.0006
2026-01-28 16:40:20 | INFO | Epoch 22 | Batch 800/1105 | Loss: 0.0004
2026-01-28 16:40:28 | INFO | Epoch 22 | Batch 900/1105 | Loss: 0.0008
2026-01-28 16:40:36 | INFO | Epoch 22 | Batch 1000/1105 | Loss: 0.0002
2026-01-28 16:40:45 | INFO | Epoch 22 | Batch 1100/1105 | Loss: 0.0005
2026-01-28 16:40:49 | INFO | Epoch 22 | Train Loss: 0.0007 | Val Loss: 0.1715
2026-01-28 16:40:49 | INFO | Val F1: 0.2960 | Prec: 0.3197 | Rec: 0.2756 | AUC: 0.7867
2026-01-28 16:40:49 | INFO | New best model saved (F1: 0.2960)
2026-01-28 16:40:50 | INFO | Epoch 23 | Batch 0/1105 | Loss: 0.0011
2026-01-28 16:40:58 | INFO | Epoch 23 | Batch 100/1105 | Loss: 0.0002
2026-01-28 16:41:06 | INFO | Epoch 23 | Batch 200/1105 | Loss: 0.0011
2026-01-28 16:41:14 | INFO | Epoch 23 | Batch 300/1105 | Loss: 0.0002
2026-01-28 16:41:23 | INFO | Epoch 23 | Batch 400/1105 | Loss: 0.0007
2026-01-28 16:41:31 | INFO | Epoch 23 | Batch 500/1105 | Loss: 0.0005
2026-01-28 16:41:39 | INFO | Epoch 23 | Batch 600/1105 | Loss: 0.0012
2026-01-28 16:41:48 | INFO | Epoch 23 | Batch 700/1105 | Loss: 0.0005
2026-01-28 16:41:56 | INFO | Epoch 23 | Batch 800/1105 | Loss: 0.0007
2026-01-28 16:42:04 | INFO | Epoch 23 | Batch 900/1105 | Loss: 0.0023
2026-01-28 16:42:13 | INFO | Epoch 23 | Batch 1000/1105 | Loss: 0.0009
2026-01-28 16:42:21 | INFO | Epoch 23 | Batch 1100/1105 | Loss: 0.0019
2026-01-28 16:42:26 | INFO | Epoch 23 | Train Loss: 0.0007 | Val Loss: 0.1577
2026-01-28 16:42:26 | INFO | Val F1: 0.2877 | Prec: 0.2772 | Rec: 0.2991 | AUC: 0.7865
2026-01-28 16:42:26 | INFO | Epoch 24 | Batch 0/1105 | Loss: 0.0018
2026-01-28 16:42:35 | INFO | Epoch 24 | Batch 100/1105 | Loss: 0.0004
2026-01-28 16:42:43 | INFO | Epoch 24 | Batch 200/1105 | Loss: 0.0004
2026-01-28 16:42:51 | INFO | Epoch 24 | Batch 300/1105 | Loss: 0.0013
2026-01-28 16:43:00 | INFO | Epoch 24 | Batch 400/1105 | Loss: 0.0007
2026-01-28 16:43:08 | INFO | Epoch 24 | Batch 500/1105 | Loss: 0.0007
2026-01-28 16:43:17 | INFO | Epoch 24 | Batch 600/1105 | Loss: 0.0012
2026-01-28 16:43:25 | INFO | Epoch 24 | Batch 700/1105 | Loss: 0.0009
2026-01-28 16:43:33 | INFO | Epoch 24 | Batch 800/1105 | Loss: 0.0002
2026-01-28 16:43:42 | INFO | Epoch 24 | Batch 900/1105 | Loss: 0.0008
2026-01-28 16:43:50 | INFO | Epoch 24 | Batch 1000/1105 | Loss: 0.0004
2026-01-28 16:43:58 | INFO | Epoch 24 | Batch 1100/1105 | Loss: 0.0001
2026-01-28 16:44:03 | INFO | Epoch 24 | Train Loss: 0.0007 | Val Loss: 0.1713
2026-01-28 16:44:03 | INFO | Val F1: 0.2816 | Prec: 0.2969 | Rec: 0.2679 | AUC: 0.7829
2026-01-28 16:44:03 | INFO | Epoch 25 | Batch 0/1105 | Loss: 0.0003
2026-01-28 16:44:12 | INFO | Epoch 25 | Batch 100/1105 | Loss: 0.0010
2026-01-28 16:44:21 | INFO | Epoch 25 | Batch 200/1105 | Loss: 0.0011
2026-01-28 16:44:29 | INFO | Epoch 25 | Batch 300/1105 | Loss: 0.0004
2026-01-28 16:44:37 | INFO | Epoch 25 | Batch 400/1105 | Loss: 0.0004
2026-01-28 16:44:46 | INFO | Epoch 25 | Batch 500/1105 | Loss: 0.0005
2026-01-28 16:44:54 | INFO | Epoch 25 | Batch 600/1105 | Loss: 0.0001
2026-01-28 16:45:03 | INFO | Epoch 25 | Batch 700/1105 | Loss: 0.0004
2026-01-28 16:45:11 | INFO | Epoch 25 | Batch 800/1105 | Loss: 0.0004
2026-01-28 16:45:20 | INFO | Epoch 25 | Batch 900/1105 | Loss: 0.0031
2026-01-28 16:45:28 | INFO | Epoch 25 | Batch 1000/1105 | Loss: 0.0007
2026-01-28 16:45:36 | INFO | Epoch 25 | Batch 1100/1105 | Loss: 0.0006
2026-01-28 16:45:41 | INFO | Epoch 25 | Train Loss: 0.0007 | Val Loss: 0.1750
2026-01-28 16:45:41 | INFO | Val F1: 0.2824 | Prec: 0.3133 | Rec: 0.2571 | AUC: 0.7823
2026-01-28 16:45:41 | INFO | Epoch 26 | Batch 0/1105 | Loss: 0.0005
2026-01-28 16:45:49 | INFO | Epoch 26 | Batch 100/1105 | Loss: 0.0008
2026-01-28 16:45:57 | INFO | Epoch 26 | Batch 200/1105 | Loss: 0.0005
2026-01-28 16:46:06 | INFO | Epoch 26 | Batch 300/1105 | Loss: 0.0001
2026-01-28 16:46:14 | INFO | Epoch 26 | Batch 400/1105 | Loss: 0.0002
2026-01-28 16:46:23 | INFO | Epoch 26 | Batch 500/1105 | Loss: 0.0015
2026-01-28 16:46:31 | INFO | Epoch 26 | Batch 600/1105 | Loss: 0.0005
2026-01-28 16:46:39 | INFO | Epoch 26 | Batch 700/1105 | Loss: 0.0005
2026-01-28 16:46:48 | INFO | Epoch 26 | Batch 800/1105 | Loss: 0.0008
2026-01-28 16:46:56 | INFO | Epoch 26 | Batch 900/1105 | Loss: 0.0008
2026-01-28 16:47:05 | INFO | Epoch 26 | Batch 1000/1105 | Loss: 0.0016
2026-01-28 16:47:13 | INFO | Epoch 26 | Batch 1100/1105 | Loss: 0.0004
2026-01-28 16:47:18 | INFO | Epoch 26 | Train Loss: 0.0006 | Val Loss: 0.1711
2026-01-28 16:47:18 | INFO | Val F1: 0.2901 | Prec: 0.3117 | Rec: 0.2712 | AUC: 0.7847
2026-01-28 16:47:18 | INFO | Epoch 27 | Batch 0/1105 | Loss: 0.0005
2026-01-28 16:47:26 | INFO | Epoch 27 | Batch 100/1105 | Loss: 0.0013
2026-01-28 16:47:35 | INFO | Epoch 27 | Batch 200/1105 | Loss: 0.0002
2026-01-28 16:47:43 | INFO | Epoch 27 | Batch 300/1105 | Loss: 0.0004
2026-01-28 16:47:51 | INFO | Epoch 27 | Batch 400/1105 | Loss: 0.0001
2026-01-28 16:48:00 | INFO | Epoch 27 | Batch 500/1105 | Loss: 0.0002
2026-01-28 16:48:08 | INFO | Epoch 27 | Batch 600/1105 | Loss: 0.0002
2026-01-28 16:48:17 | INFO | Epoch 27 | Batch 700/1105 | Loss: 0.0002
2026-01-28 16:48:25 | INFO | Epoch 27 | Batch 800/1105 | Loss: 0.0000
2026-01-28 16:48:34 | INFO | Epoch 27 | Batch 900/1105 | Loss: 0.0001
2026-01-28 16:48:42 | INFO | Epoch 27 | Batch 1000/1105 | Loss: 0.0007
2026-01-28 16:48:51 | INFO | Epoch 27 | Batch 1100/1105 | Loss: 0.0003
2026-01-28 16:48:56 | INFO | Epoch 27 | Train Loss: 0.0004 | Val Loss: 0.1888
2026-01-28 16:48:56 | INFO | Val F1: 0.2809 | Prec: 0.3029 | Rec: 0.2618 | AUC: 0.7827
2026-01-28 16:48:56 | INFO | Epoch 28 | Batch 0/1105 | Loss: 0.0002
2026-01-28 16:49:04 | INFO | Epoch 28 | Batch 100/1105 | Loss: 0.0002
2026-01-28 16:49:13 | INFO | Epoch 28 | Batch 200/1105 | Loss: 0.0003
2026-01-28 16:49:21 | INFO | Epoch 28 | Batch 300/1105 | Loss: 0.0004
2026-01-28 16:49:39 | INFO | Epoch 28 | Batch 400/1105 | Loss: 0.0000
2026-01-28 16:49:53 | INFO | Epoch 28 | Batch 500/1105 | Loss: 0.0005
2026-01-28 16:50:08 | INFO | Epoch 28 | Batch 600/1105 | Loss: 0.0015
2026-01-28 16:50:19 | INFO | Epoch 28 | Batch 700/1105 | Loss: 0.0000
2026-01-28 16:50:32 | INFO | Epoch 28 | Batch 800/1105 | Loss: 0.0001
2026-01-28 16:50:44 | INFO | Epoch 28 | Batch 900/1105 | Loss: 0.0001
2026-01-28 16:50:56 | INFO | Epoch 28 | Batch 1000/1105 | Loss: 0.0005
2026-01-28 16:51:09 | INFO | Epoch 28 | Batch 1100/1105 | Loss: 0.0009
2026-01-28 16:51:15 | INFO | Epoch 28 | Train Loss: 0.0004 | Val Loss: 0.1938
2026-01-28 16:51:15 | INFO | Val F1: 0.2869 | Prec: 0.3094 | Rec: 0.2675 | AUC: 0.7864
2026-01-28 16:51:15 | INFO | Epoch 29 | Batch 0/1105 | Loss: 0.0001
2026-01-28 16:51:28 | INFO | Epoch 29 | Batch 100/1105 | Loss: 0.0008
2026-01-28 16:51:40 | INFO | Epoch 29 | Batch 200/1105 | Loss: 0.0002
2026-01-28 16:51:52 | INFO | Epoch 29 | Batch 300/1105 | Loss: 0.0007
2026-01-28 16:52:04 | INFO | Epoch 29 | Batch 400/1105 | Loss: 0.0003
2026-01-28 16:52:16 | INFO | Epoch 29 | Batch 500/1105 | Loss: 0.0002
2026-01-28 16:52:28 | INFO | Epoch 29 | Batch 600/1105 | Loss: 0.0001
2026-01-28 16:52:40 | INFO | Epoch 29 | Batch 700/1105 | Loss: 0.0003
2026-01-28 16:52:52 | INFO | Epoch 29 | Batch 800/1105 | Loss: 0.0017
2026-01-28 16:53:05 | INFO | Epoch 29 | Batch 900/1105 | Loss: 0.0001
2026-01-28 16:53:17 | INFO | Epoch 29 | Batch 1000/1105 | Loss: 0.0000
2026-01-28 16:53:29 | INFO | Epoch 29 | Batch 1100/1105 | Loss: 0.0006
2026-01-28 16:53:35 | INFO | Epoch 29 | Train Loss: 0.0004 | Val Loss: 0.2002
2026-01-28 16:53:35 | INFO | Val F1: 0.2885 | Prec: 0.3094 | Rec: 0.2702 | AUC: 0.7851
2026-01-28 16:53:35 | INFO | Epoch 30 | Batch 0/1105 | Loss: 0.0002
2026-01-28 16:53:47 | INFO | Epoch 30 | Batch 100/1105 | Loss: 0.0008
2026-01-28 16:54:00 | INFO | Epoch 30 | Batch 200/1105 | Loss: 0.0018
2026-01-28 16:54:12 | INFO | Epoch 30 | Batch 300/1105 | Loss: 0.0001
2026-01-28 16:54:25 | INFO | Epoch 30 | Batch 400/1105 | Loss: 0.0001
2026-01-28 16:54:37 | INFO | Epoch 30 | Batch 500/1105 | Loss: 0.0001
2026-01-28 16:54:51 | INFO | Epoch 30 | Batch 600/1105 | Loss: 0.0001
2026-01-28 16:55:03 | INFO | Epoch 30 | Batch 700/1105 | Loss: 0.0001
2026-01-28 16:55:16 | INFO | Epoch 30 | Batch 800/1105 | Loss: 0.0001
2026-01-28 16:55:27 | INFO | Epoch 30 | Batch 900/1105 | Loss: 0.0014
2026-01-28 16:55:38 | INFO | Epoch 30 | Batch 1000/1105 | Loss: 0.0003
2026-01-28 16:55:49 | INFO | Epoch 30 | Batch 1100/1105 | Loss: 0.0003
2026-01-28 16:55:56 | INFO | Epoch 30 | Train Loss: 0.0003 | Val Loss: 0.2012
2026-01-28 16:55:56 | INFO | Val F1: 0.2866 | Prec: 0.3000 | Rec: 0.2743 | AUC: 0.7831
2026-01-28 16:55:56 | INFO | Epoch 31 | Batch 0/1105 | Loss: 0.0001
2026-01-28 16:56:07 | INFO | Epoch 31 | Batch 100/1105 | Loss: 0.0001
2026-01-28 16:56:18 | INFO | Epoch 31 | Batch 200/1105 | Loss: 0.0001
2026-01-28 16:56:30 | INFO | Epoch 31 | Batch 300/1105 | Loss: 0.0004
2026-01-28 16:56:42 | INFO | Epoch 31 | Batch 400/1105 | Loss: 0.0002
2026-01-28 16:56:54 | INFO | Epoch 31 | Batch 500/1105 | Loss: 0.0001
2026-01-28 16:57:06 | INFO | Epoch 31 | Batch 600/1105 | Loss: 0.0007
2026-01-28 16:57:18 | INFO | Epoch 31 | Batch 700/1105 | Loss: 0.0004
2026-01-28 16:57:30 | INFO | Epoch 31 | Batch 800/1105 | Loss: 0.0001
2026-01-28 16:57:42 | INFO | Epoch 31 | Batch 900/1105 | Loss: 0.0004
2026-01-28 16:57:54 | INFO | Epoch 31 | Batch 1000/1105 | Loss: 0.0001
2026-01-28 16:58:06 | INFO | Epoch 31 | Batch 1100/1105 | Loss: 0.0001
2026-01-28 16:58:13 | INFO | Epoch 31 | Train Loss: 0.0004 | Val Loss: 0.2070
2026-01-28 16:58:13 | INFO | Val F1: 0.2869 | Prec: 0.3049 | Rec: 0.2709 | AUC: 0.7842
2026-01-28 16:58:13 | INFO | Epoch 32 | Batch 0/1105 | Loss: 0.0002
2026-01-28 16:58:26 | INFO | Epoch 32 | Batch 100/1105 | Loss: 0.0001
2026-01-28 16:58:38 | INFO | Epoch 32 | Batch 200/1105 | Loss: 0.0002
2026-01-28 16:58:51 | INFO | Epoch 32 | Batch 300/1105 | Loss: 0.0002
2026-01-28 16:59:02 | INFO | Epoch 32 | Batch 400/1105 | Loss: 0.0004
2026-01-28 16:59:15 | INFO | Epoch 32 | Batch 500/1105 | Loss: 0.0001
2026-01-28 16:59:28 | INFO | Epoch 32 | Batch 600/1105 | Loss: 0.0000
2026-01-28 16:59:40 | INFO | Epoch 32 | Batch 700/1105 | Loss: 0.0002
2026-01-28 16:59:52 | INFO | Epoch 32 | Batch 800/1105 | Loss: 0.0007
2026-01-28 17:00:04 | INFO | Epoch 32 | Batch 900/1105 | Loss: 0.0009
2026-01-28 17:00:17 | INFO | Epoch 32 | Batch 1000/1105 | Loss: 0.0002
2026-01-28 17:00:29 | INFO | Epoch 32 | Batch 1100/1105 | Loss: 0.0002
2026-01-28 17:00:35 | INFO | Epoch 32 | Train Loss: 0.0004 | Val Loss: 0.2065
2026-01-28 17:00:35 | INFO | Val F1: 0.2886 | Prec: 0.3001 | Rec: 0.2779 | AUC: 0.7843
2026-01-28 17:00:35 | INFO | Early stopping at epoch 32
2026-01-28 17:00:45 | INFO | ==================================================
2026-01-28 17:00:45 | INFO | TEST RESULTS (Sequence LSTM)
2026-01-28 17:00:45 | INFO | ==================================================
2026-01-28 17:00:45 | INFO | F1: 0.2963
2026-01-28 17:00:45 | INFO | Precision: 0.3195
2026-01-28 17:00:45 | INFO | Recall: 0.2763
2026-01-28 17:00:45 | INFO | AUC: 0.7805
