2026-01-30 13:37:58 | INFO | Starting LSTM + GNN + Dense Fusion Model Training
2026-01-30 13:37:58 | INFO | Device: cpu
2026-01-30 13:37:59 | INFO | Train batches: 1169
2026-01-30 13:37:59 | INFO | Model parameters: 258,369
2026-01-30 13:37:59 | INFO | Temporal branch output: 128
2026-01-30 13:37:59 | INFO | Relational branch output: 64
2026-01-30 13:37:59 | INFO | Behavioral branch output: 64
2026-01-30 13:38:02 | INFO | Epoch 1 | Batch 0/1169 | Loss: 0.0819
2026-01-30 13:38:07 | INFO | Epoch 1 | Batch 100/1169 | Loss: 0.0494
2026-01-30 13:38:12 | INFO | Epoch 1 | Batch 200/1169 | Loss: 0.0459
2026-01-30 13:38:17 | INFO | Epoch 1 | Batch 300/1169 | Loss: 0.0431
2026-01-30 13:38:22 | INFO | Epoch 1 | Batch 400/1169 | Loss: 0.0444
2026-01-30 13:38:26 | INFO | Epoch 1 | Batch 500/1169 | Loss: 0.0412
2026-01-30 13:38:32 | INFO | Epoch 1 | Batch 600/1169 | Loss: 0.0439
2026-01-30 13:38:36 | INFO | Epoch 1 | Batch 700/1169 | Loss: 0.0393
2026-01-30 13:38:41 | INFO | Epoch 1 | Batch 800/1169 | Loss: 0.0401
2026-01-30 13:38:46 | INFO | Epoch 1 | Batch 900/1169 | Loss: 0.0330
2026-01-30 13:38:50 | INFO | Epoch 1 | Batch 1000/1169 | Loss: 0.0394
2026-01-30 13:38:55 | INFO | Epoch 1 | Batch 1100/1169 | Loss: 0.0363
2026-01-30 13:39:03 | INFO | Epoch 1 | Train Loss: 0.0430 | Val Loss: 0.0339
2026-01-30 13:39:03 | INFO | Val F1: 0.2022 | Prec: 0.1156 | Rec: 0.8077 | AUC: 0.8823
2026-01-30 13:39:03 | INFO | New best model saved (F1: 0.2022)
2026-01-30 13:39:03 | INFO | Epoch 2 | Batch 0/1169 | Loss: 0.0425
2026-01-30 13:39:07 | INFO | Epoch 2 | Batch 100/1169 | Loss: 0.0366
2026-01-30 13:39:11 | INFO | Epoch 2 | Batch 200/1169 | Loss: 0.0427
2026-01-30 13:39:16 | INFO | Epoch 2 | Batch 300/1169 | Loss: 0.0377
2026-01-30 13:39:20 | INFO | Epoch 2 | Batch 400/1169 | Loss: 0.0342
2026-01-30 13:39:24 | INFO | Epoch 2 | Batch 500/1169 | Loss: 0.0350
2026-01-30 13:39:29 | INFO | Epoch 2 | Batch 600/1169 | Loss: 0.0369
2026-01-30 13:39:34 | INFO | Epoch 2 | Batch 700/1169 | Loss: 0.0387
2026-01-30 13:39:39 | INFO | Epoch 2 | Batch 800/1169 | Loss: 0.0343
2026-01-30 13:39:44 | INFO | Epoch 2 | Batch 900/1169 | Loss: 0.0306
2026-01-30 13:39:49 | INFO | Epoch 2 | Batch 1000/1169 | Loss: 0.0325
2026-01-30 13:39:53 | INFO | Epoch 2 | Batch 1100/1169 | Loss: 0.0295
2026-01-30 13:40:00 | INFO | Epoch 2 | Train Loss: 0.0358 | Val Loss: 0.0316
2026-01-30 13:40:00 | INFO | Val F1: 0.2184 | Prec: 0.1258 | Rec: 0.8268 | AUC: 0.8971
2026-01-30 13:40:00 | INFO | New best model saved (F1: 0.2184)
2026-01-30 13:40:01 | INFO | Epoch 3 | Batch 0/1169 | Loss: 0.0371
2026-01-30 13:40:05 | INFO | Epoch 3 | Batch 100/1169 | Loss: 0.0318
2026-01-30 13:40:11 | INFO | Epoch 3 | Batch 200/1169 | Loss: 0.0348
2026-01-30 13:40:15 | INFO | Epoch 3 | Batch 300/1169 | Loss: 0.0323
2026-01-30 13:40:20 | INFO | Epoch 3 | Batch 400/1169 | Loss: 0.0354
2026-01-30 13:40:25 | INFO | Epoch 3 | Batch 500/1169 | Loss: 0.0333
2026-01-30 13:40:29 | INFO | Epoch 3 | Batch 600/1169 | Loss: 0.0325
2026-01-30 13:40:34 | INFO | Epoch 3 | Batch 700/1169 | Loss: 0.0302
2026-01-30 13:40:39 | INFO | Epoch 3 | Batch 800/1169 | Loss: 0.0290
2026-01-30 13:40:43 | INFO | Epoch 3 | Batch 900/1169 | Loss: 0.0306
2026-01-30 13:40:48 | INFO | Epoch 3 | Batch 1000/1169 | Loss: 0.0272
2026-01-30 13:40:53 | INFO | Epoch 3 | Batch 1100/1169 | Loss: 0.0282
2026-01-30 13:41:00 | INFO | Epoch 3 | Train Loss: 0.0323 | Val Loss: 0.0345
2026-01-30 13:41:00 | INFO | Val F1: 0.2001 | Prec: 0.1133 | Rec: 0.8548 | AUC: 0.9001
2026-01-30 13:41:00 | INFO | Epoch 4 | Batch 0/1169 | Loss: 0.0302
2026-01-30 13:41:05 | INFO | Epoch 4 | Batch 100/1169 | Loss: 0.0332
2026-01-30 13:41:10 | INFO | Epoch 4 | Batch 200/1169 | Loss: 0.0325
2026-01-30 13:41:15 | INFO | Epoch 4 | Batch 300/1169 | Loss: 0.0331
2026-01-30 13:41:19 | INFO | Epoch 4 | Batch 400/1169 | Loss: 0.0307
2026-01-30 13:41:23 | INFO | Epoch 4 | Batch 500/1169 | Loss: 0.0286
2026-01-30 13:41:28 | INFO | Epoch 4 | Batch 600/1169 | Loss: 0.0343
2026-01-30 13:41:32 | INFO | Epoch 4 | Batch 700/1169 | Loss: 0.0282
2026-01-30 13:41:37 | INFO | Epoch 4 | Batch 800/1169 | Loss: 0.0300
2026-01-30 13:41:41 | INFO | Epoch 4 | Batch 900/1169 | Loss: 0.0267
2026-01-30 13:41:46 | INFO | Epoch 4 | Batch 1000/1169 | Loss: 0.0235
2026-01-30 13:41:51 | INFO | Epoch 4 | Batch 1100/1169 | Loss: 0.0318
2026-01-30 13:41:58 | INFO | Epoch 4 | Train Loss: 0.0297 | Val Loss: 0.0270
2026-01-30 13:41:58 | INFO | Val F1: 0.2487 | Prec: 0.1463 | Rec: 0.8277 | AUC: 0.9086
2026-01-30 13:41:58 | INFO | New best model saved (F1: 0.2487)
2026-01-30 13:41:58 | INFO | Epoch 5 | Batch 0/1169 | Loss: 0.0247
2026-01-30 13:42:03 | INFO | Epoch 5 | Batch 100/1169 | Loss: 0.0292
2026-01-30 13:42:08 | INFO | Epoch 5 | Batch 200/1169 | Loss: 0.0270
2026-01-30 13:42:13 | INFO | Epoch 5 | Batch 300/1169 | Loss: 0.0293
2026-01-30 13:42:18 | INFO | Epoch 5 | Batch 400/1169 | Loss: 0.0279
2026-01-30 13:42:23 | INFO | Epoch 5 | Batch 500/1169 | Loss: 0.0295
2026-01-30 13:42:27 | INFO | Epoch 5 | Batch 600/1169 | Loss: 0.0288
2026-01-30 13:42:32 | INFO | Epoch 5 | Batch 700/1169 | Loss: 0.0261
2026-01-30 13:42:37 | INFO | Epoch 5 | Batch 800/1169 | Loss: 0.0268
2026-01-30 13:42:42 | INFO | Epoch 5 | Batch 900/1169 | Loss: 0.0268
2026-01-30 13:42:46 | INFO | Epoch 5 | Batch 1000/1169 | Loss: 0.0302
2026-01-30 13:42:51 | INFO | Epoch 5 | Batch 1100/1169 | Loss: 0.0300
2026-01-30 13:42:59 | INFO | Epoch 5 | Train Loss: 0.0280 | Val Loss: 0.0305
2026-01-30 13:42:59 | INFO | Val F1: 0.2270 | Prec: 0.1310 | Rec: 0.8477 | AUC: 0.9081
2026-01-30 13:42:59 | INFO | Epoch 6 | Batch 0/1169 | Loss: 0.0254
2026-01-30 13:43:04 | INFO | Epoch 6 | Batch 100/1169 | Loss: 0.0237
2026-01-30 13:43:09 | INFO | Epoch 6 | Batch 200/1169 | Loss: 0.0240
2026-01-30 13:43:14 | INFO | Epoch 6 | Batch 300/1169 | Loss: 0.0337
2026-01-30 13:43:19 | INFO | Epoch 6 | Batch 400/1169 | Loss: 0.0279
2026-01-30 13:43:24 | INFO | Epoch 6 | Batch 500/1169 | Loss: 0.0253
2026-01-30 13:43:28 | INFO | Epoch 6 | Batch 600/1169 | Loss: 0.0267
2026-01-30 13:43:33 | INFO | Epoch 6 | Batch 700/1169 | Loss: 0.0260
2026-01-30 13:43:38 | INFO | Epoch 6 | Batch 800/1169 | Loss: 0.0258
2026-01-30 13:43:43 | INFO | Epoch 6 | Batch 900/1169 | Loss: 0.0250
2026-01-30 13:43:48 | INFO | Epoch 6 | Batch 1000/1169 | Loss: 0.0251
2026-01-30 13:43:53 | INFO | Epoch 6 | Batch 1100/1169 | Loss: 0.0257
2026-01-30 13:44:00 | INFO | Epoch 6 | Train Loss: 0.0268 | Val Loss: 0.0254
2026-01-30 13:44:00 | INFO | Val F1: 0.2641 | Prec: 0.1576 | Rec: 0.8139 | AUC: 0.9097
2026-01-30 13:44:00 | INFO | New best model saved (F1: 0.2641)
2026-01-30 13:44:00 | INFO | Epoch 7 | Batch 0/1169 | Loss: 0.0232
2026-01-30 13:44:06 | INFO | Epoch 7 | Batch 100/1169 | Loss: 0.0291
2026-01-30 13:44:11 | INFO | Epoch 7 | Batch 200/1169 | Loss: 0.0226
2026-01-30 13:44:15 | INFO | Epoch 7 | Batch 300/1169 | Loss: 0.0264
2026-01-30 13:44:21 | INFO | Epoch 7 | Batch 400/1169 | Loss: 0.0268
2026-01-30 13:44:26 | INFO | Epoch 7 | Batch 500/1169 | Loss: 0.0244
2026-01-30 13:44:30 | INFO | Epoch 7 | Batch 600/1169 | Loss: 0.0270
2026-01-30 13:44:35 | INFO | Epoch 7 | Batch 700/1169 | Loss: 0.0219
2026-01-30 13:44:40 | INFO | Epoch 7 | Batch 800/1169 | Loss: 0.0240
2026-01-30 13:44:45 | INFO | Epoch 7 | Batch 900/1169 | Loss: 0.0241
2026-01-30 13:44:49 | INFO | Epoch 7 | Batch 1000/1169 | Loss: 0.0296
2026-01-30 13:44:54 | INFO | Epoch 7 | Batch 1100/1169 | Loss: 0.0262
2026-01-30 13:45:03 | INFO | Epoch 7 | Train Loss: 0.0257 | Val Loss: 0.0226
2026-01-30 13:45:03 | INFO | Val F1: 0.2945 | Prec: 0.1804 | Rec: 0.8013 | AUC: 0.9137
2026-01-30 13:45:03 | INFO | New best model saved (F1: 0.2945)
2026-01-30 13:45:03 | INFO | Epoch 8 | Batch 0/1169 | Loss: 0.0249
2026-01-30 13:45:08 | INFO | Epoch 8 | Batch 100/1169 | Loss: 0.0288
2026-01-30 13:45:13 | INFO | Epoch 8 | Batch 200/1169 | Loss: 0.0258
2026-01-30 13:45:18 | INFO | Epoch 8 | Batch 300/1169 | Loss: 0.0256
2026-01-30 13:45:23 | INFO | Epoch 8 | Batch 400/1169 | Loss: 0.0285
2026-01-30 13:45:28 | INFO | Epoch 8 | Batch 500/1169 | Loss: 0.0296
2026-01-30 13:45:35 | INFO | Epoch 8 | Batch 600/1169 | Loss: 0.0237
2026-01-30 13:45:40 | INFO | Epoch 8 | Batch 700/1169 | Loss: 0.0268
2026-01-30 13:45:45 | INFO | Epoch 8 | Batch 800/1169 | Loss: 0.0236
2026-01-30 13:45:51 | INFO | Epoch 8 | Batch 900/1169 | Loss: 0.0251
2026-01-30 13:45:58 | INFO | Epoch 8 | Batch 1000/1169 | Loss: 0.0226
2026-01-30 13:46:04 | INFO | Epoch 8 | Batch 1100/1169 | Loss: 0.0268
2026-01-30 13:46:12 | INFO | Epoch 8 | Train Loss: 0.0250 | Val Loss: 0.0193
2026-01-30 13:46:12 | INFO | Val F1: 0.3335 | Prec: 0.2121 | Rec: 0.7803 | AUC: 0.9170
2026-01-30 13:46:12 | INFO | New best model saved (F1: 0.3335)
2026-01-30 13:46:12 | INFO | Epoch 9 | Batch 0/1169 | Loss: 0.0208
2026-01-30 13:46:17 | INFO | Epoch 9 | Batch 100/1169 | Loss: 0.0236
2026-01-30 13:46:22 | INFO | Epoch 9 | Batch 200/1169 | Loss: 0.0232
2026-01-30 13:46:27 | INFO | Epoch 9 | Batch 300/1169 | Loss: 0.0248
2026-01-30 13:46:32 | INFO | Epoch 9 | Batch 400/1169 | Loss: 0.0278
2026-01-30 13:46:37 | INFO | Epoch 9 | Batch 500/1169 | Loss: 0.0274
2026-01-30 13:46:42 | INFO | Epoch 9 | Batch 600/1169 | Loss: 0.0220
2026-01-30 13:46:47 | INFO | Epoch 9 | Batch 700/1169 | Loss: 0.0202
2026-01-30 13:46:52 | INFO | Epoch 9 | Batch 800/1169 | Loss: 0.0227
2026-01-30 13:46:57 | INFO | Epoch 9 | Batch 900/1169 | Loss: 0.0257
2026-01-30 13:47:02 | INFO | Epoch 9 | Batch 1000/1169 | Loss: 0.0207
2026-01-30 13:47:08 | INFO | Epoch 9 | Batch 1100/1169 | Loss: 0.0237
2026-01-30 13:47:15 | INFO | Epoch 9 | Train Loss: 0.0243 | Val Loss: 0.0246
2026-01-30 13:47:15 | INFO | Val F1: 0.2613 | Prec: 0.1547 | Rec: 0.8406 | AUC: 0.9199
2026-01-30 13:47:15 | INFO | Epoch 10 | Batch 0/1169 | Loss: 0.0260
2026-01-30 13:47:20 | INFO | Epoch 10 | Batch 100/1169 | Loss: 0.0263
2026-01-30 13:47:25 | INFO | Epoch 10 | Batch 200/1169 | Loss: 0.0233
2026-01-30 13:47:30 | INFO | Epoch 10 | Batch 300/1169 | Loss: 0.0250
2026-01-30 13:47:36 | INFO | Epoch 10 | Batch 400/1169 | Loss: 0.0219
2026-01-30 13:47:41 | INFO | Epoch 10 | Batch 500/1169 | Loss: 0.0212
2026-01-30 13:47:46 | INFO | Epoch 10 | Batch 600/1169 | Loss: 0.0200
2026-01-30 13:47:51 | INFO | Epoch 10 | Batch 700/1169 | Loss: 0.0207
2026-01-30 13:47:56 | INFO | Epoch 10 | Batch 800/1169 | Loss: 0.0252
2026-01-30 13:48:01 | INFO | Epoch 10 | Batch 900/1169 | Loss: 0.0276
2026-01-30 13:48:05 | INFO | Epoch 10 | Batch 1000/1169 | Loss: 0.0218
2026-01-30 13:48:10 | INFO | Epoch 10 | Batch 1100/1169 | Loss: 0.0210
2026-01-30 13:48:17 | INFO | Epoch 10 | Train Loss: 0.0237 | Val Loss: 0.0197
2026-01-30 13:48:17 | INFO | Val F1: 0.3311 | Prec: 0.2091 | Rec: 0.7948 | AUC: 0.9206
2026-01-30 13:48:17 | INFO | Epoch 11 | Batch 0/1169 | Loss: 0.0220
2026-01-30 13:48:22 | INFO | Epoch 11 | Batch 100/1169 | Loss: 0.0236
2026-01-30 13:48:27 | INFO | Epoch 11 | Batch 200/1169 | Loss: 0.0186
2026-01-30 13:48:32 | INFO | Epoch 11 | Batch 300/1169 | Loss: 0.0269
2026-01-30 13:48:37 | INFO | Epoch 11 | Batch 400/1169 | Loss: 0.0264
2026-01-30 13:48:41 | INFO | Epoch 11 | Batch 500/1169 | Loss: 0.0254
2026-01-30 13:48:46 | INFO | Epoch 11 | Batch 600/1169 | Loss: 0.0234
2026-01-30 13:48:51 | INFO | Epoch 11 | Batch 700/1169 | Loss: 0.0215
2026-01-30 13:48:57 | INFO | Epoch 11 | Batch 800/1169 | Loss: 0.0178
2026-01-30 13:49:01 | INFO | Epoch 11 | Batch 900/1169 | Loss: 0.0195
2026-01-30 13:49:06 | INFO | Epoch 11 | Batch 1000/1169 | Loss: 0.0237
2026-01-30 13:49:11 | INFO | Epoch 11 | Batch 1100/1169 | Loss: 0.0245
2026-01-30 13:49:19 | INFO | Epoch 11 | Train Loss: 0.0231 | Val Loss: 0.0201
2026-01-30 13:49:19 | INFO | Val F1: 0.3189 | Prec: 0.1987 | Rec: 0.8065 | AUC: 0.9210
2026-01-30 13:49:19 | INFO | Epoch 12 | Batch 0/1169 | Loss: 0.0236
2026-01-30 13:49:25 | INFO | Epoch 12 | Batch 100/1169 | Loss: 0.0238
2026-01-30 13:49:30 | INFO | Epoch 12 | Batch 200/1169 | Loss: 0.0231
2026-01-30 13:49:35 | INFO | Epoch 12 | Batch 300/1169 | Loss: 0.0276
2026-01-30 13:49:40 | INFO | Epoch 12 | Batch 400/1169 | Loss: 0.0216
2026-01-30 13:49:45 | INFO | Epoch 12 | Batch 500/1169 | Loss: 0.0216
2026-01-30 13:49:50 | INFO | Epoch 12 | Batch 600/1169 | Loss: 0.0250
2026-01-30 13:49:56 | INFO | Epoch 12 | Batch 700/1169 | Loss: 0.0258
2026-01-30 13:50:01 | INFO | Epoch 12 | Batch 800/1169 | Loss: 0.0237
2026-01-30 13:50:07 | INFO | Epoch 12 | Batch 900/1169 | Loss: 0.0242
2026-01-30 13:50:13 | INFO | Epoch 12 | Batch 1000/1169 | Loss: 0.0213
2026-01-30 13:50:18 | INFO | Epoch 12 | Batch 1100/1169 | Loss: 0.0190
2026-01-30 13:50:26 | INFO | Epoch 12 | Train Loss: 0.0226 | Val Loss: 0.0211
2026-01-30 13:50:26 | INFO | Val F1: 0.3133 | Prec: 0.1945 | Rec: 0.8055 | AUC: 0.9208
2026-01-30 13:50:26 | INFO | Epoch 13 | Batch 0/1169 | Loss: 0.0200
2026-01-30 13:50:31 | INFO | Epoch 13 | Batch 100/1169 | Loss: 0.0194
2026-01-30 13:50:37 | INFO | Epoch 13 | Batch 200/1169 | Loss: 0.0180
2026-01-30 13:50:43 | INFO | Epoch 13 | Batch 300/1169 | Loss: 0.0232
2026-01-30 13:50:48 | INFO | Epoch 13 | Batch 400/1169 | Loss: 0.0213
2026-01-30 13:50:54 | INFO | Epoch 13 | Batch 500/1169 | Loss: 0.0229
2026-01-30 13:50:59 | INFO | Epoch 13 | Batch 600/1169 | Loss: 0.0177
2026-01-30 13:51:05 | INFO | Epoch 13 | Batch 700/1169 | Loss: 0.0200
2026-01-30 13:51:10 | INFO | Epoch 13 | Batch 800/1169 | Loss: 0.0217
2026-01-30 13:51:15 | INFO | Epoch 13 | Batch 900/1169 | Loss: 0.0296
2026-01-30 13:51:20 | INFO | Epoch 13 | Batch 1000/1169 | Loss: 0.0238
2026-01-30 13:51:26 | INFO | Epoch 13 | Batch 1100/1169 | Loss: 0.0235
2026-01-30 13:51:35 | INFO | Epoch 13 | Train Loss: 0.0222 | Val Loss: 0.0192
2026-01-30 13:51:35 | INFO | Val F1: 0.3386 | Prec: 0.2147 | Rec: 0.8006 | AUC: 0.9225
2026-01-30 13:51:35 | INFO | New best model saved (F1: 0.3386)
2026-01-30 13:51:35 | INFO | Epoch 14 | Batch 0/1169 | Loss: 0.0180
2026-01-30 13:51:41 | INFO | Epoch 14 | Batch 100/1169 | Loss: 0.0237
2026-01-30 13:51:46 | INFO | Epoch 14 | Batch 200/1169 | Loss: 0.0240
2026-01-30 13:51:50 | INFO | Epoch 14 | Batch 300/1169 | Loss: 0.0253
2026-01-30 13:51:55 | INFO | Epoch 14 | Batch 400/1169 | Loss: 0.0179
2026-01-30 13:52:00 | INFO | Epoch 14 | Batch 500/1169 | Loss: 0.0243
2026-01-30 13:52:05 | INFO | Epoch 14 | Batch 600/1169 | Loss: 0.0289
2026-01-30 13:52:10 | INFO | Epoch 14 | Batch 700/1169 | Loss: 0.0200
2026-01-30 13:52:15 | INFO | Epoch 14 | Batch 800/1169 | Loss: 0.0208
2026-01-30 13:52:20 | INFO | Epoch 14 | Batch 900/1169 | Loss: 0.0189
2026-01-30 13:52:25 | INFO | Epoch 14 | Batch 1000/1169 | Loss: 0.0182
2026-01-30 13:52:30 | INFO | Epoch 14 | Batch 1100/1169 | Loss: 0.0194
2026-01-30 13:52:38 | INFO | Epoch 14 | Train Loss: 0.0218 | Val Loss: 0.0214
2026-01-30 13:52:38 | INFO | Val F1: 0.3016 | Prec: 0.1849 | Rec: 0.8177 | AUC: 0.9212
2026-01-30 13:52:38 | INFO | Epoch 15 | Batch 0/1169 | Loss: 0.0211
2026-01-30 13:52:43 | INFO | Epoch 15 | Batch 100/1169 | Loss: 0.0194
2026-01-30 13:52:48 | INFO | Epoch 15 | Batch 200/1169 | Loss: 0.0211
2026-01-30 13:52:53 | INFO | Epoch 15 | Batch 300/1169 | Loss: 0.0206
2026-01-30 13:52:58 | INFO | Epoch 15 | Batch 400/1169 | Loss: 0.0215
2026-01-30 13:53:03 | INFO | Epoch 15 | Batch 500/1169 | Loss: 0.0252
2026-01-30 13:53:08 | INFO | Epoch 15 | Batch 600/1169 | Loss: 0.0222
2026-01-30 13:53:13 | INFO | Epoch 15 | Batch 700/1169 | Loss: 0.0253
2026-01-30 13:53:18 | INFO | Epoch 15 | Batch 800/1169 | Loss: 0.0213
2026-01-30 13:53:23 | INFO | Epoch 15 | Batch 900/1169 | Loss: 0.0224
2026-01-30 13:53:27 | INFO | Epoch 15 | Batch 1000/1169 | Loss: 0.0183
2026-01-30 13:53:33 | INFO | Epoch 15 | Batch 1100/1169 | Loss: 0.0209
2026-01-30 13:53:40 | INFO | Epoch 15 | Train Loss: 0.0215 | Val Loss: 0.0226
2026-01-30 13:53:40 | INFO | Val F1: 0.2854 | Prec: 0.1720 | Rec: 0.8361 | AUC: 0.9234
2026-01-30 13:53:40 | INFO | Epoch 16 | Batch 0/1169 | Loss: 0.0215
2026-01-30 13:53:46 | INFO | Epoch 16 | Batch 100/1169 | Loss: 0.0206
2026-01-30 13:53:51 | INFO | Epoch 16 | Batch 200/1169 | Loss: 0.0186
2026-01-30 13:53:56 | INFO | Epoch 16 | Batch 300/1169 | Loss: 0.0219
2026-01-30 13:54:01 | INFO | Epoch 16 | Batch 400/1169 | Loss: 0.0242
2026-01-30 13:54:07 | INFO | Epoch 16 | Batch 500/1169 | Loss: 0.0219
2026-01-30 13:54:12 | INFO | Epoch 16 | Batch 600/1169 | Loss: 0.0185
2026-01-30 13:54:18 | INFO | Epoch 16 | Batch 700/1169 | Loss: 0.0218
2026-01-30 13:54:23 | INFO | Epoch 16 | Batch 800/1169 | Loss: 0.0219
2026-01-30 13:54:28 | INFO | Epoch 16 | Batch 900/1169 | Loss: 0.0174
2026-01-30 13:54:34 | INFO | Epoch 16 | Batch 1000/1169 | Loss: 0.0231
2026-01-30 13:54:39 | INFO | Epoch 16 | Batch 1100/1169 | Loss: 0.0195
2026-01-30 13:54:47 | INFO | Epoch 16 | Train Loss: 0.0211 | Val Loss: 0.0181
2026-01-30 13:54:47 | INFO | Val F1: 0.3578 | Prec: 0.2314 | Rec: 0.7884 | AUC: 0.9232
2026-01-30 13:54:47 | INFO | New best model saved (F1: 0.3578)
2026-01-30 13:54:47 | INFO | Epoch 17 | Batch 0/1169 | Loss: 0.0199
2026-01-30 13:54:53 | INFO | Epoch 17 | Batch 100/1169 | Loss: 0.0243
2026-01-30 13:54:59 | INFO | Epoch 17 | Batch 200/1169 | Loss: 0.0177
2026-01-30 13:55:04 | INFO | Epoch 17 | Batch 300/1169 | Loss: 0.0179
2026-01-30 13:55:09 | INFO | Epoch 17 | Batch 400/1169 | Loss: 0.0231
2026-01-30 13:55:16 | INFO | Epoch 17 | Batch 500/1169 | Loss: 0.0195
2026-01-30 13:55:21 | INFO | Epoch 17 | Batch 600/1169 | Loss: 0.0235
2026-01-30 13:55:26 | INFO | Epoch 17 | Batch 700/1169 | Loss: 0.0173
2026-01-30 13:55:31 | INFO | Epoch 17 | Batch 800/1169 | Loss: 0.0249
2026-01-30 13:55:37 | INFO | Epoch 17 | Batch 900/1169 | Loss: 0.0200
2026-01-30 13:55:42 | INFO | Epoch 17 | Batch 1000/1169 | Loss: 0.0237
2026-01-30 13:55:47 | INFO | Epoch 17 | Batch 1100/1169 | Loss: 0.0196
2026-01-30 13:55:55 | INFO | Epoch 17 | Train Loss: 0.0208 | Val Loss: 0.0219
2026-01-30 13:55:55 | INFO | Val F1: 0.2991 | Prec: 0.1830 | Rec: 0.8184 | AUC: 0.9228
2026-01-30 13:55:55 | INFO | Epoch 18 | Batch 0/1169 | Loss: 0.0163
2026-01-30 13:56:00 | INFO | Epoch 18 | Batch 100/1169 | Loss: 0.0218
2026-01-30 13:56:05 | INFO | Epoch 18 | Batch 200/1169 | Loss: 0.0266
2026-01-30 13:56:10 | INFO | Epoch 18 | Batch 300/1169 | Loss: 0.0216
2026-01-30 13:56:16 | INFO | Epoch 18 | Batch 400/1169 | Loss: 0.0241
2026-01-30 13:56:21 | INFO | Epoch 18 | Batch 500/1169 | Loss: 0.0189
2026-01-30 13:56:26 | INFO | Epoch 18 | Batch 600/1169 | Loss: 0.0187
2026-01-30 13:56:31 | INFO | Epoch 18 | Batch 700/1169 | Loss: 0.0153
2026-01-30 13:56:36 | INFO | Epoch 18 | Batch 800/1169 | Loss: 0.0207
2026-01-30 13:56:41 | INFO | Epoch 18 | Batch 900/1169 | Loss: 0.0161
2026-01-30 13:56:46 | INFO | Epoch 18 | Batch 1000/1169 | Loss: 0.0186
2026-01-30 13:56:51 | INFO | Epoch 18 | Batch 1100/1169 | Loss: 0.0204
2026-01-30 13:57:00 | INFO | Epoch 18 | Train Loss: 0.0205 | Val Loss: 0.0186
2026-01-30 13:57:00 | INFO | Val F1: 0.3455 | Prec: 0.2210 | Rec: 0.7910 | AUC: 0.9242
2026-01-30 13:57:00 | INFO | Epoch 19 | Batch 0/1169 | Loss: 0.0241
2026-01-30 13:57:05 | INFO | Epoch 19 | Batch 100/1169 | Loss: 0.0189
2026-01-30 13:57:10 | INFO | Epoch 19 | Batch 200/1169 | Loss: 0.0243
2026-01-30 13:57:15 | INFO | Epoch 19 | Batch 300/1169 | Loss: 0.0240
2026-01-30 13:57:21 | INFO | Epoch 19 | Batch 400/1169 | Loss: 0.0191
2026-01-30 13:57:26 | INFO | Epoch 19 | Batch 500/1169 | Loss: 0.0223
2026-01-30 13:57:31 | INFO | Epoch 19 | Batch 600/1169 | Loss: 0.0182
2026-01-30 13:57:36 | INFO | Epoch 19 | Batch 700/1169 | Loss: 0.0178
2026-01-30 13:57:41 | INFO | Epoch 19 | Batch 800/1169 | Loss: 0.0194
2026-01-30 13:57:45 | INFO | Epoch 19 | Batch 900/1169 | Loss: 0.0201
2026-01-30 13:57:51 | INFO | Epoch 19 | Batch 1000/1169 | Loss: 0.0209
2026-01-30 13:57:57 | INFO | Epoch 19 | Batch 1100/1169 | Loss: 0.0233
2026-01-30 13:58:05 | INFO | Epoch 19 | Train Loss: 0.0203 | Val Loss: 0.0188
2026-01-30 13:58:05 | INFO | Val F1: 0.3472 | Prec: 0.2227 | Rec: 0.7871 | AUC: 0.9193
2026-01-30 13:58:05 | INFO | Epoch 20 | Batch 0/1169 | Loss: 0.0234
2026-01-30 13:58:10 | INFO | Epoch 20 | Batch 100/1169 | Loss: 0.0220
2026-01-30 13:58:16 | INFO | Epoch 20 | Batch 200/1169 | Loss: 0.0234
2026-01-30 13:58:21 | INFO | Epoch 20 | Batch 300/1169 | Loss: 0.0207
2026-01-30 13:58:27 | INFO | Epoch 20 | Batch 400/1169 | Loss: 0.0200
2026-01-30 13:58:32 | INFO | Epoch 20 | Batch 500/1169 | Loss: 0.0247
2026-01-30 13:58:38 | INFO | Epoch 20 | Batch 600/1169 | Loss: 0.0222
2026-01-30 13:58:43 | INFO | Epoch 20 | Batch 700/1169 | Loss: 0.0209
2026-01-30 13:58:49 | INFO | Epoch 20 | Batch 800/1169 | Loss: 0.0189
2026-01-30 13:58:54 | INFO | Epoch 20 | Batch 900/1169 | Loss: 0.0217
2026-01-30 13:58:59 | INFO | Epoch 20 | Batch 1000/1169 | Loss: 0.0185
2026-01-30 13:59:04 | INFO | Epoch 20 | Batch 1100/1169 | Loss: 0.0263
2026-01-30 13:59:12 | INFO | Epoch 20 | Train Loss: 0.0199 | Val Loss: 0.0231
2026-01-30 13:59:12 | INFO | Val F1: 0.2790 | Prec: 0.1676 | Rec: 0.8319 | AUC: 0.9211
2026-01-30 13:59:12 | INFO | Epoch 21 | Batch 0/1169 | Loss: 0.0193
2026-01-30 13:59:18 | INFO | Epoch 21 | Batch 100/1169 | Loss: 0.0186
2026-01-30 13:59:23 | INFO | Epoch 21 | Batch 200/1169 | Loss: 0.0215
2026-01-30 13:59:29 | INFO | Epoch 21 | Batch 300/1169 | Loss: 0.0188
2026-01-30 13:59:34 | INFO | Epoch 21 | Batch 400/1169 | Loss: 0.0191
2026-01-30 13:59:39 | INFO | Epoch 21 | Batch 500/1169 | Loss: 0.0176
2026-01-30 13:59:44 | INFO | Epoch 21 | Batch 600/1169 | Loss: 0.0223
2026-01-30 13:59:49 | INFO | Epoch 21 | Batch 700/1169 | Loss: 0.0226
2026-01-30 13:59:55 | INFO | Epoch 21 | Batch 800/1169 | Loss: 0.0179
2026-01-30 14:00:00 | INFO | Epoch 21 | Batch 900/1169 | Loss: 0.0191
2026-01-30 14:00:05 | INFO | Epoch 21 | Batch 1000/1169 | Loss: 0.0188
2026-01-30 14:00:10 | INFO | Epoch 21 | Batch 1100/1169 | Loss: 0.0234
2026-01-30 14:00:17 | INFO | Epoch 21 | Train Loss: 0.0197 | Val Loss: 0.0189
2026-01-30 14:00:17 | INFO | Val F1: 0.3431 | Prec: 0.2178 | Rec: 0.8081 | AUC: 0.9270
2026-01-30 14:00:17 | INFO | Epoch 22 | Batch 0/1169 | Loss: 0.0171
2026-01-30 14:00:23 | INFO | Epoch 22 | Batch 100/1169 | Loss: 0.0200
2026-01-30 14:00:27 | INFO | Epoch 22 | Batch 200/1169 | Loss: 0.0180
2026-01-30 14:00:32 | INFO | Epoch 22 | Batch 300/1169 | Loss: 0.0220
2026-01-30 14:00:37 | INFO | Epoch 22 | Batch 400/1169 | Loss: 0.0188
2026-01-30 14:00:43 | INFO | Epoch 22 | Batch 500/1169 | Loss: 0.0247
2026-01-30 14:00:48 | INFO | Epoch 22 | Batch 600/1169 | Loss: 0.0164
2026-01-30 14:00:53 | INFO | Epoch 22 | Batch 700/1169 | Loss: 0.0228
2026-01-30 14:00:58 | INFO | Epoch 22 | Batch 800/1169 | Loss: 0.0218
2026-01-30 14:01:03 | INFO | Epoch 22 | Batch 900/1169 | Loss: 0.0174
2026-01-30 14:01:07 | INFO | Epoch 22 | Batch 1000/1169 | Loss: 0.0191
2026-01-30 14:01:12 | INFO | Epoch 22 | Batch 1100/1169 | Loss: 0.0199
2026-01-30 14:01:19 | INFO | Epoch 22 | Train Loss: 0.0195 | Val Loss: 0.0174
2026-01-30 14:01:19 | INFO | Val F1: 0.3857 | Prec: 0.2561 | Rec: 0.7813 | AUC: 0.9264
2026-01-30 14:01:19 | INFO | New best model saved (F1: 0.3857)
2026-01-30 14:01:20 | INFO | Epoch 23 | Batch 0/1169 | Loss: 0.0203
2026-01-30 14:01:24 | INFO | Epoch 23 | Batch 100/1169 | Loss: 0.0221
2026-01-30 14:01:29 | INFO | Epoch 23 | Batch 200/1169 | Loss: 0.0199
2026-01-30 14:01:34 | INFO | Epoch 23 | Batch 300/1169 | Loss: 0.0183
2026-01-30 14:01:39 | INFO | Epoch 23 | Batch 400/1169 | Loss: 0.0212
2026-01-30 14:01:44 | INFO | Epoch 23 | Batch 500/1169 | Loss: 0.0203
2026-01-30 14:01:49 | INFO | Epoch 23 | Batch 600/1169 | Loss: 0.0187
2026-01-30 14:01:54 | INFO | Epoch 23 | Batch 700/1169 | Loss: 0.0178
2026-01-30 14:02:00 | INFO | Epoch 23 | Batch 800/1169 | Loss: 0.0166
2026-01-30 14:02:05 | INFO | Epoch 23 | Batch 900/1169 | Loss: 0.0225
2026-01-30 14:02:11 | INFO | Epoch 23 | Batch 1000/1169 | Loss: 0.0149
2026-01-30 14:02:16 | INFO | Epoch 23 | Batch 1100/1169 | Loss: 0.0230
2026-01-30 14:02:25 | INFO | Epoch 23 | Train Loss: 0.0192 | Val Loss: 0.0180
2026-01-30 14:02:25 | INFO | Val F1: 0.3592 | Prec: 0.2326 | Rec: 0.7884 | AUC: 0.9242
2026-01-30 14:02:25 | INFO | Epoch 24 | Batch 0/1169 | Loss: 0.0172
2026-01-30 14:02:30 | INFO | Epoch 24 | Batch 100/1169 | Loss: 0.0197
2026-01-30 14:02:36 | INFO | Epoch 24 | Batch 200/1169 | Loss: 0.0192
2026-01-30 14:02:42 | INFO | Epoch 24 | Batch 300/1169 | Loss: 0.0215
2026-01-30 14:02:48 | INFO | Epoch 24 | Batch 400/1169 | Loss: 0.0199
2026-01-30 14:02:55 | INFO | Epoch 24 | Batch 500/1169 | Loss: 0.0213
2026-01-30 14:03:01 | INFO | Epoch 24 | Batch 600/1169 | Loss: 0.0187
2026-01-30 14:03:07 | INFO | Epoch 24 | Batch 700/1169 | Loss: 0.0161
2026-01-30 14:03:12 | INFO | Epoch 24 | Batch 800/1169 | Loss: 0.0151
2026-01-30 14:03:17 | INFO | Epoch 24 | Batch 900/1169 | Loss: 0.0190
2026-01-30 14:03:22 | INFO | Epoch 24 | Batch 1000/1169 | Loss: 0.0211
2026-01-30 14:03:27 | INFO | Epoch 24 | Batch 1100/1169 | Loss: 0.0181
2026-01-30 14:03:36 | INFO | Epoch 24 | Train Loss: 0.0190 | Val Loss: 0.0201
2026-01-30 14:03:36 | INFO | Val F1: 0.3291 | Prec: 0.2065 | Rec: 0.8097 | AUC: 0.9235
2026-01-30 14:03:36 | INFO | Epoch 25 | Batch 0/1169 | Loss: 0.0188
2026-01-30 14:03:41 | INFO | Epoch 25 | Batch 100/1169 | Loss: 0.0179
2026-01-30 14:03:46 | INFO | Epoch 25 | Batch 200/1169 | Loss: 0.0201
2026-01-30 14:03:51 | INFO | Epoch 25 | Batch 300/1169 | Loss: 0.0167
2026-01-30 14:03:57 | INFO | Epoch 25 | Batch 400/1169 | Loss: 0.0160
2026-01-30 14:04:02 | INFO | Epoch 25 | Batch 500/1169 | Loss: 0.0169
2026-01-30 14:04:07 | INFO | Epoch 25 | Batch 600/1169 | Loss: 0.0201
2026-01-30 14:04:12 | INFO | Epoch 25 | Batch 700/1169 | Loss: 0.0151
2026-01-30 14:04:17 | INFO | Epoch 25 | Batch 800/1169 | Loss: 0.0184
2026-01-30 14:04:22 | INFO | Epoch 25 | Batch 900/1169 | Loss: 0.0215
2026-01-30 14:04:27 | INFO | Epoch 25 | Batch 1000/1169 | Loss: 0.0151
2026-01-30 14:04:32 | INFO | Epoch 25 | Batch 1100/1169 | Loss: 0.0178
2026-01-30 14:04:40 | INFO | Epoch 25 | Train Loss: 0.0188 | Val Loss: 0.0180
2026-01-30 14:04:40 | INFO | Val F1: 0.3555 | Prec: 0.2282 | Rec: 0.8045 | AUC: 0.9281
2026-01-30 14:04:40 | INFO | Epoch 26 | Batch 0/1169 | Loss: 0.0185
2026-01-30 14:04:45 | INFO | Epoch 26 | Batch 100/1169 | Loss: 0.0223
2026-01-30 14:04:50 | INFO | Epoch 26 | Batch 200/1169 | Loss: 0.0210
2026-01-30 14:04:56 | INFO | Epoch 26 | Batch 300/1169 | Loss: 0.0178
2026-01-30 14:05:01 | INFO | Epoch 26 | Batch 400/1169 | Loss: 0.0183
2026-01-30 14:05:06 | INFO | Epoch 26 | Batch 500/1169 | Loss: 0.0177
2026-01-30 14:05:11 | INFO | Epoch 26 | Batch 600/1169 | Loss: 0.0220
2026-01-30 14:05:15 | INFO | Epoch 26 | Batch 700/1169 | Loss: 0.0180
2026-01-30 14:05:20 | INFO | Epoch 26 | Batch 800/1169 | Loss: 0.0222
2026-01-30 14:05:25 | INFO | Epoch 26 | Batch 900/1169 | Loss: 0.0165
2026-01-30 14:05:30 | INFO | Epoch 26 | Batch 1000/1169 | Loss: 0.0189
2026-01-30 14:05:35 | INFO | Epoch 26 | Batch 1100/1169 | Loss: 0.0156
2026-01-30 14:05:43 | INFO | Epoch 26 | Train Loss: 0.0185 | Val Loss: 0.0163
2026-01-30 14:05:43 | INFO | Val F1: 0.4072 | Prec: 0.2763 | Rec: 0.7735 | AUC: 0.9279
2026-01-30 14:05:43 | INFO | New best model saved (F1: 0.4072)
2026-01-30 14:05:43 | INFO | Epoch 27 | Batch 0/1169 | Loss: 0.0180
2026-01-30 14:05:48 | INFO | Epoch 27 | Batch 100/1169 | Loss: 0.0205
2026-01-30 14:05:54 | INFO | Epoch 27 | Batch 200/1169 | Loss: 0.0186
2026-01-30 14:05:59 | INFO | Epoch 27 | Batch 300/1169 | Loss: 0.0161
2026-01-30 14:06:05 | INFO | Epoch 27 | Batch 400/1169 | Loss: 0.0195
2026-01-30 14:06:10 | INFO | Epoch 27 | Batch 500/1169 | Loss: 0.0200
2026-01-30 14:06:16 | INFO | Epoch 27 | Batch 600/1169 | Loss: 0.0174
2026-01-30 14:06:21 | INFO | Epoch 27 | Batch 700/1169 | Loss: 0.0154
2026-01-30 14:06:27 | INFO | Epoch 27 | Batch 800/1169 | Loss: 0.0166
2026-01-30 14:06:32 | INFO | Epoch 27 | Batch 900/1169 | Loss: 0.0182
2026-01-30 14:06:38 | INFO | Epoch 27 | Batch 1000/1169 | Loss: 0.0193
2026-01-30 14:06:43 | INFO | Epoch 27 | Batch 1100/1169 | Loss: 0.0148
2026-01-30 14:06:51 | INFO | Epoch 27 | Train Loss: 0.0185 | Val Loss: 0.0166
2026-01-30 14:06:51 | INFO | Val F1: 0.4022 | Prec: 0.2700 | Rec: 0.7887 | AUC: 0.9280
2026-01-30 14:06:51 | INFO | Epoch 28 | Batch 0/1169 | Loss: 0.0213
2026-01-30 14:06:56 | INFO | Epoch 28 | Batch 100/1169 | Loss: 0.0154
2026-01-30 14:07:02 | INFO | Epoch 28 | Batch 200/1169 | Loss: 0.0160
2026-01-30 14:07:08 | INFO | Epoch 28 | Batch 300/1169 | Loss: 0.0172
2026-01-30 14:07:13 | INFO | Epoch 28 | Batch 400/1169 | Loss: 0.0187
2026-01-30 14:07:18 | INFO | Epoch 28 | Batch 500/1169 | Loss: 0.0197
2026-01-30 14:07:24 | INFO | Epoch 28 | Batch 600/1169 | Loss: 0.0174
2026-01-30 14:07:29 | INFO | Epoch 28 | Batch 700/1169 | Loss: 0.0188
2026-01-30 14:07:34 | INFO | Epoch 28 | Batch 800/1169 | Loss: 0.0181
2026-01-30 14:07:40 | INFO | Epoch 28 | Batch 900/1169 | Loss: 0.0191
2026-01-30 14:07:45 | INFO | Epoch 28 | Batch 1000/1169 | Loss: 0.0182
2026-01-30 14:07:50 | INFO | Epoch 28 | Batch 1100/1169 | Loss: 0.0226
2026-01-30 14:07:58 | INFO | Epoch 28 | Train Loss: 0.0184 | Val Loss: 0.0202
2026-01-30 14:07:58 | INFO | Val F1: 0.3105 | Prec: 0.1911 | Rec: 0.8274 | AUC: 0.9259
2026-01-30 14:07:58 | INFO | Epoch 29 | Batch 0/1169 | Loss: 0.0179
2026-01-30 14:08:03 | INFO | Epoch 29 | Batch 100/1169 | Loss: 0.0178
2026-01-30 14:08:08 | INFO | Epoch 29 | Batch 200/1169 | Loss: 0.0168
2026-01-30 14:08:13 | INFO | Epoch 29 | Batch 300/1169 | Loss: 0.0161
2026-01-30 14:08:18 | INFO | Epoch 29 | Batch 400/1169 | Loss: 0.0155
2026-01-30 14:08:23 | INFO | Epoch 29 | Batch 500/1169 | Loss: 0.0185
2026-01-30 14:08:28 | INFO | Epoch 29 | Batch 600/1169 | Loss: 0.0185
2026-01-30 14:08:33 | INFO | Epoch 29 | Batch 700/1169 | Loss: 0.0218
2026-01-30 14:08:38 | INFO | Epoch 29 | Batch 800/1169 | Loss: 0.0185
2026-01-30 14:08:43 | INFO | Epoch 29 | Batch 900/1169 | Loss: 0.0163
2026-01-30 14:08:48 | INFO | Epoch 29 | Batch 1000/1169 | Loss: 0.0203
2026-01-30 14:08:53 | INFO | Epoch 29 | Batch 1100/1169 | Loss: 0.0152
2026-01-30 14:09:00 | INFO | Epoch 29 | Train Loss: 0.0180 | Val Loss: 0.0201
2026-01-30 14:09:00 | INFO | Val F1: 0.3289 | Prec: 0.2062 | Rec: 0.8126 | AUC: 0.9265
2026-01-30 14:09:00 | INFO | Epoch 30 | Batch 0/1169 | Loss: 0.0165
2026-01-30 14:09:05 | INFO | Epoch 30 | Batch 100/1169 | Loss: 0.0181
2026-01-30 14:09:10 | INFO | Epoch 30 | Batch 200/1169 | Loss: 0.0196
2026-01-30 14:09:15 | INFO | Epoch 30 | Batch 300/1169 | Loss: 0.0177
2026-01-30 14:09:21 | INFO | Epoch 30 | Batch 400/1169 | Loss: 0.0150
2026-01-30 14:09:26 | INFO | Epoch 30 | Batch 500/1169 | Loss: 0.0156
2026-01-30 14:09:31 | INFO | Epoch 30 | Batch 600/1169 | Loss: 0.0153
2026-01-30 14:09:36 | INFO | Epoch 30 | Batch 700/1169 | Loss: 0.0167
2026-01-30 14:09:41 | INFO | Epoch 30 | Batch 800/1169 | Loss: 0.0175
2026-01-30 14:09:46 | INFO | Epoch 30 | Batch 900/1169 | Loss: 0.0202
2026-01-30 14:09:52 | INFO | Epoch 30 | Batch 1000/1169 | Loss: 0.0121
2026-01-30 14:09:57 | INFO | Epoch 30 | Batch 1100/1169 | Loss: 0.0173
2026-01-30 14:10:05 | INFO | Epoch 30 | Train Loss: 0.0179 | Val Loss: 0.0186
2026-01-30 14:10:05 | INFO | Val F1: 0.3486 | Prec: 0.2225 | Rec: 0.8048 | AUC: 0.9273
2026-01-30 14:10:06 | INFO | Epoch 31 | Batch 0/1169 | Loss: 0.0193
2026-01-30 14:10:11 | INFO | Epoch 31 | Batch 100/1169 | Loss: 0.0202
2026-01-30 14:10:16 | INFO | Epoch 31 | Batch 200/1169 | Loss: 0.0157
2026-01-30 14:10:21 | INFO | Epoch 31 | Batch 300/1169 | Loss: 0.0169
2026-01-30 14:10:27 | INFO | Epoch 31 | Batch 400/1169 | Loss: 0.0183
2026-01-30 14:10:32 | INFO | Epoch 31 | Batch 500/1169 | Loss: 0.0201
2026-01-30 14:10:37 | INFO | Epoch 31 | Batch 600/1169 | Loss: 0.0237
2026-01-30 14:10:43 | INFO | Epoch 31 | Batch 700/1169 | Loss: 0.0163
2026-01-30 14:10:48 | INFO | Epoch 31 | Batch 800/1169 | Loss: 0.0174
2026-01-30 14:10:54 | INFO | Epoch 31 | Batch 900/1169 | Loss: 0.0176
2026-01-30 14:10:59 | INFO | Epoch 31 | Batch 1000/1169 | Loss: 0.0157
2026-01-30 14:11:04 | INFO | Epoch 31 | Batch 1100/1169 | Loss: 0.0190
2026-01-30 14:11:13 | INFO | Epoch 31 | Train Loss: 0.0178 | Val Loss: 0.0187
2026-01-30 14:11:13 | INFO | Val F1: 0.3461 | Prec: 0.2197 | Rec: 0.8142 | AUC: 0.9290
2026-01-30 14:11:13 | INFO | Epoch 32 | Batch 0/1169 | Loss: 0.0167
2026-01-30 14:11:18 | INFO | Epoch 32 | Batch 100/1169 | Loss: 0.0174
2026-01-30 14:11:24 | INFO | Epoch 32 | Batch 200/1169 | Loss: 0.0174
2026-01-30 14:11:29 | INFO | Epoch 32 | Batch 300/1169 | Loss: 0.0219
2026-01-30 14:11:34 | INFO | Epoch 32 | Batch 400/1169 | Loss: 0.0183
2026-01-30 14:11:40 | INFO | Epoch 32 | Batch 500/1169 | Loss: 0.0157
2026-01-30 14:11:46 | INFO | Epoch 32 | Batch 600/1169 | Loss: 0.0159
2026-01-30 14:11:50 | INFO | Epoch 32 | Batch 700/1169 | Loss: 0.0174
2026-01-30 14:11:56 | INFO | Epoch 32 | Batch 800/1169 | Loss: 0.0161
2026-01-30 14:12:00 | INFO | Epoch 32 | Batch 900/1169 | Loss: 0.0208
2026-01-30 14:12:05 | INFO | Epoch 32 | Batch 1000/1169 | Loss: 0.0161
2026-01-30 14:12:10 | INFO | Epoch 32 | Batch 1100/1169 | Loss: 0.0190
2026-01-30 14:12:18 | INFO | Epoch 32 | Train Loss: 0.0177 | Val Loss: 0.0170
2026-01-30 14:12:18 | INFO | Val F1: 0.3951 | Prec: 0.2634 | Rec: 0.7900 | AUC: 0.9298
2026-01-30 14:12:18 | INFO | Epoch 33 | Batch 0/1169 | Loss: 0.0199
2026-01-30 14:12:23 | INFO | Epoch 33 | Batch 100/1169 | Loss: 0.0127
2026-01-30 14:12:28 | INFO | Epoch 33 | Batch 200/1169 | Loss: 0.0161
2026-01-30 14:12:33 | INFO | Epoch 33 | Batch 300/1169 | Loss: 0.0141
2026-01-30 14:12:38 | INFO | Epoch 33 | Batch 400/1169 | Loss: 0.0193
2026-01-30 14:12:43 | INFO | Epoch 33 | Batch 500/1169 | Loss: 0.0155
2026-01-30 14:12:48 | INFO | Epoch 33 | Batch 600/1169 | Loss: 0.0152
2026-01-30 14:12:54 | INFO | Epoch 33 | Batch 700/1169 | Loss: 0.0159
2026-01-30 14:12:59 | INFO | Epoch 33 | Batch 800/1169 | Loss: 0.0145
2026-01-30 14:13:04 | INFO | Epoch 33 | Batch 900/1169 | Loss: 0.0171
2026-01-30 14:13:10 | INFO | Epoch 33 | Batch 1000/1169 | Loss: 0.0142
2026-01-30 14:13:15 | INFO | Epoch 33 | Batch 1100/1169 | Loss: 0.0164
2026-01-30 14:13:22 | INFO | Epoch 33 | Train Loss: 0.0163 | Val Loss: 0.0172
2026-01-30 14:13:22 | INFO | Val F1: 0.3947 | Prec: 0.2628 | Rec: 0.7929 | AUC: 0.9310
2026-01-30 14:13:22 | INFO | Epoch 34 | Batch 0/1169 | Loss: 0.0217
2026-01-30 14:13:27 | INFO | Epoch 34 | Batch 100/1169 | Loss: 0.0162
2026-01-30 14:13:32 | INFO | Epoch 34 | Batch 200/1169 | Loss: 0.0143
2026-01-30 14:13:37 | INFO | Epoch 34 | Batch 300/1169 | Loss: 0.0133
2026-01-30 14:13:42 | INFO | Epoch 34 | Batch 400/1169 | Loss: 0.0186
2026-01-30 14:13:48 | INFO | Epoch 34 | Batch 500/1169 | Loss: 0.0131
2026-01-30 14:13:53 | INFO | Epoch 34 | Batch 600/1169 | Loss: 0.0166
2026-01-30 14:13:59 | INFO | Epoch 34 | Batch 700/1169 | Loss: 0.0163
2026-01-30 14:14:05 | INFO | Epoch 34 | Batch 800/1169 | Loss: 0.0137
2026-01-30 14:14:10 | INFO | Epoch 34 | Batch 900/1169 | Loss: 0.0215
2026-01-30 14:14:15 | INFO | Epoch 34 | Batch 1000/1169 | Loss: 0.0168
2026-01-30 14:14:21 | INFO | Epoch 34 | Batch 1100/1169 | Loss: 0.0158
2026-01-30 14:14:29 | INFO | Epoch 34 | Train Loss: 0.0158 | Val Loss: 0.0162
2026-01-30 14:14:29 | INFO | Val F1: 0.4196 | Prec: 0.2876 | Rec: 0.7758 | AUC: 0.9297
2026-01-30 14:14:29 | INFO | New best model saved (F1: 0.4196)
2026-01-30 14:14:29 | INFO | Epoch 35 | Batch 0/1169 | Loss: 0.0158
2026-01-30 14:14:34 | INFO | Epoch 35 | Batch 100/1169 | Loss: 0.0177
2026-01-30 14:14:39 | INFO | Epoch 35 | Batch 200/1169 | Loss: 0.0152
2026-01-30 14:14:45 | INFO | Epoch 35 | Batch 300/1169 | Loss: 0.0177
2026-01-30 14:14:50 | INFO | Epoch 35 | Batch 400/1169 | Loss: 0.0164
2026-01-30 14:14:55 | INFO | Epoch 35 | Batch 500/1169 | Loss: 0.0152
2026-01-30 14:15:01 | INFO | Epoch 35 | Batch 600/1169 | Loss: 0.0142
2026-01-30 14:15:07 | INFO | Epoch 35 | Batch 700/1169 | Loss: 0.0123
2026-01-30 14:15:12 | INFO | Epoch 35 | Batch 800/1169 | Loss: 0.0158
2026-01-30 14:15:17 | INFO | Epoch 35 | Batch 900/1169 | Loss: 0.0147
2026-01-30 14:15:23 | INFO | Epoch 35 | Batch 1000/1169 | Loss: 0.0132
2026-01-30 14:15:28 | INFO | Epoch 35 | Batch 1100/1169 | Loss: 0.0183
2026-01-30 14:15:36 | INFO | Epoch 35 | Train Loss: 0.0157 | Val Loss: 0.0186
2026-01-30 14:15:36 | INFO | Val F1: 0.3762 | Prec: 0.2449 | Rec: 0.8110 | AUC: 0.9301
2026-01-30 14:15:36 | INFO | Epoch 36 | Batch 0/1169 | Loss: 0.0135
2026-01-30 14:15:41 | INFO | Epoch 36 | Batch 100/1169 | Loss: 0.0193
2026-01-30 14:15:47 | INFO | Epoch 36 | Batch 200/1169 | Loss: 0.0169
2026-01-30 14:15:52 | INFO | Epoch 36 | Batch 300/1169 | Loss: 0.0174
2026-01-30 14:15:57 | INFO | Epoch 36 | Batch 400/1169 | Loss: 0.0161
2026-01-30 14:16:02 | INFO | Epoch 36 | Batch 500/1169 | Loss: 0.0152
2026-01-30 14:16:07 | INFO | Epoch 36 | Batch 600/1169 | Loss: 0.0134
2026-01-30 14:16:12 | INFO | Epoch 36 | Batch 700/1169 | Loss: 0.0161
2026-01-30 14:16:17 | INFO | Epoch 36 | Batch 800/1169 | Loss: 0.0131
2026-01-30 14:16:22 | INFO | Epoch 36 | Batch 900/1169 | Loss: 0.0154
2026-01-30 14:16:27 | INFO | Epoch 36 | Batch 1000/1169 | Loss: 0.0116
2026-01-30 14:16:33 | INFO | Epoch 36 | Batch 1100/1169 | Loss: 0.0159
2026-01-30 14:16:41 | INFO | Epoch 36 | Train Loss: 0.0156 | Val Loss: 0.0185
2026-01-30 14:16:41 | INFO | Val F1: 0.3697 | Prec: 0.2401 | Rec: 0.8035 | AUC: 0.9289
2026-01-30 14:16:41 | INFO | Epoch 37 | Batch 0/1169 | Loss: 0.0163
2026-01-30 14:16:46 | INFO | Epoch 37 | Batch 100/1169 | Loss: 0.0143
2026-01-30 14:16:51 | INFO | Epoch 37 | Batch 200/1169 | Loss: 0.0150
2026-01-30 14:16:56 | INFO | Epoch 37 | Batch 300/1169 | Loss: 0.0137
2026-01-30 14:17:01 | INFO | Epoch 37 | Batch 400/1169 | Loss: 0.0163
2026-01-30 14:17:07 | INFO | Epoch 37 | Batch 500/1169 | Loss: 0.0140
2026-01-30 14:17:12 | INFO | Epoch 37 | Batch 600/1169 | Loss: 0.0162
2026-01-30 14:17:17 | INFO | Epoch 37 | Batch 700/1169 | Loss: 0.0139
2026-01-30 14:17:22 | INFO | Epoch 37 | Batch 800/1169 | Loss: 0.0121
2026-01-30 14:17:27 | INFO | Epoch 37 | Batch 900/1169 | Loss: 0.0138
2026-01-30 14:17:32 | INFO | Epoch 37 | Batch 1000/1169 | Loss: 0.0162
2026-01-30 14:17:38 | INFO | Epoch 37 | Batch 1100/1169 | Loss: 0.0099
2026-01-30 14:17:45 | INFO | Epoch 37 | Train Loss: 0.0154 | Val Loss: 0.0180
2026-01-30 14:17:45 | INFO | Val F1: 0.3687 | Prec: 0.2398 | Rec: 0.7977 | AUC: 0.9290
2026-01-30 14:17:46 | INFO | Epoch 38 | Batch 0/1169 | Loss: 0.0167
2026-01-30 14:17:51 | INFO | Epoch 38 | Batch 100/1169 | Loss: 0.0155
2026-01-30 14:17:56 | INFO | Epoch 38 | Batch 200/1169 | Loss: 0.0105
2026-01-30 14:18:02 | INFO | Epoch 38 | Batch 300/1169 | Loss: 0.0144
2026-01-30 14:18:08 | INFO | Epoch 38 | Batch 400/1169 | Loss: 0.0132
2026-01-30 14:18:14 | INFO | Epoch 38 | Batch 500/1169 | Loss: 0.0131
2026-01-30 14:18:19 | INFO | Epoch 38 | Batch 600/1169 | Loss: 0.0154
2026-01-30 14:18:25 | INFO | Epoch 38 | Batch 700/1169 | Loss: 0.0133
2026-01-30 14:18:30 | INFO | Epoch 38 | Batch 800/1169 | Loss: 0.0151
2026-01-30 14:18:35 | INFO | Epoch 38 | Batch 900/1169 | Loss: 0.0238
2026-01-30 14:18:41 | INFO | Epoch 38 | Batch 1000/1169 | Loss: 0.0131
2026-01-30 14:18:46 | INFO | Epoch 38 | Batch 1100/1169 | Loss: 0.0136
2026-01-30 14:18:55 | INFO | Epoch 38 | Train Loss: 0.0154 | Val Loss: 0.0176
2026-01-30 14:18:55 | INFO | Val F1: 0.3870 | Prec: 0.2552 | Rec: 0.8003 | AUC: 0.9302
2026-01-30 14:18:55 | INFO | Epoch 39 | Batch 0/1169 | Loss: 0.0172
2026-01-30 14:19:00 | INFO | Epoch 39 | Batch 100/1169 | Loss: 0.0155
2026-01-30 14:19:06 | INFO | Epoch 39 | Batch 200/1169 | Loss: 0.0127
2026-01-30 14:19:11 | INFO | Epoch 39 | Batch 300/1169 | Loss: 0.0120
2026-01-30 14:19:16 | INFO | Epoch 39 | Batch 400/1169 | Loss: 0.0123
2026-01-30 14:19:22 | INFO | Epoch 39 | Batch 500/1169 | Loss: 0.0160
2026-01-30 14:19:27 | INFO | Epoch 39 | Batch 600/1169 | Loss: 0.0171
2026-01-30 14:19:32 | INFO | Epoch 39 | Batch 700/1169 | Loss: 0.0159
2026-01-30 14:19:38 | INFO | Epoch 39 | Batch 800/1169 | Loss: 0.0117
2026-01-30 14:19:43 | INFO | Epoch 39 | Batch 900/1169 | Loss: 0.0155
2026-01-30 14:19:48 | INFO | Epoch 39 | Batch 1000/1169 | Loss: 0.0141
2026-01-30 14:19:53 | INFO | Epoch 39 | Batch 1100/1169 | Loss: 0.0116
2026-01-30 14:20:01 | INFO | Epoch 39 | Train Loss: 0.0152 | Val Loss: 0.0164
2026-01-30 14:20:01 | INFO | Val F1: 0.4173 | Prec: 0.2832 | Rec: 0.7926 | AUC: 0.9309
2026-01-30 14:20:01 | INFO | Epoch 40 | Batch 0/1169 | Loss: 0.0156
2026-01-30 14:20:07 | INFO | Epoch 40 | Batch 100/1169 | Loss: 0.0131
2026-01-30 14:20:12 | INFO | Epoch 40 | Batch 200/1169 | Loss: 0.0146
2026-01-30 14:20:17 | INFO | Epoch 40 | Batch 300/1169 | Loss: 0.0138
2026-01-30 14:20:22 | INFO | Epoch 40 | Batch 400/1169 | Loss: 0.0136
2026-01-30 14:20:27 | INFO | Epoch 40 | Batch 500/1169 | Loss: 0.0132
2026-01-30 14:20:33 | INFO | Epoch 40 | Batch 600/1169 | Loss: 0.0146
2026-01-30 14:20:38 | INFO | Epoch 40 | Batch 700/1169 | Loss: 0.0109
2026-01-30 14:20:43 | INFO | Epoch 40 | Batch 800/1169 | Loss: 0.0135
2026-01-30 14:20:48 | INFO | Epoch 40 | Batch 900/1169 | Loss: 0.0154
2026-01-30 14:20:53 | INFO | Epoch 40 | Batch 1000/1169 | Loss: 0.0143
2026-01-30 14:20:58 | INFO | Epoch 40 | Batch 1100/1169 | Loss: 0.0127
2026-01-30 14:21:06 | INFO | Epoch 40 | Train Loss: 0.0152 | Val Loss: 0.0175
2026-01-30 14:21:06 | INFO | Val F1: 0.3939 | Prec: 0.2615 | Rec: 0.7974 | AUC: 0.9302
2026-01-30 14:21:06 | INFO | Epoch 41 | Batch 0/1169 | Loss: 0.0137
2026-01-30 14:21:11 | INFO | Epoch 41 | Batch 100/1169 | Loss: 0.0164
2026-01-30 14:21:16 | INFO | Epoch 41 | Batch 200/1169 | Loss: 0.0164
2026-01-30 14:21:21 | INFO | Epoch 41 | Batch 300/1169 | Loss: 0.0169
2026-01-30 14:21:26 | INFO | Epoch 41 | Batch 400/1169 | Loss: 0.0155
2026-01-30 14:21:31 | INFO | Epoch 41 | Batch 500/1169 | Loss: 0.0139
2026-01-30 14:21:37 | INFO | Epoch 41 | Batch 600/1169 | Loss: 0.0149
2026-01-30 14:21:42 | INFO | Epoch 41 | Batch 700/1169 | Loss: 0.0161
2026-01-30 14:21:48 | INFO | Epoch 41 | Batch 800/1169 | Loss: 0.0154
2026-01-30 14:21:54 | INFO | Epoch 41 | Batch 900/1169 | Loss: 0.0150
2026-01-30 14:21:59 | INFO | Epoch 41 | Batch 1000/1169 | Loss: 0.0135
2026-01-30 14:22:04 | INFO | Epoch 41 | Batch 1100/1169 | Loss: 0.0138
2026-01-30 14:22:12 | INFO | Epoch 41 | Train Loss: 0.0144 | Val Loss: 0.0162
2026-01-30 14:22:12 | INFO | Val F1: 0.4322 | Prec: 0.2988 | Rec: 0.7806 | AUC: 0.9310
2026-01-30 14:22:12 | INFO | New best model saved (F1: 0.4322)
2026-01-30 14:22:12 | INFO | Epoch 42 | Batch 0/1169 | Loss: 0.0134
2026-01-30 14:22:18 | INFO | Epoch 42 | Batch 100/1169 | Loss: 0.0162
2026-01-30 14:22:23 | INFO | Epoch 42 | Batch 200/1169 | Loss: 0.0154
2026-01-30 14:22:29 | INFO | Epoch 42 | Batch 300/1169 | Loss: 0.0120
2026-01-30 14:22:34 | INFO | Epoch 42 | Batch 400/1169 | Loss: 0.0134
2026-01-30 14:22:40 | INFO | Epoch 42 | Batch 500/1169 | Loss: 0.0140
2026-01-30 14:22:45 | INFO | Epoch 42 | Batch 600/1169 | Loss: 0.0134
2026-01-30 14:22:51 | INFO | Epoch 42 | Batch 700/1169 | Loss: 0.0158
2026-01-30 14:22:56 | INFO | Epoch 42 | Batch 800/1169 | Loss: 0.0135
2026-01-30 14:23:01 | INFO | Epoch 42 | Batch 900/1169 | Loss: 0.0118
2026-01-30 14:23:07 | INFO | Epoch 42 | Batch 1000/1169 | Loss: 0.0139
2026-01-30 14:23:12 | INFO | Epoch 42 | Batch 1100/1169 | Loss: 0.0155
2026-01-30 14:23:20 | INFO | Epoch 42 | Train Loss: 0.0142 | Val Loss: 0.0178
2026-01-30 14:23:20 | INFO | Val F1: 0.3939 | Prec: 0.2615 | Rec: 0.7977 | AUC: 0.9312
2026-01-30 14:23:20 | INFO | Epoch 43 | Batch 0/1169 | Loss: 0.0142
2026-01-30 14:23:26 | INFO | Epoch 43 | Batch 100/1169 | Loss: 0.0122
2026-01-30 14:23:31 | INFO | Epoch 43 | Batch 200/1169 | Loss: 0.0145
2026-01-30 14:23:37 | INFO | Epoch 43 | Batch 300/1169 | Loss: 0.0118
2026-01-30 14:23:42 | INFO | Epoch 43 | Batch 400/1169 | Loss: 0.0140
2026-01-30 14:23:47 | INFO | Epoch 43 | Batch 500/1169 | Loss: 0.0147
2026-01-30 14:23:52 | INFO | Epoch 43 | Batch 600/1169 | Loss: 0.0170
2026-01-30 14:23:58 | INFO | Epoch 43 | Batch 700/1169 | Loss: 0.0113
2026-01-30 14:24:03 | INFO | Epoch 43 | Batch 800/1169 | Loss: 0.0145
2026-01-30 14:24:08 | INFO | Epoch 43 | Batch 900/1169 | Loss: 0.0114
2026-01-30 14:24:13 | INFO | Epoch 43 | Batch 1000/1169 | Loss: 0.0148
2026-01-30 14:24:18 | INFO | Epoch 43 | Batch 1100/1169 | Loss: 0.0127
2026-01-30 14:24:25 | INFO | Epoch 43 | Train Loss: 0.0142 | Val Loss: 0.0171
2026-01-30 14:24:25 | INFO | Val F1: 0.4058 | Prec: 0.2726 | Rec: 0.7939 | AUC: 0.9295
2026-01-30 14:24:25 | INFO | Epoch 44 | Batch 0/1169 | Loss: 0.0109
2026-01-30 14:24:31 | INFO | Epoch 44 | Batch 100/1169 | Loss: 0.0116
2026-01-30 14:24:36 | INFO | Epoch 44 | Batch 200/1169 | Loss: 0.0123
2026-01-30 14:24:41 | INFO | Epoch 44 | Batch 300/1169 | Loss: 0.0126
2026-01-30 14:24:46 | INFO | Epoch 44 | Batch 400/1169 | Loss: 0.0139
2026-01-30 14:24:51 | INFO | Epoch 44 | Batch 500/1169 | Loss: 0.0117
2026-01-30 14:24:57 | INFO | Epoch 44 | Batch 600/1169 | Loss: 0.0116
2026-01-30 14:25:02 | INFO | Epoch 44 | Batch 700/1169 | Loss: 0.0107
2026-01-30 14:25:07 | INFO | Epoch 44 | Batch 800/1169 | Loss: 0.0117
2026-01-30 14:25:12 | INFO | Epoch 44 | Batch 900/1169 | Loss: 0.0152
2026-01-30 14:25:17 | INFO | Epoch 44 | Batch 1000/1169 | Loss: 0.0175
2026-01-30 14:25:23 | INFO | Epoch 44 | Batch 1100/1169 | Loss: 0.0125
2026-01-30 14:25:31 | INFO | Epoch 44 | Train Loss: 0.0141 | Val Loss: 0.0177
2026-01-30 14:25:31 | INFO | Val F1: 0.4009 | Prec: 0.2673 | Rec: 0.8019 | AUC: 0.9310
2026-01-30 14:25:31 | INFO | Epoch 45 | Batch 0/1169 | Loss: 0.0115
2026-01-30 14:25:36 | INFO | Epoch 45 | Batch 100/1169 | Loss: 0.0155
2026-01-30 14:25:41 | INFO | Epoch 45 | Batch 200/1169 | Loss: 0.0161
2026-01-30 14:25:47 | INFO | Epoch 45 | Batch 300/1169 | Loss: 0.0120
2026-01-30 14:25:52 | INFO | Epoch 45 | Batch 400/1169 | Loss: 0.0127
2026-01-30 14:25:58 | INFO | Epoch 45 | Batch 500/1169 | Loss: 0.0123
2026-01-30 14:26:03 | INFO | Epoch 45 | Batch 600/1169 | Loss: 0.0150
2026-01-30 14:26:09 | INFO | Epoch 45 | Batch 700/1169 | Loss: 0.0157
2026-01-30 14:26:14 | INFO | Epoch 45 | Batch 800/1169 | Loss: 0.0224
2026-01-30 14:26:20 | INFO | Epoch 45 | Batch 900/1169 | Loss: 0.0159
2026-01-30 14:26:26 | INFO | Epoch 45 | Batch 1000/1169 | Loss: 0.0138
2026-01-30 14:26:31 | INFO | Epoch 45 | Batch 1100/1169 | Loss: 0.0125
2026-01-30 14:26:39 | INFO | Epoch 45 | Train Loss: 0.0140 | Val Loss: 0.0175
2026-01-30 14:26:39 | INFO | Val F1: 0.3919 | Prec: 0.2593 | Rec: 0.8016 | AUC: 0.9309
2026-01-30 14:26:39 | INFO | Epoch 46 | Batch 0/1169 | Loss: 0.0127
2026-01-30 14:26:45 | INFO | Epoch 46 | Batch 100/1169 | Loss: 0.0168
2026-01-30 14:26:50 | INFO | Epoch 46 | Batch 200/1169 | Loss: 0.0110
2026-01-30 14:26:56 | INFO | Epoch 46 | Batch 300/1169 | Loss: 0.0149
2026-01-30 14:27:01 | INFO | Epoch 46 | Batch 400/1169 | Loss: 0.0166
2026-01-30 14:27:06 | INFO | Epoch 46 | Batch 500/1169 | Loss: 0.0141
2026-01-30 14:27:12 | INFO | Epoch 46 | Batch 600/1169 | Loss: 0.0100
2026-01-30 14:27:17 | INFO | Epoch 46 | Batch 700/1169 | Loss: 0.0149
2026-01-30 14:27:22 | INFO | Epoch 46 | Batch 800/1169 | Loss: 0.0150
2026-01-30 14:27:28 | INFO | Epoch 46 | Batch 900/1169 | Loss: 0.0142
2026-01-30 14:27:33 | INFO | Epoch 46 | Batch 1000/1169 | Loss: 0.0119
2026-01-30 14:27:38 | INFO | Epoch 46 | Batch 1100/1169 | Loss: 0.0090
2026-01-30 14:27:46 | INFO | Epoch 46 | Train Loss: 0.0140 | Val Loss: 0.0171
2026-01-30 14:27:46 | INFO | Val F1: 0.4127 | Prec: 0.2792 | Rec: 0.7910 | AUC: 0.9305
2026-01-30 14:27:46 | INFO | Epoch 47 | Batch 0/1169 | Loss: 0.0109
2026-01-30 14:27:51 | INFO | Epoch 47 | Batch 100/1169 | Loss: 0.0149
2026-01-30 14:27:56 | INFO | Epoch 47 | Batch 200/1169 | Loss: 0.0166
2026-01-30 14:28:02 | INFO | Epoch 47 | Batch 300/1169 | Loss: 0.0122
2026-01-30 14:28:07 | INFO | Epoch 47 | Batch 400/1169 | Loss: 0.0112
2026-01-30 14:28:12 | INFO | Epoch 47 | Batch 500/1169 | Loss: 0.0118
2026-01-30 14:28:17 | INFO | Epoch 47 | Batch 600/1169 | Loss: 0.0164
2026-01-30 14:28:22 | INFO | Epoch 47 | Batch 700/1169 | Loss: 0.0118
2026-01-30 14:28:27 | INFO | Epoch 47 | Batch 800/1169 | Loss: 0.0140
2026-01-30 14:28:32 | INFO | Epoch 47 | Batch 900/1169 | Loss: 0.0130
2026-01-30 14:28:37 | INFO | Epoch 47 | Batch 1000/1169 | Loss: 0.0130
2026-01-30 14:28:42 | INFO | Epoch 47 | Batch 1100/1169 | Loss: 0.0195
2026-01-30 14:28:51 | INFO | Epoch 47 | Train Loss: 0.0139 | Val Loss: 0.0166
2026-01-30 14:28:51 | INFO | Val F1: 0.4242 | Prec: 0.2902 | Rec: 0.7881 | AUC: 0.9305
2026-01-30 14:28:51 | INFO | Epoch 48 | Batch 0/1169 | Loss: 0.0119
2026-01-30 14:28:56 | INFO | Epoch 48 | Batch 100/1169 | Loss: 0.0133
2026-01-30 14:29:01 | INFO | Epoch 48 | Batch 200/1169 | Loss: 0.0119
2026-01-30 14:29:06 | INFO | Epoch 48 | Batch 300/1169 | Loss: 0.0159
2026-01-30 14:29:12 | INFO | Epoch 48 | Batch 400/1169 | Loss: 0.0120
2026-01-30 14:29:17 | INFO | Epoch 48 | Batch 500/1169 | Loss: 0.0122
2026-01-30 14:29:22 | INFO | Epoch 48 | Batch 600/1169 | Loss: 0.0122
2026-01-30 14:29:27 | INFO | Epoch 48 | Batch 700/1169 | Loss: 0.0116
2026-01-30 14:29:32 | INFO | Epoch 48 | Batch 800/1169 | Loss: 0.0160
2026-01-30 14:29:37 | INFO | Epoch 48 | Batch 900/1169 | Loss: 0.0150
2026-01-30 14:29:43 | INFO | Epoch 48 | Batch 1000/1169 | Loss: 0.0098
2026-01-30 14:29:48 | INFO | Epoch 48 | Batch 1100/1169 | Loss: 0.0133
2026-01-30 14:29:57 | INFO | Epoch 48 | Train Loss: 0.0136 | Val Loss: 0.0176
2026-01-30 14:29:57 | INFO | Val F1: 0.4052 | Prec: 0.2718 | Rec: 0.7955 | AUC: 0.9310
2026-01-30 14:29:57 | INFO | Epoch 49 | Batch 0/1169 | Loss: 0.0144
2026-01-30 14:30:02 | INFO | Epoch 49 | Batch 100/1169 | Loss: 0.0158
2026-01-30 14:30:08 | INFO | Epoch 49 | Batch 200/1169 | Loss: 0.0130
2026-01-30 14:30:13 | INFO | Epoch 49 | Batch 300/1169 | Loss: 0.0121
2026-01-30 14:30:21 | INFO | Epoch 49 | Batch 400/1169 | Loss: 0.0131
2026-01-30 14:30:32 | INFO | Epoch 49 | Batch 500/1169 | Loss: 0.0116
2026-01-30 14:30:43 | INFO | Epoch 49 | Batch 600/1169 | Loss: 0.0137
2026-01-30 14:30:55 | INFO | Epoch 49 | Batch 700/1169 | Loss: 0.0218
2026-01-30 14:31:05 | INFO | Epoch 49 | Batch 800/1169 | Loss: 0.0116
2026-01-30 14:31:16 | INFO | Epoch 49 | Batch 900/1169 | Loss: 0.0106
2026-01-30 14:31:27 | INFO | Epoch 49 | Batch 1000/1169 | Loss: 0.0123
2026-01-30 14:31:38 | INFO | Epoch 49 | Batch 1100/1169 | Loss: 0.0130
2026-01-30 14:31:53 | INFO | Epoch 49 | Train Loss: 0.0134 | Val Loss: 0.0178
2026-01-30 14:31:53 | INFO | Val F1: 0.3994 | Prec: 0.2663 | Rec: 0.7984 | AUC: 0.9300
2026-01-30 14:31:53 | INFO | Epoch 50 | Batch 0/1169 | Loss: 0.0132
2026-01-30 14:32:03 | INFO | Epoch 50 | Batch 100/1169 | Loss: 0.0188
2026-01-30 14:32:14 | INFO | Epoch 50 | Batch 200/1169 | Loss: 0.0173
2026-01-30 14:32:24 | INFO | Epoch 50 | Batch 300/1169 | Loss: 0.0102
2026-01-30 14:32:34 | INFO | Epoch 50 | Batch 400/1169 | Loss: 0.0113
2026-01-30 14:32:45 | INFO | Epoch 50 | Batch 500/1169 | Loss: 0.0117
2026-01-30 14:32:55 | INFO | Epoch 50 | Batch 600/1169 | Loss: 0.0122
2026-01-30 14:33:05 | INFO | Epoch 50 | Batch 700/1169 | Loss: 0.0139
2026-01-30 14:33:15 | INFO | Epoch 50 | Batch 800/1169 | Loss: 0.0127
2026-01-30 14:33:26 | INFO | Epoch 50 | Batch 900/1169 | Loss: 0.0119
2026-01-30 14:33:35 | INFO | Epoch 50 | Batch 1000/1169 | Loss: 0.0118
2026-01-30 14:33:46 | INFO | Epoch 50 | Batch 1100/1169 | Loss: 0.0154
2026-01-30 14:34:01 | INFO | Epoch 50 | Train Loss: 0.0134 | Val Loss: 0.0182
2026-01-30 14:34:01 | INFO | Val F1: 0.3920 | Prec: 0.2593 | Rec: 0.8032 | AUC: 0.9295
2026-01-30 14:34:01 | INFO | Epoch 51 | Batch 0/1169 | Loss: 0.0140
2026-01-30 14:34:12 | INFO | Epoch 51 | Batch 100/1169 | Loss: 0.0155
2026-01-30 14:34:22 | INFO | Epoch 51 | Batch 200/1169 | Loss: 0.0128
2026-01-30 14:34:33 | INFO | Epoch 51 | Batch 300/1169 | Loss: 0.0114
2026-01-30 14:34:43 | INFO | Epoch 51 | Batch 400/1169 | Loss: 0.0138
2026-01-30 14:34:54 | INFO | Epoch 51 | Batch 500/1169 | Loss: 0.0156
2026-01-30 14:35:05 | INFO | Epoch 51 | Batch 600/1169 | Loss: 0.0103
2026-01-30 14:35:15 | INFO | Epoch 51 | Batch 700/1169 | Loss: 0.0128
2026-01-30 14:35:25 | INFO | Epoch 51 | Batch 800/1169 | Loss: 0.0123
2026-01-30 14:35:35 | INFO | Epoch 51 | Batch 900/1169 | Loss: 0.0157
2026-01-30 14:35:46 | INFO | Epoch 51 | Batch 1000/1169 | Loss: 0.0109
2026-01-30 14:35:57 | INFO | Epoch 51 | Batch 1100/1169 | Loss: 0.0153
2026-01-30 14:36:12 | INFO | Epoch 51 | Train Loss: 0.0133 | Val Loss: 0.0183
2026-01-30 14:36:12 | INFO | Val F1: 0.3903 | Prec: 0.2579 | Rec: 0.8013 | AUC: 0.9304
2026-01-30 14:36:12 | INFO | Early stopping at epoch 51
2026-01-30 14:36:22 | INFO | ============================================================
2026-01-30 14:36:22 | INFO | TEST RESULTS (LSTM + GNN + Dense Fusion)
2026-01-30 14:36:22 | INFO | ============================================================
2026-01-30 14:36:22 | INFO | F1: 0.4419
2026-01-30 14:36:22 | INFO | Precision: 0.3048
2026-01-30 14:36:22 | INFO | Recall: 0.8032
2026-01-30 14:36:22 | INFO | AUC: 0.9356
2026-01-30 14:36:22 | INFO | 
Threshold Analysis:
2026-01-30 14:36:22 | INFO | Threshold 0.3: F1=0.2304 | Prec=0.1322 | Rec=0.8974
2026-01-30 14:36:23 | INFO | Threshold 0.5: F1=0.4419 | Prec=0.3048 | Rec=0.8032
2026-01-30 14:36:23 | INFO | Threshold 0.7: F1=0.6556 | Prec=0.6946 | Rec=0.6208
2026-01-30 14:36:23 | INFO | Threshold 0.8: F1=0.6322 | Prec=0.8746 | Rec=0.4950
2026-01-30 14:36:23 | INFO | Threshold 0.9: F1=0.4930 | Prec=0.9652 | Rec=0.3311
