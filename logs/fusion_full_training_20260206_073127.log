2026-02-06 07:31:27 | INFO | Starting FULL FEATURE Fusion Model Training
2026-02-06 07:31:27 | INFO | Features: Temporal=30, Relational=52, Behavioral=353
2026-02-06 07:31:27 | INFO | Total features: 435
2026-02-06 07:31:27 | INFO | Device: cpu
2026-02-06 07:31:28 | INFO | Train batches: 1169
2026-02-06 07:31:28 | INFO | Model parameters: 425,473
2026-02-06 07:31:32 | INFO | Epoch 1 | Batch 0/1169 | Loss: 0.0761
2026-02-06 07:31:38 | INFO | Epoch 1 | Batch 100/1169 | Loss: 0.0407
2026-02-06 07:31:44 | INFO | Epoch 1 | Batch 200/1169 | Loss: 0.0428
2026-02-06 07:31:50 | INFO | Epoch 1 | Batch 300/1169 | Loss: 0.0435
2026-02-06 07:31:56 | INFO | Epoch 1 | Batch 400/1169 | Loss: 0.0398
2026-02-06 07:32:02 | INFO | Epoch 1 | Batch 500/1169 | Loss: 0.0401
2026-02-06 07:32:08 | INFO | Epoch 1 | Batch 600/1169 | Loss: 0.0391
2026-02-06 07:32:14 | INFO | Epoch 1 | Batch 700/1169 | Loss: 0.0417
2026-02-06 07:32:20 | INFO | Epoch 1 | Batch 800/1169 | Loss: 0.0372
2026-02-06 07:32:26 | INFO | Epoch 1 | Batch 900/1169 | Loss: 0.0385
2026-02-06 07:32:32 | INFO | Epoch 1 | Batch 1000/1169 | Loss: 0.0408
2026-02-06 07:32:38 | INFO | Epoch 1 | Batch 1100/1169 | Loss: 0.0327
2026-02-06 07:32:48 | INFO | Epoch 1 | Train Loss: 0.0406 | Val Loss: 0.0343
2026-02-06 07:32:48 | INFO | Val F1: 0.2040 | Prec: 0.1161 | Rec: 0.8413 | AUC: 0.8928
2026-02-06 07:32:48 | INFO | New best model saved (F1: 0.2040)
2026-02-06 07:32:48 | INFO | Epoch 2 | Batch 0/1169 | Loss: 0.0342
2026-02-06 07:32:54 | INFO | Epoch 2 | Batch 100/1169 | Loss: 0.0352
2026-02-06 07:33:00 | INFO | Epoch 2 | Batch 200/1169 | Loss: 0.0360
2026-02-06 07:33:06 | INFO | Epoch 2 | Batch 300/1169 | Loss: 0.0342
2026-02-06 07:33:12 | INFO | Epoch 2 | Batch 400/1169 | Loss: 0.0330
2026-02-06 07:33:18 | INFO | Epoch 2 | Batch 500/1169 | Loss: 0.0354
2026-02-06 07:33:24 | INFO | Epoch 2 | Batch 600/1169 | Loss: 0.0355
2026-02-06 07:33:30 | INFO | Epoch 2 | Batch 700/1169 | Loss: 0.0289
2026-02-06 07:33:36 | INFO | Epoch 2 | Batch 800/1169 | Loss: 0.0319
2026-02-06 07:33:42 | INFO | Epoch 2 | Batch 900/1169 | Loss: 0.0293
2026-02-06 07:33:48 | INFO | Epoch 2 | Batch 1000/1169 | Loss: 0.0292
2026-02-06 07:33:54 | INFO | Epoch 2 | Batch 1100/1169 | Loss: 0.0356
2026-02-06 07:34:03 | INFO | Epoch 2 | Train Loss: 0.0324 | Val Loss: 0.0268
2026-02-06 07:34:03 | INFO | Val F1: 0.2555 | Prec: 0.1519 | Rec: 0.8045 | AUC: 0.9011
2026-02-06 07:34:03 | INFO | New best model saved (F1: 0.2555)
2026-02-06 07:34:03 | INFO | Epoch 3 | Batch 0/1169 | Loss: 0.0291
2026-02-06 07:34:09 | INFO | Epoch 3 | Batch 100/1169 | Loss: 0.0254
2026-02-06 07:34:15 | INFO | Epoch 3 | Batch 200/1169 | Loss: 0.0319
2026-02-06 07:34:21 | INFO | Epoch 3 | Batch 300/1169 | Loss: 0.0276
2026-02-06 07:34:27 | INFO | Epoch 3 | Batch 400/1169 | Loss: 0.0299
2026-02-06 07:34:34 | INFO | Epoch 3 | Batch 500/1169 | Loss: 0.0289
2026-02-06 07:34:40 | INFO | Epoch 3 | Batch 600/1169 | Loss: 0.0345
2026-02-06 07:34:46 | INFO | Epoch 3 | Batch 700/1169 | Loss: 0.0312
2026-02-06 07:34:52 | INFO | Epoch 3 | Batch 800/1169 | Loss: 0.0271
2026-02-06 07:34:58 | INFO | Epoch 3 | Batch 900/1169 | Loss: 0.0374
2026-02-06 07:35:07 | INFO | Epoch 3 | Batch 1000/1169 | Loss: 0.0249
2026-02-06 07:35:14 | INFO | Epoch 3 | Batch 1100/1169 | Loss: 0.0322
2026-02-06 07:35:27 | INFO | Epoch 3 | Train Loss: 0.0287 | Val Loss: 0.0270
2026-02-06 07:35:27 | INFO | Val F1: 0.2724 | Prec: 0.1634 | Rec: 0.8190 | AUC: 0.9105
2026-02-06 07:35:27 | INFO | New best model saved (F1: 0.2724)
2026-02-06 07:35:27 | INFO | Epoch 4 | Batch 0/1169 | Loss: 0.0250
2026-02-06 07:35:39 | INFO | Epoch 4 | Batch 100/1169 | Loss: 0.0269
2026-02-06 07:35:50 | INFO | Epoch 4 | Batch 200/1169 | Loss: 0.0269
2026-02-06 07:36:01 | INFO | Epoch 4 | Batch 300/1169 | Loss: 0.0259
2026-02-06 07:36:12 | INFO | Epoch 4 | Batch 400/1169 | Loss: 0.0277
2026-02-06 07:36:21 | INFO | Epoch 4 | Batch 500/1169 | Loss: 0.0299
2026-02-06 07:36:27 | INFO | Epoch 4 | Batch 600/1169 | Loss: 0.0220
2026-02-06 07:36:33 | INFO | Epoch 4 | Batch 700/1169 | Loss: 0.0265
2026-02-06 07:36:39 | INFO | Epoch 4 | Batch 800/1169 | Loss: 0.0250
2026-02-06 07:36:45 | INFO | Epoch 4 | Batch 900/1169 | Loss: 0.0267
2026-02-06 07:36:51 | INFO | Epoch 4 | Batch 1000/1169 | Loss: 0.0262
2026-02-06 07:36:59 | INFO | Epoch 4 | Batch 1100/1169 | Loss: 0.0263
2026-02-06 07:37:08 | INFO | Epoch 4 | Train Loss: 0.0261 | Val Loss: 0.0255
2026-02-06 07:37:08 | INFO | Val F1: 0.2624 | Prec: 0.1560 | Rec: 0.8248 | AUC: 0.9142
2026-02-06 07:37:09 | INFO | Epoch 5 | Batch 0/1169 | Loss: 0.0295
2026-02-06 07:37:17 | INFO | Epoch 5 | Batch 100/1169 | Loss: 0.0226
2026-02-06 07:37:21 | INFO | Epoch 5 | Batch 200/1169 | Loss: 0.0185
2026-02-06 07:37:24 | INFO | Epoch 5 | Batch 300/1169 | Loss: 0.0241
2026-02-06 07:37:28 | INFO | Epoch 5 | Batch 400/1169 | Loss: 0.0277
2026-02-06 07:37:31 | INFO | Epoch 5 | Batch 500/1169 | Loss: 0.0216
2026-02-06 07:37:35 | INFO | Epoch 5 | Batch 600/1169 | Loss: 0.0296
2026-02-06 07:37:38 | INFO | Epoch 5 | Batch 700/1169 | Loss: 0.0218
2026-02-06 07:37:42 | INFO | Epoch 5 | Batch 800/1169 | Loss: 0.0238
2026-02-06 07:37:45 | INFO | Epoch 5 | Batch 900/1169 | Loss: 0.0259
2026-02-06 07:37:49 | INFO | Epoch 5 | Batch 1000/1169 | Loss: 0.0260
2026-02-06 07:37:52 | INFO | Epoch 5 | Batch 1100/1169 | Loss: 0.0231
2026-02-06 07:37:57 | INFO | Epoch 5 | Train Loss: 0.0241 | Val Loss: 0.0219
2026-02-06 07:37:57 | INFO | Val F1: 0.3014 | Prec: 0.1851 | Rec: 0.8116 | AUC: 0.9166
2026-02-06 07:37:57 | INFO | New best model saved (F1: 0.3014)
2026-02-06 07:37:57 | INFO | Epoch 6 | Batch 0/1169 | Loss: 0.0189
2026-02-06 07:38:00 | INFO | Epoch 6 | Batch 100/1169 | Loss: 0.0209
2026-02-06 07:38:04 | INFO | Epoch 6 | Batch 200/1169 | Loss: 0.0209
2026-02-06 07:38:07 | INFO | Epoch 6 | Batch 300/1169 | Loss: 0.0250
2026-02-06 07:38:10 | INFO | Epoch 6 | Batch 400/1169 | Loss: 0.0256
2026-02-06 07:38:14 | INFO | Epoch 6 | Batch 500/1169 | Loss: 0.0201
2026-02-06 07:38:17 | INFO | Epoch 6 | Batch 600/1169 | Loss: 0.0272
2026-02-06 07:38:21 | INFO | Epoch 6 | Batch 700/1169 | Loss: 0.0195
2026-02-06 07:38:24 | INFO | Epoch 6 | Batch 800/1169 | Loss: 0.0214
2026-02-06 07:38:28 | INFO | Epoch 6 | Batch 900/1169 | Loss: 0.0251
2026-02-06 07:38:31 | INFO | Epoch 6 | Batch 1000/1169 | Loss: 0.0267
2026-02-06 07:38:35 | INFO | Epoch 6 | Batch 1100/1169 | Loss: 0.0315
2026-02-06 07:38:40 | INFO | Epoch 6 | Train Loss: 0.0228 | Val Loss: 0.0205
2026-02-06 07:38:40 | INFO | Val F1: 0.3397 | Prec: 0.2156 | Rec: 0.7997 | AUC: 0.9209
2026-02-06 07:38:40 | INFO | New best model saved (F1: 0.3397)
2026-02-06 07:38:40 | INFO | Epoch 7 | Batch 0/1169 | Loss: 0.0279
2026-02-06 07:38:44 | INFO | Epoch 7 | Batch 100/1169 | Loss: 0.0219
2026-02-06 07:38:48 | INFO | Epoch 7 | Batch 200/1169 | Loss: 0.0233
2026-02-06 07:38:52 | INFO | Epoch 7 | Batch 300/1169 | Loss: 0.0245
2026-02-06 07:38:56 | INFO | Epoch 7 | Batch 400/1169 | Loss: 0.0200
2026-02-06 07:39:00 | INFO | Epoch 7 | Batch 500/1169 | Loss: 0.0258
2026-02-06 07:39:04 | INFO | Epoch 7 | Batch 600/1169 | Loss: 0.0200
2026-02-06 07:39:08 | INFO | Epoch 7 | Batch 700/1169 | Loss: 0.0206
2026-02-06 07:39:12 | INFO | Epoch 7 | Batch 800/1169 | Loss: 0.0199
2026-02-06 07:39:16 | INFO | Epoch 7 | Batch 900/1169 | Loss: 0.0161
2026-02-06 07:39:20 | INFO | Epoch 7 | Batch 1000/1169 | Loss: 0.0207
2026-02-06 07:39:23 | INFO | Epoch 7 | Batch 1100/1169 | Loss: 0.0177
2026-02-06 07:39:29 | INFO | Epoch 7 | Train Loss: 0.0217 | Val Loss: 0.0205
2026-02-06 07:39:29 | INFO | Val F1: 0.3229 | Prec: 0.2019 | Rec: 0.8055 | AUC: 0.9205
2026-02-06 07:39:29 | INFO | Epoch 8 | Batch 0/1169 | Loss: 0.0199
2026-02-06 07:39:33 | INFO | Epoch 8 | Batch 100/1169 | Loss: 0.0191
2026-02-06 07:39:37 | INFO | Epoch 8 | Batch 200/1169 | Loss: 0.0235
2026-02-06 07:39:41 | INFO | Epoch 8 | Batch 300/1169 | Loss: 0.0251
2026-02-06 07:39:44 | INFO | Epoch 8 | Batch 400/1169 | Loss: 0.0211
2026-02-06 07:39:48 | INFO | Epoch 8 | Batch 500/1169 | Loss: 0.0186
2026-02-06 07:39:52 | INFO | Epoch 8 | Batch 600/1169 | Loss: 0.0227
2026-02-06 07:39:56 | INFO | Epoch 8 | Batch 700/1169 | Loss: 0.0202
2026-02-06 07:40:00 | INFO | Epoch 8 | Batch 800/1169 | Loss: 0.0199
2026-02-06 07:40:04 | INFO | Epoch 8 | Batch 900/1169 | Loss: 0.0184
2026-02-06 07:40:08 | INFO | Epoch 8 | Batch 1000/1169 | Loss: 0.0195
2026-02-06 07:40:12 | INFO | Epoch 8 | Batch 1100/1169 | Loss: 0.0219
2026-02-06 07:40:18 | INFO | Epoch 8 | Train Loss: 0.0208 | Val Loss: 0.0183
2026-02-06 07:40:18 | INFO | Val F1: 0.3669 | Prec: 0.2395 | Rec: 0.7839 | AUC: 0.9209
2026-02-06 07:40:18 | INFO | New best model saved (F1: 0.3669)
2026-02-06 07:40:18 | INFO | Epoch 9 | Batch 0/1169 | Loss: 0.0209
2026-02-06 07:40:23 | INFO | Epoch 9 | Batch 100/1169 | Loss: 0.0204
2026-02-06 07:40:27 | INFO | Epoch 9 | Batch 200/1169 | Loss: 0.0207
2026-02-06 07:40:32 | INFO | Epoch 9 | Batch 300/1169 | Loss: 0.0153
2026-02-06 07:40:37 | INFO | Epoch 9 | Batch 400/1169 | Loss: 0.0187
2026-02-06 07:40:41 | INFO | Epoch 9 | Batch 500/1169 | Loss: 0.0170
2026-02-06 07:40:46 | INFO | Epoch 9 | Batch 600/1169 | Loss: 0.0152
2026-02-06 07:40:50 | INFO | Epoch 9 | Batch 700/1169 | Loss: 0.0198
2026-02-06 07:40:55 | INFO | Epoch 9 | Batch 800/1169 | Loss: 0.0194
2026-02-06 07:40:59 | INFO | Epoch 9 | Batch 900/1169 | Loss: 0.0166
2026-02-06 07:41:04 | INFO | Epoch 9 | Batch 1000/1169 | Loss: 0.0180
2026-02-06 07:41:09 | INFO | Epoch 9 | Batch 1100/1169 | Loss: 0.0210
2026-02-06 07:41:16 | INFO | Epoch 9 | Train Loss: 0.0201 | Val Loss: 0.0223
2026-02-06 07:41:16 | INFO | Val F1: 0.2906 | Prec: 0.1760 | Rec: 0.8319 | AUC: 0.9228
2026-02-06 07:41:16 | INFO | Epoch 10 | Batch 0/1169 | Loss: 0.0199
2026-02-06 07:41:22 | INFO | Epoch 10 | Batch 100/1169 | Loss: 0.0186
2026-02-06 07:41:27 | INFO | Epoch 10 | Batch 200/1169 | Loss: 0.0218
2026-02-06 07:41:32 | INFO | Epoch 10 | Batch 300/1169 | Loss: 0.0247
2026-02-06 07:41:38 | INFO | Epoch 10 | Batch 400/1169 | Loss: 0.0218
2026-02-06 07:41:43 | INFO | Epoch 10 | Batch 500/1169 | Loss: 0.0248
2026-02-06 07:41:49 | INFO | Epoch 10 | Batch 600/1169 | Loss: 0.0217
2026-02-06 07:41:56 | INFO | Epoch 10 | Batch 700/1169 | Loss: 0.0170
2026-02-06 07:42:03 | INFO | Epoch 10 | Batch 800/1169 | Loss: 0.0179
2026-02-06 07:42:08 | INFO | Epoch 10 | Batch 900/1169 | Loss: 0.0155
2026-02-06 07:42:14 | INFO | Epoch 10 | Batch 1000/1169 | Loss: 0.0164
2026-02-06 07:42:20 | INFO | Epoch 10 | Batch 1100/1169 | Loss: 0.0227
2026-02-06 07:42:27 | INFO | Epoch 10 | Train Loss: 0.0195 | Val Loss: 0.0287
2026-02-06 07:42:27 | INFO | Val F1: 0.2399 | Prec: 0.1396 | Rec: 0.8529 | AUC: 0.9171
2026-02-06 07:42:27 | INFO | Epoch 11 | Batch 0/1169 | Loss: 0.0173
2026-02-06 07:42:32 | INFO | Epoch 11 | Batch 100/1169 | Loss: 0.0190
2026-02-06 07:42:36 | INFO | Epoch 11 | Batch 200/1169 | Loss: 0.0135
2026-02-06 07:42:41 | INFO | Epoch 11 | Batch 300/1169 | Loss: 0.0204
2026-02-06 07:42:45 | INFO | Epoch 11 | Batch 400/1169 | Loss: 0.0174
2026-02-06 07:42:50 | INFO | Epoch 11 | Batch 500/1169 | Loss: 0.0133
2026-02-06 07:42:55 | INFO | Epoch 11 | Batch 600/1169 | Loss: 0.0173
2026-02-06 07:42:59 | INFO | Epoch 11 | Batch 700/1169 | Loss: 0.0223
2026-02-06 07:43:04 | INFO | Epoch 11 | Batch 800/1169 | Loss: 0.0182
2026-02-06 07:43:09 | INFO | Epoch 11 | Batch 900/1169 | Loss: 0.0178
2026-02-06 07:43:14 | INFO | Epoch 11 | Batch 1000/1169 | Loss: 0.0236
2026-02-06 07:43:18 | INFO | Epoch 11 | Batch 1100/1169 | Loss: 0.0144
2026-02-06 07:43:26 | INFO | Epoch 11 | Train Loss: 0.0188 | Val Loss: 0.0205
2026-02-06 07:43:26 | INFO | Val F1: 0.3252 | Prec: 0.2034 | Rec: 0.8103 | AUC: 0.9252
2026-02-06 07:43:26 | INFO | Epoch 12 | Batch 0/1169 | Loss: 0.0195
2026-02-06 07:43:30 | INFO | Epoch 12 | Batch 100/1169 | Loss: 0.0182
2026-02-06 07:43:35 | INFO | Epoch 12 | Batch 200/1169 | Loss: 0.0177
2026-02-06 07:43:40 | INFO | Epoch 12 | Batch 300/1169 | Loss: 0.0179
2026-02-06 07:43:45 | INFO | Epoch 12 | Batch 400/1169 | Loss: 0.0186
2026-02-06 07:43:50 | INFO | Epoch 12 | Batch 500/1169 | Loss: 0.0160
2026-02-06 07:43:54 | INFO | Epoch 12 | Batch 600/1169 | Loss: 0.0196
2026-02-06 07:43:59 | INFO | Epoch 12 | Batch 700/1169 | Loss: 0.0188
2026-02-06 07:44:03 | INFO | Epoch 12 | Batch 800/1169 | Loss: 0.0141
2026-02-06 07:44:08 | INFO | Epoch 12 | Batch 900/1169 | Loss: 0.0120
2026-02-06 07:44:13 | INFO | Epoch 12 | Batch 1000/1169 | Loss: 0.0155
2026-02-06 07:44:18 | INFO | Epoch 12 | Batch 1100/1169 | Loss: 0.0164
2026-02-06 07:44:25 | INFO | Epoch 12 | Train Loss: 0.0185 | Val Loss: 0.0167
2026-02-06 07:44:25 | INFO | Val F1: 0.4082 | Prec: 0.2779 | Rec: 0.7684 | AUC: 0.9229
2026-02-06 07:44:25 | INFO | New best model saved (F1: 0.4082)
2026-02-06 07:44:25 | INFO | Epoch 13 | Batch 0/1169 | Loss: 0.0202
2026-02-06 07:44:30 | INFO | Epoch 13 | Batch 100/1169 | Loss: 0.0203
2026-02-06 07:44:34 | INFO | Epoch 13 | Batch 200/1169 | Loss: 0.0203
2026-02-06 07:44:39 | INFO | Epoch 13 | Batch 300/1169 | Loss: 0.0156
2026-02-06 07:44:43 | INFO | Epoch 13 | Batch 400/1169 | Loss: 0.0152
2026-02-06 07:44:48 | INFO | Epoch 13 | Batch 500/1169 | Loss: 0.0182
2026-02-06 07:44:52 | INFO | Epoch 13 | Batch 600/1169 | Loss: 0.0209
2026-02-06 07:44:57 | INFO | Epoch 13 | Batch 700/1169 | Loss: 0.0201
2026-02-06 07:45:01 | INFO | Epoch 13 | Batch 800/1169 | Loss: 0.0158
2026-02-06 07:45:06 | INFO | Epoch 13 | Batch 900/1169 | Loss: 0.0167
2026-02-06 07:45:11 | INFO | Epoch 13 | Batch 1000/1169 | Loss: 0.0117
2026-02-06 07:45:15 | INFO | Epoch 13 | Batch 1100/1169 | Loss: 0.0219
2026-02-06 07:45:22 | INFO | Epoch 13 | Train Loss: 0.0180 | Val Loss: 0.0180
2026-02-06 07:45:22 | INFO | Val F1: 0.3652 | Prec: 0.2368 | Rec: 0.7977 | AUC: 0.9268
2026-02-06 07:45:22 | INFO | Epoch 14 | Batch 0/1169 | Loss: 0.0197
2026-02-06 07:45:27 | INFO | Epoch 14 | Batch 100/1169 | Loss: 0.0179
2026-02-06 07:45:31 | INFO | Epoch 14 | Batch 200/1169 | Loss: 0.0213
2026-02-06 07:45:36 | INFO | Epoch 14 | Batch 300/1169 | Loss: 0.0175
2026-02-06 07:45:41 | INFO | Epoch 14 | Batch 400/1169 | Loss: 0.0164
2026-02-06 07:45:46 | INFO | Epoch 14 | Batch 500/1169 | Loss: 0.0166
2026-02-06 07:45:50 | INFO | Epoch 14 | Batch 600/1169 | Loss: 0.0192
2026-02-06 07:45:55 | INFO | Epoch 14 | Batch 700/1169 | Loss: 0.0150
2026-02-06 07:45:59 | INFO | Epoch 14 | Batch 800/1169 | Loss: 0.0174
2026-02-06 07:46:04 | INFO | Epoch 14 | Batch 900/1169 | Loss: 0.0166
2026-02-06 07:46:08 | INFO | Epoch 14 | Batch 1000/1169 | Loss: 0.0174
2026-02-06 07:46:12 | INFO | Epoch 14 | Batch 1100/1169 | Loss: 0.0171
2026-02-06 07:46:19 | INFO | Epoch 14 | Train Loss: 0.0175 | Val Loss: 0.0205
2026-02-06 07:46:19 | INFO | Val F1: 0.3248 | Prec: 0.2029 | Rec: 0.8145 | AUC: 0.9231
2026-02-06 07:46:19 | INFO | Epoch 15 | Batch 0/1169 | Loss: 0.0161
2026-02-06 07:46:24 | INFO | Epoch 15 | Batch 100/1169 | Loss: 0.0158
2026-02-06 07:46:29 | INFO | Epoch 15 | Batch 200/1169 | Loss: 0.0177
2026-02-06 07:46:34 | INFO | Epoch 15 | Batch 300/1169 | Loss: 0.0253
2026-02-06 07:46:38 | INFO | Epoch 15 | Batch 400/1169 | Loss: 0.0180
2026-02-06 07:46:43 | INFO | Epoch 15 | Batch 500/1169 | Loss: 0.0176
2026-02-06 07:46:48 | INFO | Epoch 15 | Batch 600/1169 | Loss: 0.0198
2026-02-06 07:46:53 | INFO | Epoch 15 | Batch 700/1169 | Loss: 0.0183
2026-02-06 07:46:57 | INFO | Epoch 15 | Batch 800/1169 | Loss: 0.0154
2026-02-06 07:47:02 | INFO | Epoch 15 | Batch 900/1169 | Loss: 0.0188
2026-02-06 07:47:06 | INFO | Epoch 15 | Batch 1000/1169 | Loss: 0.0196
2026-02-06 07:47:11 | INFO | Epoch 15 | Batch 1100/1169 | Loss: 0.0163
2026-02-06 07:47:18 | INFO | Epoch 15 | Train Loss: 0.0171 | Val Loss: 0.0155
2026-02-06 07:47:18 | INFO | Val F1: 0.4270 | Prec: 0.2952 | Rec: 0.7710 | AUC: 0.9285
2026-02-06 07:47:18 | INFO | New best model saved (F1: 0.4270)
2026-02-06 07:47:18 | INFO | Epoch 16 | Batch 0/1169 | Loss: 0.0177
2026-02-06 07:47:22 | INFO | Epoch 16 | Batch 100/1169 | Loss: 0.0147
2026-02-06 07:47:27 | INFO | Epoch 16 | Batch 200/1169 | Loss: 0.0185
2026-02-06 07:47:31 | INFO | Epoch 16 | Batch 300/1169 | Loss: 0.0190
2026-02-06 07:47:36 | INFO | Epoch 16 | Batch 400/1169 | Loss: 0.0162
2026-02-06 07:47:40 | INFO | Epoch 16 | Batch 500/1169 | Loss: 0.0153
2026-02-06 07:47:45 | INFO | Epoch 16 | Batch 600/1169 | Loss: 0.0153
2026-02-06 07:47:50 | INFO | Epoch 16 | Batch 700/1169 | Loss: 0.0119
2026-02-06 07:47:54 | INFO | Epoch 16 | Batch 800/1169 | Loss: 0.0145
2026-02-06 07:47:59 | INFO | Epoch 16 | Batch 900/1169 | Loss: 0.0143
2026-02-06 07:48:04 | INFO | Epoch 16 | Batch 1000/1169 | Loss: 0.0158
2026-02-06 07:48:08 | INFO | Epoch 16 | Batch 1100/1169 | Loss: 0.0152
2026-02-06 07:48:15 | INFO | Epoch 16 | Train Loss: 0.0168 | Val Loss: 0.0199
2026-02-06 07:48:15 | INFO | Val F1: 0.3358 | Prec: 0.2119 | Rec: 0.8084 | AUC: 0.9242
2026-02-06 07:48:15 | INFO | Epoch 17 | Batch 0/1169 | Loss: 0.0198
2026-02-06 07:48:20 | INFO | Epoch 17 | Batch 100/1169 | Loss: 0.0146
2026-02-06 07:48:24 | INFO | Epoch 17 | Batch 200/1169 | Loss: 0.0145
2026-02-06 07:48:29 | INFO | Epoch 17 | Batch 300/1169 | Loss: 0.0205
2026-02-06 07:48:34 | INFO | Epoch 17 | Batch 400/1169 | Loss: 0.0167
2026-02-06 07:48:39 | INFO | Epoch 17 | Batch 500/1169 | Loss: 0.0180
2026-02-06 07:48:43 | INFO | Epoch 17 | Batch 600/1169 | Loss: 0.0157
2026-02-06 07:48:48 | INFO | Epoch 17 | Batch 700/1169 | Loss: 0.0164
2026-02-06 07:48:53 | INFO | Epoch 17 | Batch 800/1169 | Loss: 0.0156
2026-02-06 07:48:58 | INFO | Epoch 17 | Batch 900/1169 | Loss: 0.0168
2026-02-06 07:49:02 | INFO | Epoch 17 | Batch 1000/1169 | Loss: 0.0125
2026-02-06 07:49:06 | INFO | Epoch 17 | Batch 1100/1169 | Loss: 0.0170
2026-02-06 07:49:13 | INFO | Epoch 17 | Train Loss: 0.0165 | Val Loss: 0.0163
2026-02-06 07:49:13 | INFO | Val F1: 0.4131 | Prec: 0.2813 | Rec: 0.7768 | AUC: 0.9276
2026-02-06 07:49:13 | INFO | Epoch 18 | Batch 0/1169 | Loss: 0.0142
2026-02-06 07:49:18 | INFO | Epoch 18 | Batch 100/1169 | Loss: 0.0143
2026-02-06 07:49:22 | INFO | Epoch 18 | Batch 200/1169 | Loss: 0.0116
2026-02-06 07:49:28 | INFO | Epoch 18 | Batch 300/1169 | Loss: 0.0114
2026-02-06 07:49:32 | INFO | Epoch 18 | Batch 400/1169 | Loss: 0.0138
2026-02-06 07:49:40 | INFO | Epoch 18 | Batch 500/1169 | Loss: 0.0120
2026-02-06 07:49:46 | INFO | Epoch 18 | Batch 600/1169 | Loss: 0.0163
2026-02-06 07:49:52 | INFO | Epoch 18 | Batch 700/1169 | Loss: 0.0161
2026-02-06 07:49:58 | INFO | Epoch 18 | Batch 800/1169 | Loss: 0.0214
2026-02-06 07:50:03 | INFO | Epoch 18 | Batch 900/1169 | Loss: 0.0141
2026-02-06 07:50:09 | INFO | Epoch 18 | Batch 1000/1169 | Loss: 0.0176
2026-02-06 07:50:15 | INFO | Epoch 18 | Batch 1100/1169 | Loss: 0.0208
2026-02-06 07:50:23 | INFO | Epoch 18 | Train Loss: 0.0161 | Val Loss: 0.0173
2026-02-06 07:50:23 | INFO | Val F1: 0.3930 | Prec: 0.2622 | Rec: 0.7842 | AUC: 0.9259
2026-02-06 07:50:23 | INFO | Epoch 19 | Batch 0/1169 | Loss: 0.0157
2026-02-06 07:50:29 | INFO | Epoch 19 | Batch 100/1169 | Loss: 0.0176
2026-02-06 07:50:35 | INFO | Epoch 19 | Batch 200/1169 | Loss: 0.0151
2026-02-06 07:50:40 | INFO | Epoch 19 | Batch 300/1169 | Loss: 0.0165
2026-02-06 07:50:46 | INFO | Epoch 19 | Batch 400/1169 | Loss: 0.0165
2026-02-06 07:50:51 | INFO | Epoch 19 | Batch 500/1169 | Loss: 0.0138
2026-02-06 07:50:57 | INFO | Epoch 19 | Batch 600/1169 | Loss: 0.0142
2026-02-06 07:51:03 | INFO | Epoch 19 | Batch 700/1169 | Loss: 0.0124
2026-02-06 07:51:09 | INFO | Epoch 19 | Batch 800/1169 | Loss: 0.0173
2026-02-06 07:51:15 | INFO | Epoch 19 | Batch 900/1169 | Loss: 0.0155
2026-02-06 07:51:21 | INFO | Epoch 19 | Batch 1000/1169 | Loss: 0.0143
2026-02-06 07:51:26 | INFO | Epoch 19 | Batch 1100/1169 | Loss: 0.0150
2026-02-06 07:51:39 | INFO | Epoch 19 | Train Loss: 0.0159 | Val Loss: 0.0168
2026-02-06 07:51:39 | INFO | Val F1: 0.4059 | Prec: 0.2735 | Rec: 0.7861 | AUC: 0.9302
2026-02-06 07:51:39 | INFO | Epoch 20 | Batch 0/1169 | Loss: 0.0129
2026-02-06 07:51:44 | INFO | Epoch 20 | Batch 100/1169 | Loss: 0.0170
2026-02-06 07:51:48 | INFO | Epoch 20 | Batch 200/1169 | Loss: 0.0177
2026-02-06 07:51:51 | INFO | Epoch 20 | Batch 300/1169 | Loss: 0.0129
2026-02-06 07:51:55 | INFO | Epoch 20 | Batch 400/1169 | Loss: 0.0157
2026-02-06 07:51:59 | INFO | Epoch 20 | Batch 500/1169 | Loss: 0.0125
2026-02-06 07:52:03 | INFO | Epoch 20 | Batch 600/1169 | Loss: 0.0142
2026-02-06 07:52:07 | INFO | Epoch 20 | Batch 700/1169 | Loss: 0.0182
2026-02-06 07:52:10 | INFO | Epoch 20 | Batch 800/1169 | Loss: 0.0165
2026-02-06 07:52:14 | INFO | Epoch 20 | Batch 900/1169 | Loss: 0.0186
2026-02-06 07:52:18 | INFO | Epoch 20 | Batch 1000/1169 | Loss: 0.0128
2026-02-06 07:52:21 | INFO | Epoch 20 | Batch 1100/1169 | Loss: 0.0160
2026-02-06 07:52:27 | INFO | Epoch 20 | Train Loss: 0.0155 | Val Loss: 0.0163
2026-02-06 07:52:27 | INFO | Val F1: 0.4203 | Prec: 0.2875 | Rec: 0.7810 | AUC: 0.9274
2026-02-06 07:52:27 | INFO | Epoch 21 | Batch 0/1169 | Loss: 0.0164
2026-02-06 07:52:30 | INFO | Epoch 21 | Batch 100/1169 | Loss: 0.0167
2026-02-06 07:52:34 | INFO | Epoch 21 | Batch 200/1169 | Loss: 0.0118
2026-02-06 07:52:38 | INFO | Epoch 21 | Batch 300/1169 | Loss: 0.0126
2026-02-06 07:52:42 | INFO | Epoch 21 | Batch 400/1169 | Loss: 0.0219
2026-02-06 07:52:45 | INFO | Epoch 21 | Batch 500/1169 | Loss: 0.0162
2026-02-06 07:52:49 | INFO | Epoch 21 | Batch 600/1169 | Loss: 0.0138
2026-02-06 07:52:53 | INFO | Epoch 21 | Batch 700/1169 | Loss: 0.0139
2026-02-06 07:52:57 | INFO | Epoch 21 | Batch 800/1169 | Loss: 0.0164
2026-02-06 07:53:00 | INFO | Epoch 21 | Batch 900/1169 | Loss: 0.0134
2026-02-06 07:53:04 | INFO | Epoch 21 | Batch 1000/1169 | Loss: 0.0162
2026-02-06 07:53:08 | INFO | Epoch 21 | Batch 1100/1169 | Loss: 0.0213
2026-02-06 07:53:13 | INFO | Epoch 21 | Train Loss: 0.0154 | Val Loss: 0.0228
2026-02-06 07:53:13 | INFO | Val F1: 0.3111 | Prec: 0.1911 | Rec: 0.8368 | AUC: 0.9275
2026-02-06 07:53:13 | INFO | Epoch 22 | Batch 0/1169 | Loss: 0.0156
2026-02-06 07:53:17 | INFO | Epoch 22 | Batch 100/1169 | Loss: 0.0180
2026-02-06 07:53:21 | INFO | Epoch 22 | Batch 200/1169 | Loss: 0.0163
2026-02-06 07:53:24 | INFO | Epoch 22 | Batch 300/1169 | Loss: 0.0101
2026-02-06 07:53:28 | INFO | Epoch 22 | Batch 400/1169 | Loss: 0.0125
2026-02-06 07:53:31 | INFO | Epoch 22 | Batch 500/1169 | Loss: 0.0135
2026-02-06 07:53:35 | INFO | Epoch 22 | Batch 600/1169 | Loss: 0.0167
2026-02-06 07:53:39 | INFO | Epoch 22 | Batch 700/1169 | Loss: 0.0115
2026-02-06 07:53:42 | INFO | Epoch 22 | Batch 800/1169 | Loss: 0.0113
2026-02-06 07:53:46 | INFO | Epoch 22 | Batch 900/1169 | Loss: 0.0162
2026-02-06 07:53:50 | INFO | Epoch 22 | Batch 1000/1169 | Loss: 0.0155
2026-02-06 07:53:54 | INFO | Epoch 22 | Batch 1100/1169 | Loss: 0.0150
2026-02-06 07:53:59 | INFO | Epoch 22 | Train Loss: 0.0138 | Val Loss: 0.0164
2026-02-06 07:53:59 | INFO | Val F1: 0.4251 | Prec: 0.2925 | Rec: 0.7781 | AUC: 0.9301
2026-02-06 07:53:59 | INFO | Epoch 23 | Batch 0/1169 | Loss: 0.0117
2026-02-06 07:54:03 | INFO | Epoch 23 | Batch 100/1169 | Loss: 0.0145
2026-02-06 07:54:07 | INFO | Epoch 23 | Batch 200/1169 | Loss: 0.0141
2026-02-06 07:54:10 | INFO | Epoch 23 | Batch 300/1169 | Loss: 0.0155
2026-02-06 07:54:14 | INFO | Epoch 23 | Batch 400/1169 | Loss: 0.0122
2026-02-06 07:54:18 | INFO | Epoch 23 | Batch 500/1169 | Loss: 0.0135
2026-02-06 07:54:21 | INFO | Epoch 23 | Batch 600/1169 | Loss: 0.0114
2026-02-06 07:54:25 | INFO | Epoch 23 | Batch 700/1169 | Loss: 0.0172
2026-02-06 07:54:29 | INFO | Epoch 23 | Batch 800/1169 | Loss: 0.0146
2026-02-06 07:54:33 | INFO | Epoch 23 | Batch 900/1169 | Loss: 0.0139
2026-02-06 07:54:36 | INFO | Epoch 23 | Batch 1000/1169 | Loss: 0.0113
2026-02-06 07:54:40 | INFO | Epoch 23 | Batch 1100/1169 | Loss: 0.0158
2026-02-06 07:54:46 | INFO | Epoch 23 | Train Loss: 0.0132 | Val Loss: 0.0167
2026-02-06 07:54:46 | INFO | Val F1: 0.4154 | Prec: 0.2821 | Rec: 0.7874 | AUC: 0.9293
2026-02-06 07:54:46 | INFO | Epoch 24 | Batch 0/1169 | Loss: 0.0146
2026-02-06 07:54:50 | INFO | Epoch 24 | Batch 100/1169 | Loss: 0.0146
2026-02-06 07:54:54 | INFO | Epoch 24 | Batch 200/1169 | Loss: 0.0113
2026-02-06 07:54:57 | INFO | Epoch 24 | Batch 300/1169 | Loss: 0.0137
2026-02-06 07:55:01 | INFO | Epoch 24 | Batch 400/1169 | Loss: 0.0115
2026-02-06 07:55:05 | INFO | Epoch 24 | Batch 500/1169 | Loss: 0.0158
2026-02-06 07:55:08 | INFO | Epoch 24 | Batch 600/1169 | Loss: 0.0116
2026-02-06 07:55:12 | INFO | Epoch 24 | Batch 700/1169 | Loss: 0.0143
2026-02-06 07:55:16 | INFO | Epoch 24 | Batch 800/1169 | Loss: 0.0084
2026-02-06 07:55:20 | INFO | Epoch 24 | Batch 900/1169 | Loss: 0.0096
2026-02-06 07:55:23 | INFO | Epoch 24 | Batch 1000/1169 | Loss: 0.0129
2026-02-06 07:55:27 | INFO | Epoch 24 | Batch 1100/1169 | Loss: 0.0119
2026-02-06 07:55:33 | INFO | Epoch 24 | Train Loss: 0.0129 | Val Loss: 0.0162
2026-02-06 07:55:33 | INFO | Val F1: 0.4323 | Prec: 0.2991 | Rec: 0.7797 | AUC: 0.9300
2026-02-06 07:55:33 | INFO | New best model saved (F1: 0.4323)
2026-02-06 07:55:33 | INFO | Epoch 25 | Batch 0/1169 | Loss: 0.0128
2026-02-06 07:55:37 | INFO | Epoch 25 | Batch 100/1169 | Loss: 0.0120
2026-02-06 07:55:42 | INFO | Epoch 25 | Batch 200/1169 | Loss: 0.0110
2026-02-06 07:55:46 | INFO | Epoch 25 | Batch 300/1169 | Loss: 0.0140
2026-02-06 07:55:51 | INFO | Epoch 25 | Batch 400/1169 | Loss: 0.0109
2026-02-06 07:55:55 | INFO | Epoch 25 | Batch 500/1169 | Loss: 0.0126
2026-02-06 07:56:00 | INFO | Epoch 25 | Batch 600/1169 | Loss: 0.0108
2026-02-06 07:56:04 | INFO | Epoch 25 | Batch 700/1169 | Loss: 0.0122
2026-02-06 07:56:09 | INFO | Epoch 25 | Batch 800/1169 | Loss: 0.0113
2026-02-06 07:56:13 | INFO | Epoch 25 | Batch 900/1169 | Loss: 0.0096
2026-02-06 07:56:18 | INFO | Epoch 25 | Batch 1000/1169 | Loss: 0.0127
2026-02-06 07:56:23 | INFO | Epoch 25 | Batch 1100/1169 | Loss: 0.0133
2026-02-06 07:56:29 | INFO | Epoch 25 | Train Loss: 0.0128 | Val Loss: 0.0159
2026-02-06 07:56:29 | INFO | Val F1: 0.4411 | Prec: 0.3079 | Rec: 0.7774 | AUC: 0.9307
2026-02-06 07:56:29 | INFO | New best model saved (F1: 0.4411)
2026-02-06 07:56:29 | INFO | Epoch 26 | Batch 0/1169 | Loss: 0.0147
2026-02-06 07:56:35 | INFO | Epoch 26 | Batch 100/1169 | Loss: 0.0108
2026-02-06 07:56:41 | INFO | Epoch 26 | Batch 200/1169 | Loss: 0.0083
2026-02-06 07:56:48 | INFO | Epoch 26 | Batch 300/1169 | Loss: 0.0107
2026-02-06 07:56:56 | INFO | Epoch 26 | Batch 400/1169 | Loss: 0.0128
2026-02-06 07:57:05 | INFO | Epoch 26 | Batch 500/1169 | Loss: 0.0096
2026-02-06 07:57:10 | INFO | Epoch 26 | Batch 600/1169 | Loss: 0.0119
2026-02-06 07:57:16 | INFO | Epoch 26 | Batch 700/1169 | Loss: 0.0121
2026-02-06 07:57:23 | INFO | Epoch 26 | Batch 800/1169 | Loss: 0.0127
2026-02-06 07:57:32 | INFO | Epoch 26 | Batch 900/1169 | Loss: 0.0133
2026-02-06 07:57:39 | INFO | Epoch 26 | Batch 1000/1169 | Loss: 0.0106
2026-02-06 07:57:47 | INFO | Epoch 26 | Batch 1100/1169 | Loss: 0.0112
2026-02-06 07:58:00 | INFO | Epoch 26 | Train Loss: 0.0126 | Val Loss: 0.0164
2026-02-06 07:58:00 | INFO | Val F1: 0.4357 | Prec: 0.3017 | Rec: 0.7839 | AUC: 0.9328
2026-02-06 07:58:00 | INFO | Epoch 27 | Batch 0/1169 | Loss: 0.0131
2026-02-06 07:58:08 | INFO | Epoch 27 | Batch 100/1169 | Loss: 0.0125
2026-02-06 07:58:16 | INFO | Epoch 27 | Batch 200/1169 | Loss: 0.0156
2026-02-06 07:58:24 | INFO | Epoch 27 | Batch 300/1169 | Loss: 0.0177
2026-02-06 07:58:29 | INFO | Epoch 27 | Batch 400/1169 | Loss: 0.0151
2026-02-06 07:58:35 | INFO | Epoch 27 | Batch 500/1169 | Loss: 0.0144
2026-02-06 07:58:41 | INFO | Epoch 27 | Batch 600/1169 | Loss: 0.0133
2026-02-06 07:58:46 | INFO | Epoch 27 | Batch 700/1169 | Loss: 0.0130
2026-02-06 07:58:52 | INFO | Epoch 27 | Batch 800/1169 | Loss: 0.0132
2026-02-06 07:58:58 | INFO | Epoch 27 | Batch 900/1169 | Loss: 0.0148
2026-02-06 07:59:03 | INFO | Epoch 27 | Batch 1000/1169 | Loss: 0.0134
2026-02-06 07:59:09 | INFO | Epoch 27 | Batch 1100/1169 | Loss: 0.0151
2026-02-06 07:59:17 | INFO | Epoch 27 | Train Loss: 0.0125 | Val Loss: 0.0157
2026-02-06 07:59:17 | INFO | Val F1: 0.4565 | Prec: 0.3245 | Rec: 0.7697 | AUC: 0.9316
2026-02-06 07:59:17 | INFO | New best model saved (F1: 0.4565)
2026-02-06 07:59:17 | INFO | Epoch 28 | Batch 0/1169 | Loss: 0.0153
2026-02-06 07:59:22 | INFO | Epoch 28 | Batch 100/1169 | Loss: 0.0133
2026-02-06 07:59:28 | INFO | Epoch 28 | Batch 200/1169 | Loss: 0.0133
2026-02-06 07:59:33 | INFO | Epoch 28 | Batch 300/1169 | Loss: 0.0141
2026-02-06 07:59:37 | INFO | Epoch 28 | Batch 400/1169 | Loss: 0.0090
2026-02-06 07:59:43 | INFO | Epoch 28 | Batch 500/1169 | Loss: 0.0092
2026-02-06 07:59:48 | INFO | Epoch 28 | Batch 600/1169 | Loss: 0.0115
2026-02-06 07:59:54 | INFO | Epoch 28 | Batch 700/1169 | Loss: 0.0134
2026-02-06 08:00:00 | INFO | Epoch 28 | Batch 800/1169 | Loss: 0.0104
2026-02-06 08:00:06 | INFO | Epoch 28 | Batch 900/1169 | Loss: 0.0138
2026-02-06 08:00:12 | INFO | Epoch 28 | Batch 1000/1169 | Loss: 0.0124
2026-02-06 08:00:18 | INFO | Epoch 28 | Batch 1100/1169 | Loss: 0.0127
2026-02-06 08:00:25 | INFO | Epoch 28 | Train Loss: 0.0118 | Val Loss: 0.0165
2026-02-06 08:00:25 | INFO | Val F1: 0.4358 | Prec: 0.3028 | Rec: 0.7774 | AUC: 0.9317
2026-02-06 08:00:26 | INFO | Epoch 29 | Batch 0/1169 | Loss: 0.0109
2026-02-06 08:00:30 | INFO | Epoch 29 | Batch 100/1169 | Loss: 0.0141
2026-02-06 08:00:35 | INFO | Epoch 29 | Batch 200/1169 | Loss: 0.0079
2026-02-06 08:00:41 | INFO | Epoch 29 | Batch 300/1169 | Loss: 0.0111
2026-02-06 08:00:46 | INFO | Epoch 29 | Batch 400/1169 | Loss: 0.0186
2026-02-06 08:00:52 | INFO | Epoch 29 | Batch 500/1169 | Loss: 0.0119
2026-02-06 08:00:58 | INFO | Epoch 29 | Batch 600/1169 | Loss: 0.0092
2026-02-06 08:01:04 | INFO | Epoch 29 | Batch 700/1169 | Loss: 0.0119
2026-02-06 08:01:09 | INFO | Epoch 29 | Batch 800/1169 | Loss: 0.0127
2026-02-06 08:01:15 | INFO | Epoch 29 | Batch 900/1169 | Loss: 0.0107
2026-02-06 08:01:21 | INFO | Epoch 29 | Batch 1000/1169 | Loss: 0.0107
2026-02-06 08:01:27 | INFO | Epoch 29 | Batch 1100/1169 | Loss: 0.0116
2026-02-06 08:01:35 | INFO | Epoch 29 | Train Loss: 0.0114 | Val Loss: 0.0160
2026-02-06 08:01:35 | INFO | Val F1: 0.4558 | Prec: 0.3229 | Rec: 0.7742 | AUC: 0.9322
2026-02-06 08:01:35 | INFO | Epoch 30 | Batch 0/1169 | Loss: 0.0117
2026-02-06 08:01:41 | INFO | Epoch 30 | Batch 100/1169 | Loss: 0.0111
2026-02-06 08:01:47 | INFO | Epoch 30 | Batch 200/1169 | Loss: 0.0097
2026-02-06 08:01:53 | INFO | Epoch 30 | Batch 300/1169 | Loss: 0.0094
2026-02-06 08:01:59 | INFO | Epoch 30 | Batch 400/1169 | Loss: 0.0123
2026-02-06 08:02:04 | INFO | Epoch 30 | Batch 500/1169 | Loss: 0.0108
2026-02-06 08:02:10 | INFO | Epoch 30 | Batch 600/1169 | Loss: 0.0101
2026-02-06 08:02:17 | INFO | Epoch 30 | Batch 700/1169 | Loss: 0.0105
2026-02-06 08:02:24 | INFO | Epoch 30 | Batch 800/1169 | Loss: 0.0126
2026-02-06 08:02:30 | INFO | Epoch 30 | Batch 900/1169 | Loss: 0.0090
2026-02-06 08:02:36 | INFO | Epoch 30 | Batch 1000/1169 | Loss: 0.0140
2026-02-06 08:02:41 | INFO | Epoch 30 | Batch 1100/1169 | Loss: 0.0106
2026-02-06 08:02:51 | INFO | Epoch 30 | Train Loss: 0.0113 | Val Loss: 0.0155
2026-02-06 08:02:51 | INFO | Val F1: 0.4925 | Prec: 0.3634 | Rec: 0.7635 | AUC: 0.9330
2026-02-06 08:02:51 | INFO | New best model saved (F1: 0.4925)
2026-02-06 08:02:51 | INFO | Epoch 31 | Batch 0/1169 | Loss: 0.0076
2026-02-06 08:02:56 | INFO | Epoch 31 | Batch 100/1169 | Loss: 0.0088
2026-02-06 08:03:02 | INFO | Epoch 31 | Batch 200/1169 | Loss: 0.0090
2026-02-06 08:03:08 | INFO | Epoch 31 | Batch 300/1169 | Loss: 0.0131
2026-02-06 08:03:14 | INFO | Epoch 31 | Batch 400/1169 | Loss: 0.0116
2026-02-06 08:03:20 | INFO | Epoch 31 | Batch 500/1169 | Loss: 0.0101
2026-02-06 08:03:25 | INFO | Epoch 31 | Batch 600/1169 | Loss: 0.0094
2026-02-06 08:03:29 | INFO | Epoch 31 | Batch 700/1169 | Loss: 0.0139
2026-02-06 08:03:34 | INFO | Epoch 31 | Batch 800/1169 | Loss: 0.0134
2026-02-06 08:03:38 | INFO | Epoch 31 | Batch 900/1169 | Loss: 0.0092
2026-02-06 08:03:44 | INFO | Epoch 31 | Batch 1000/1169 | Loss: 0.0120
2026-02-06 08:03:49 | INFO | Epoch 31 | Batch 1100/1169 | Loss: 0.0136
2026-02-06 08:03:57 | INFO | Epoch 31 | Train Loss: 0.0112 | Val Loss: 0.0164
2026-02-06 08:03:57 | INFO | Val F1: 0.4471 | Prec: 0.3143 | Rec: 0.7742 | AUC: 0.9321
2026-02-06 08:03:58 | INFO | Epoch 32 | Batch 0/1169 | Loss: 0.0089
2026-02-06 08:04:03 | INFO | Epoch 32 | Batch 100/1169 | Loss: 0.0121
2026-02-06 08:04:09 | INFO | Epoch 32 | Batch 200/1169 | Loss: 0.0128
2026-02-06 08:04:14 | INFO | Epoch 32 | Batch 300/1169 | Loss: 0.0132
2026-02-06 08:04:19 | INFO | Epoch 32 | Batch 400/1169 | Loss: 0.0095
2026-02-06 08:04:24 | INFO | Epoch 32 | Batch 500/1169 | Loss: 0.0097
2026-02-06 08:04:30 | INFO | Epoch 32 | Batch 600/1169 | Loss: 0.0079
2026-02-06 08:04:36 | INFO | Epoch 32 | Batch 700/1169 | Loss: 0.0120
2026-02-06 08:04:42 | INFO | Epoch 32 | Batch 800/1169 | Loss: 0.0075
2026-02-06 08:04:48 | INFO | Epoch 32 | Batch 900/1169 | Loss: 0.0116
2026-02-06 08:04:54 | INFO | Epoch 32 | Batch 1000/1169 | Loss: 0.0114
2026-02-06 08:05:00 | INFO | Epoch 32 | Batch 1100/1169 | Loss: 0.0135
2026-02-06 08:05:09 | INFO | Epoch 32 | Train Loss: 0.0111 | Val Loss: 0.0166
2026-02-06 08:05:09 | INFO | Val F1: 0.4546 | Prec: 0.3214 | Rec: 0.7761 | AUC: 0.9330
2026-02-06 08:05:09 | INFO | Epoch 33 | Batch 0/1169 | Loss: 0.0109
2026-02-06 08:05:15 | INFO | Epoch 33 | Batch 100/1169 | Loss: 0.0128
2026-02-06 08:05:21 | INFO | Epoch 33 | Batch 200/1169 | Loss: 0.0152
2026-02-06 08:05:26 | INFO | Epoch 33 | Batch 300/1169 | Loss: 0.0124
2026-02-06 08:05:32 | INFO | Epoch 33 | Batch 400/1169 | Loss: 0.0104
2026-02-06 08:05:37 | INFO | Epoch 33 | Batch 500/1169 | Loss: 0.0152
2026-02-06 08:05:42 | INFO | Epoch 33 | Batch 600/1169 | Loss: 0.0141
2026-02-06 08:05:48 | INFO | Epoch 33 | Batch 700/1169 | Loss: 0.0118
2026-02-06 08:05:54 | INFO | Epoch 33 | Batch 800/1169 | Loss: 0.0122
2026-02-06 08:05:59 | INFO | Epoch 33 | Batch 900/1169 | Loss: 0.0114
2026-02-06 08:06:05 | INFO | Epoch 33 | Batch 1000/1169 | Loss: 0.0146
2026-02-06 08:06:11 | INFO | Epoch 33 | Batch 1100/1169 | Loss: 0.0087
2026-02-06 08:06:21 | INFO | Epoch 33 | Train Loss: 0.0110 | Val Loss: 0.0163
2026-02-06 08:06:21 | INFO | Val F1: 0.4603 | Prec: 0.3277 | Rec: 0.7732 | AUC: 0.9320
2026-02-06 08:06:21 | INFO | Epoch 34 | Batch 0/1169 | Loss: 0.0118
2026-02-06 08:06:26 | INFO | Epoch 34 | Batch 100/1169 | Loss: 0.0112
2026-02-06 08:06:30 | INFO | Epoch 34 | Batch 200/1169 | Loss: 0.0133
2026-02-06 08:06:35 | INFO | Epoch 34 | Batch 300/1169 | Loss: 0.0139
2026-02-06 08:06:42 | INFO | Epoch 34 | Batch 400/1169 | Loss: 0.0139
2026-02-06 08:06:48 | INFO | Epoch 34 | Batch 500/1169 | Loss: 0.0138
2026-02-06 08:06:53 | INFO | Epoch 34 | Batch 600/1169 | Loss: 0.0106
2026-02-06 08:06:59 | INFO | Epoch 34 | Batch 700/1169 | Loss: 0.0083
2026-02-06 08:07:04 | INFO | Epoch 34 | Batch 800/1169 | Loss: 0.0131
2026-02-06 08:07:10 | INFO | Epoch 34 | Batch 900/1169 | Loss: 0.0117
2026-02-06 08:07:16 | INFO | Epoch 34 | Batch 1000/1169 | Loss: 0.0110
2026-02-06 08:07:21 | INFO | Epoch 34 | Batch 1100/1169 | Loss: 0.0114
2026-02-06 08:07:29 | INFO | Epoch 34 | Train Loss: 0.0109 | Val Loss: 0.0165
2026-02-06 08:07:29 | INFO | Val F1: 0.4690 | Prec: 0.3364 | Rec: 0.7742 | AUC: 0.9320
2026-02-06 08:07:29 | INFO | Epoch 35 | Batch 0/1169 | Loss: 0.0107
2026-02-06 08:07:35 | INFO | Epoch 35 | Batch 100/1169 | Loss: 0.0119
2026-02-06 08:07:41 | INFO | Epoch 35 | Batch 200/1169 | Loss: 0.0094
2026-02-06 08:07:46 | INFO | Epoch 35 | Batch 300/1169 | Loss: 0.0105
2026-02-06 08:07:52 | INFO | Epoch 35 | Batch 400/1169 | Loss: 0.0092
2026-02-06 08:07:58 | INFO | Epoch 35 | Batch 500/1169 | Loss: 0.0107
2026-02-06 08:08:03 | INFO | Epoch 35 | Batch 600/1169 | Loss: 0.0107
2026-02-06 08:08:07 | INFO | Epoch 35 | Batch 700/1169 | Loss: 0.0139
2026-02-06 08:08:13 | INFO | Epoch 35 | Batch 800/1169 | Loss: 0.0095
2026-02-06 08:08:18 | INFO | Epoch 35 | Batch 900/1169 | Loss: 0.0115
2026-02-06 08:08:24 | INFO | Epoch 35 | Batch 1000/1169 | Loss: 0.0094
2026-02-06 08:08:29 | INFO | Epoch 35 | Batch 1100/1169 | Loss: 0.0098
2026-02-06 08:08:38 | INFO | Epoch 35 | Train Loss: 0.0108 | Val Loss: 0.0160
2026-02-06 08:08:38 | INFO | Val F1: 0.4815 | Prec: 0.3497 | Rec: 0.7729 | AUC: 0.9327
2026-02-06 08:08:38 | INFO | Epoch 36 | Batch 0/1169 | Loss: 0.0099
2026-02-06 08:08:43 | INFO | Epoch 36 | Batch 100/1169 | Loss: 0.0072
2026-02-06 08:08:48 | INFO | Epoch 36 | Batch 200/1169 | Loss: 0.0114
2026-02-06 08:08:52 | INFO | Epoch 36 | Batch 300/1169 | Loss: 0.0092
2026-02-06 08:08:57 | INFO | Epoch 36 | Batch 400/1169 | Loss: 0.0084
2026-02-06 08:09:01 | INFO | Epoch 36 | Batch 500/1169 | Loss: 0.0127
2026-02-06 08:09:07 | INFO | Epoch 36 | Batch 600/1169 | Loss: 0.0083
2026-02-06 08:09:12 | INFO | Epoch 36 | Batch 700/1169 | Loss: 0.0092
2026-02-06 08:09:18 | INFO | Epoch 36 | Batch 800/1169 | Loss: 0.0109
2026-02-06 08:09:24 | INFO | Epoch 36 | Batch 900/1169 | Loss: 0.0110
2026-02-06 08:09:29 | INFO | Epoch 36 | Batch 1000/1169 | Loss: 0.0116
2026-02-06 08:09:34 | INFO | Epoch 36 | Batch 1100/1169 | Loss: 0.0148
2026-02-06 08:09:43 | INFO | Epoch 36 | Train Loss: 0.0107 | Val Loss: 0.0160
2026-02-06 08:09:43 | INFO | Val F1: 0.4796 | Prec: 0.3479 | Rec: 0.7716 | AUC: 0.9318
2026-02-06 08:09:43 | INFO | Epoch 37 | Batch 0/1169 | Loss: 0.0094
2026-02-06 08:09:49 | INFO | Epoch 37 | Batch 100/1169 | Loss: 0.0078
2026-02-06 08:09:55 | INFO | Epoch 37 | Batch 200/1169 | Loss: 0.0091
2026-02-06 08:10:00 | INFO | Epoch 37 | Batch 300/1169 | Loss: 0.0088
2026-02-06 08:10:06 | INFO | Epoch 37 | Batch 400/1169 | Loss: 0.0102
2026-02-06 08:10:12 | INFO | Epoch 37 | Batch 500/1169 | Loss: 0.0161
2026-02-06 08:10:18 | INFO | Epoch 37 | Batch 600/1169 | Loss: 0.0071
2026-02-06 08:10:23 | INFO | Epoch 37 | Batch 700/1169 | Loss: 0.0089
2026-02-06 08:10:29 | INFO | Epoch 37 | Batch 800/1169 | Loss: 0.0103
2026-02-06 08:10:35 | INFO | Epoch 37 | Batch 900/1169 | Loss: 0.0097
2026-02-06 08:10:41 | INFO | Epoch 37 | Batch 1000/1169 | Loss: 0.0126
2026-02-06 08:10:47 | INFO | Epoch 37 | Batch 1100/1169 | Loss: 0.0095
2026-02-06 08:10:55 | INFO | Epoch 37 | Train Loss: 0.0104 | Val Loss: 0.0165
2026-02-06 08:10:55 | INFO | Val F1: 0.4641 | Prec: 0.3312 | Rec: 0.7752 | AUC: 0.9323
2026-02-06 08:10:55 | INFO | Epoch 38 | Batch 0/1169 | Loss: 0.0096
2026-02-06 08:11:01 | INFO | Epoch 38 | Batch 100/1169 | Loss: 0.0094
2026-02-06 08:11:07 | INFO | Epoch 38 | Batch 200/1169 | Loss: 0.0072
2026-02-06 08:11:12 | INFO | Epoch 38 | Batch 300/1169 | Loss: 0.0065
2026-02-06 08:11:18 | INFO | Epoch 38 | Batch 400/1169 | Loss: 0.0118
2026-02-06 08:11:22 | INFO | Epoch 38 | Batch 500/1169 | Loss: 0.0090
2026-02-06 08:11:28 | INFO | Epoch 38 | Batch 600/1169 | Loss: 0.0097
2026-02-06 08:11:33 | INFO | Epoch 38 | Batch 700/1169 | Loss: 0.0109
2026-02-06 08:11:38 | INFO | Epoch 38 | Batch 800/1169 | Loss: 0.0072
2026-02-06 08:11:44 | INFO | Epoch 38 | Batch 900/1169 | Loss: 0.0087
2026-02-06 08:11:50 | INFO | Epoch 38 | Batch 1000/1169 | Loss: 0.0074
2026-02-06 08:11:56 | INFO | Epoch 38 | Batch 1100/1169 | Loss: 0.0090
2026-02-06 08:12:05 | INFO | Epoch 38 | Train Loss: 0.0103 | Val Loss: 0.0166
2026-02-06 08:12:05 | INFO | Val F1: 0.4729 | Prec: 0.3412 | Rec: 0.7700 | AUC: 0.9320
2026-02-06 08:12:05 | INFO | Epoch 39 | Batch 0/1169 | Loss: 0.0106
2026-02-06 08:12:10 | INFO | Epoch 39 | Batch 100/1169 | Loss: 0.0078
2026-02-06 08:12:15 | INFO | Epoch 39 | Batch 200/1169 | Loss: 0.0100
2026-02-06 08:12:20 | INFO | Epoch 39 | Batch 300/1169 | Loss: 0.0076
2026-02-06 08:12:26 | INFO | Epoch 39 | Batch 400/1169 | Loss: 0.0099
2026-02-06 08:12:31 | INFO | Epoch 39 | Batch 500/1169 | Loss: 0.0119
2026-02-06 08:12:37 | INFO | Epoch 39 | Batch 600/1169 | Loss: 0.0094
2026-02-06 08:12:42 | INFO | Epoch 39 | Batch 700/1169 | Loss: 0.0101
2026-02-06 08:12:47 | INFO | Epoch 39 | Batch 800/1169 | Loss: 0.0085
2026-02-06 08:12:52 | INFO | Epoch 39 | Batch 900/1169 | Loss: 0.0115
2026-02-06 08:12:57 | INFO | Epoch 39 | Batch 1000/1169 | Loss: 0.0101
2026-02-06 08:13:02 | INFO | Epoch 39 | Batch 1100/1169 | Loss: 0.0120
2026-02-06 08:13:12 | INFO | Epoch 39 | Train Loss: 0.0102 | Val Loss: 0.0163
2026-02-06 08:13:12 | INFO | Val F1: 0.4841 | Prec: 0.3537 | Rec: 0.7671 | AUC: 0.9310
2026-02-06 08:13:12 | INFO | Epoch 40 | Batch 0/1169 | Loss: 0.0092
2026-02-06 08:13:17 | INFO | Epoch 40 | Batch 100/1169 | Loss: 0.0097
2026-02-06 08:13:22 | INFO | Epoch 40 | Batch 200/1169 | Loss: 0.0104
2026-02-06 08:13:26 | INFO | Epoch 40 | Batch 300/1169 | Loss: 0.0104
2026-02-06 08:13:31 | INFO | Epoch 40 | Batch 400/1169 | Loss: 0.0098
2026-02-06 08:13:37 | INFO | Epoch 40 | Batch 500/1169 | Loss: 0.0089
2026-02-06 08:13:42 | INFO | Epoch 40 | Batch 600/1169 | Loss: 0.0162
2026-02-06 08:13:48 | INFO | Epoch 40 | Batch 700/1169 | Loss: 0.0118
2026-02-06 08:13:54 | INFO | Epoch 40 | Batch 800/1169 | Loss: 0.0083
2026-02-06 08:13:59 | INFO | Epoch 40 | Batch 900/1169 | Loss: 0.0091
2026-02-06 08:14:05 | INFO | Epoch 40 | Batch 1000/1169 | Loss: 0.0079
2026-02-06 08:14:11 | INFO | Epoch 40 | Batch 1100/1169 | Loss: 0.0091
2026-02-06 08:14:19 | INFO | Epoch 40 | Train Loss: 0.0101 | Val Loss: 0.0164
2026-02-06 08:14:19 | INFO | Val F1: 0.4795 | Prec: 0.3473 | Rec: 0.7745 | AUC: 0.9327
2026-02-06 08:14:19 | INFO | Early stopping at epoch 40
2026-02-06 08:14:25 | INFO | ======================================================================
2026-02-06 08:14:25 | INFO | TEST RESULTS (FULL FEATURE Fusion: LSTM + GNN + Dense)
2026-02-06 08:14:25 | INFO | ======================================================================
2026-02-06 08:14:25 | INFO | F1: 0.5043
2026-02-06 08:14:25 | INFO | Precision: 0.3723
2026-02-06 08:14:25 | INFO | Recall: 0.7812
2026-02-06 08:14:25 | INFO | AUC: 0.9379
2026-02-06 08:14:25 | INFO | 
Threshold Analysis:
2026-02-06 08:14:25 | INFO | Threshold 0.3: F1=0.2775 | Prec=0.1649 | Rec=0.8738
2026-02-06 08:14:25 | INFO | Threshold 0.5: F1=0.5043 | Prec=0.3723 | Rec=0.7812
2026-02-06 08:14:25 | INFO | Threshold 0.7: F1=0.6860 | Prec=0.7512 | Rec=0.6312
2026-02-06 08:14:25 | INFO | Threshold 0.8: F1=0.6684 | Prec=0.9128 | Rec=0.5273
2026-02-06 08:14:25 | INFO | Threshold 0.9: F1=0.5386 | Prec=0.9771 | Rec=0.3717
