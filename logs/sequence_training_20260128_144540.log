2026-01-28 14:45:40 | INFO | Starting Sequence LSTM training
2026-01-28 14:45:40 | INFO | Device: cpu
2026-01-28 14:45:46 | INFO | Train batches: 764
2026-01-28 14:45:46 | INFO | Model parameters: 857,602
2026-01-28 14:46:04 | INFO | Epoch 1 | Batch 0/764 | Loss: 0.0462
2026-01-28 14:46:25 | INFO | Epoch 1 | Batch 100/764 | Loss: 0.0223
2026-01-28 14:46:39 | INFO | Epoch 1 | Batch 200/764 | Loss: 0.0198
2026-01-28 14:46:50 | INFO | Epoch 1 | Batch 300/764 | Loss: 0.0197
2026-01-28 14:47:03 | INFO | Epoch 1 | Batch 400/764 | Loss: 0.0220
2026-01-28 14:47:18 | INFO | Epoch 1 | Batch 500/764 | Loss: 0.0185
2026-01-28 14:47:31 | INFO | Epoch 1 | Batch 600/764 | Loss: 0.0230
2026-01-28 14:47:44 | INFO | Epoch 1 | Batch 700/764 | Loss: 0.0193
2026-01-28 14:48:03 | INFO | Epoch 1 | Train Loss: 0.0209 | Val Loss: 0.0195
2026-01-28 14:48:03 | INFO | Val F1: 0.2058 | Prec: 0.3783 | Rec: 0.1413 | AUC: 0.7791
2026-01-28 14:48:03 | INFO | New best model saved (F1: 0.2058)
2026-01-28 14:48:03 | INFO | Epoch 2 | Batch 0/764 | Loss: 0.0322
2026-01-28 14:48:16 | INFO | Epoch 2 | Batch 100/764 | Loss: 0.0203
2026-01-28 14:48:28 | INFO | Epoch 2 | Batch 200/764 | Loss: 0.0261
2026-01-28 14:48:40 | INFO | Epoch 2 | Batch 300/764 | Loss: 0.0249
2026-01-28 14:48:53 | INFO | Epoch 2 | Batch 400/764 | Loss: 0.0215
2026-01-28 14:49:05 | INFO | Epoch 2 | Batch 500/764 | Loss: 0.0172
2026-01-28 14:49:18 | INFO | Epoch 2 | Batch 600/764 | Loss: 0.0155
2026-01-28 14:49:30 | INFO | Epoch 2 | Batch 700/764 | Loss: 0.0196
2026-01-28 14:49:44 | INFO | Epoch 2 | Train Loss: 0.0197 | Val Loss: 0.0193
2026-01-28 14:49:44 | INFO | Val F1: 0.2411 | Prec: 0.3846 | Rec: 0.1756 | AUC: 0.7860
2026-01-28 14:49:44 | INFO | New best model saved (F1: 0.2411)
2026-01-28 14:49:45 | INFO | Epoch 3 | Batch 0/764 | Loss: 0.0183
2026-01-28 14:49:57 | INFO | Epoch 3 | Batch 100/764 | Loss: 0.0256
2026-01-28 14:50:10 | INFO | Epoch 3 | Batch 200/764 | Loss: 0.0180
2026-01-28 14:50:22 | INFO | Epoch 3 | Batch 300/764 | Loss: 0.0172
2026-01-28 14:50:35 | INFO | Epoch 3 | Batch 400/764 | Loss: 0.0198
2026-01-28 14:50:47 | INFO | Epoch 3 | Batch 500/764 | Loss: 0.0175
2026-01-28 14:51:00 | INFO | Epoch 3 | Batch 600/764 | Loss: 0.0148
2026-01-28 14:51:13 | INFO | Epoch 3 | Batch 700/764 | Loss: 0.0199
2026-01-28 14:51:28 | INFO | Epoch 3 | Train Loss: 0.0190 | Val Loss: 0.0190
2026-01-28 14:51:28 | INFO | Val F1: 0.2368 | Prec: 0.4465 | Rec: 0.1611 | AUC: 0.7896
2026-01-28 14:51:28 | INFO | Epoch 4 | Batch 0/764 | Loss: 0.0195
2026-01-28 14:51:41 | INFO | Epoch 4 | Batch 100/764 | Loss: 0.0133
2026-01-28 14:51:54 | INFO | Epoch 4 | Batch 200/764 | Loss: 0.0146
2026-01-28 14:52:07 | INFO | Epoch 4 | Batch 300/764 | Loss: 0.0220
2026-01-28 14:52:21 | INFO | Epoch 4 | Batch 400/764 | Loss: 0.0134
2026-01-28 14:52:34 | INFO | Epoch 4 | Batch 500/764 | Loss: 0.0171
2026-01-28 14:52:45 | INFO | Epoch 4 | Batch 600/764 | Loss: 0.0193
2026-01-28 14:52:57 | INFO | Epoch 4 | Batch 700/764 | Loss: 0.0179
2026-01-28 14:53:11 | INFO | Epoch 4 | Train Loss: 0.0183 | Val Loss: 0.0191
2026-01-28 14:53:11 | INFO | Val F1: 0.2263 | Prec: 0.4698 | Rec: 0.1490 | AUC: 0.7925
2026-01-28 14:53:11 | INFO | Epoch 5 | Batch 0/764 | Loss: 0.0113
2026-01-28 14:53:23 | INFO | Epoch 5 | Batch 100/764 | Loss: 0.0147
2026-01-28 14:53:35 | INFO | Epoch 5 | Batch 200/764 | Loss: 0.0175
2026-01-28 14:53:46 | INFO | Epoch 5 | Batch 300/764 | Loss: 0.0164
2026-01-28 14:53:59 | INFO | Epoch 5 | Batch 400/764 | Loss: 0.0206
2026-01-28 14:54:10 | INFO | Epoch 5 | Batch 500/764 | Loss: 0.0159
2026-01-28 14:54:23 | INFO | Epoch 5 | Batch 600/764 | Loss: 0.0150
2026-01-28 14:54:35 | INFO | Epoch 5 | Batch 700/764 | Loss: 0.0219
2026-01-28 14:55:02 | INFO | Epoch 5 | Train Loss: 0.0176 | Val Loss: 0.0191
2026-01-28 14:55:02 | INFO | Val F1: 0.2870 | Prec: 0.3591 | Rec: 0.2390 | AUC: 0.7882
2026-01-28 14:55:02 | INFO | New best model saved (F1: 0.2870)
2026-01-28 14:55:03 | INFO | Epoch 6 | Batch 0/764 | Loss: 0.0149
2026-01-28 14:55:34 | INFO | Epoch 6 | Batch 100/764 | Loss: 0.0210
2026-01-28 14:56:06 | INFO | Epoch 6 | Batch 200/764 | Loss: 0.0150
2026-01-28 14:56:37 | INFO | Epoch 6 | Batch 300/764 | Loss: 0.0176
2026-01-28 14:57:11 | INFO | Epoch 6 | Batch 400/764 | Loss: 0.0148
2026-01-28 14:57:46 | INFO | Epoch 6 | Batch 500/764 | Loss: 0.0164
2026-01-28 14:58:24 | INFO | Epoch 6 | Batch 600/764 | Loss: 0.0208
2026-01-28 14:59:00 | INFO | Epoch 6 | Batch 700/764 | Loss: 0.0162
2026-01-28 14:59:39 | INFO | Epoch 6 | Train Loss: 0.0166 | Val Loss: 0.0198
2026-01-28 14:59:39 | INFO | Val F1: 0.2754 | Prec: 0.4030 | Rec: 0.2091 | AUC: 0.7900
2026-01-28 14:59:39 | INFO | Epoch 7 | Batch 0/764 | Loss: 0.0103
2026-01-28 15:00:13 | INFO | Epoch 7 | Batch 100/764 | Loss: 0.0189
2026-01-28 15:00:45 | INFO | Epoch 7 | Batch 200/764 | Loss: 0.0138
2026-01-28 15:01:19 | INFO | Epoch 7 | Batch 300/764 | Loss: 0.0136
2026-01-28 15:01:53 | INFO | Epoch 7 | Batch 400/764 | Loss: 0.0122
2026-01-28 15:02:30 | INFO | Epoch 7 | Batch 500/764 | Loss: 0.0162
2026-01-28 15:03:19 | INFO | Epoch 7 | Batch 600/764 | Loss: 0.0126
2026-01-28 15:03:54 | INFO | Epoch 7 | Batch 700/764 | Loss: 0.0132
2026-01-28 15:04:32 | INFO | Epoch 7 | Train Loss: 0.0157 | Val Loss: 0.0198
2026-01-28 15:04:32 | INFO | Val F1: 0.2771 | Prec: 0.3362 | Rec: 0.2356 | AUC: 0.7886
2026-01-28 15:04:33 | INFO | Epoch 8 | Batch 0/764 | Loss: 0.0114
2026-01-28 15:05:12 | INFO | Epoch 8 | Batch 100/764 | Loss: 0.0146
2026-01-28 15:05:50 | INFO | Epoch 8 | Batch 200/764 | Loss: 0.0129
2026-01-28 15:06:33 | INFO | Epoch 8 | Batch 300/764 | Loss: 0.0157
2026-01-28 15:07:25 | INFO | Epoch 8 | Batch 400/764 | Loss: 0.0136
2026-01-28 15:08:09 | INFO | Epoch 8 | Batch 500/764 | Loss: 0.0123
2026-01-28 15:08:48 | INFO | Epoch 8 | Batch 600/764 | Loss: 0.0169
2026-01-28 15:09:13 | INFO | Epoch 8 | Batch 700/764 | Loss: 0.0108
2026-01-28 15:09:33 | INFO | Epoch 8 | Train Loss: 0.0147 | Val Loss: 0.0235
2026-01-28 15:09:33 | INFO | Val F1: 0.3042 | Prec: 0.3630 | Rec: 0.2618 | AUC: 0.7892
2026-01-28 15:09:33 | INFO | New best model saved (F1: 0.3042)
2026-01-28 15:09:33 | INFO | Epoch 9 | Batch 0/764 | Loss: 0.0129
2026-01-28 15:09:46 | INFO | Epoch 9 | Batch 100/764 | Loss: 0.0175
2026-01-28 15:10:01 | INFO | Epoch 9 | Batch 200/764 | Loss: 0.0090
2026-01-28 15:10:15 | INFO | Epoch 9 | Batch 300/764 | Loss: 0.0134
2026-01-28 15:10:29 | INFO | Epoch 9 | Batch 400/764 | Loss: 0.0131
2026-01-28 15:10:43 | INFO | Epoch 9 | Batch 500/764 | Loss: 0.0126
2026-01-28 15:10:57 | INFO | Epoch 9 | Batch 600/764 | Loss: 0.0139
2026-01-28 15:11:10 | INFO | Epoch 9 | Batch 700/764 | Loss: 0.0096
2026-01-28 15:11:26 | INFO | Epoch 9 | Train Loss: 0.0137 | Val Loss: 0.0234
2026-01-28 15:11:26 | INFO | Val F1: 0.2636 | Prec: 0.3516 | Rec: 0.2108 | AUC: 0.7941
2026-01-28 15:11:26 | INFO | Epoch 10 | Batch 0/764 | Loss: 0.0156
2026-01-28 15:11:38 | INFO | Epoch 10 | Batch 100/764 | Loss: 0.0119
2026-01-28 15:11:51 | INFO | Epoch 10 | Batch 200/764 | Loss: 0.0068
2026-01-28 15:12:03 | INFO | Epoch 10 | Batch 300/764 | Loss: 0.0122
2026-01-28 15:12:15 | INFO | Epoch 10 | Batch 400/764 | Loss: 0.0134
2026-01-28 15:12:28 | INFO | Epoch 10 | Batch 500/764 | Loss: 0.0167
2026-01-28 15:12:41 | INFO | Epoch 10 | Batch 600/764 | Loss: 0.0092
2026-01-28 15:12:53 | INFO | Epoch 10 | Batch 700/764 | Loss: 0.0083
2026-01-28 15:13:09 | INFO | Epoch 10 | Train Loss: 0.0118 | Val Loss: 0.0292
2026-01-28 15:13:09 | INFO | Val F1: 0.2727 | Prec: 0.3794 | Rec: 0.2128 | AUC: 0.7905
2026-01-28 15:13:09 | INFO | Epoch 11 | Batch 0/764 | Loss: 0.0111
2026-01-28 15:13:21 | INFO | Epoch 11 | Batch 100/764 | Loss: 0.0092
2026-01-28 15:13:34 | INFO | Epoch 11 | Batch 200/764 | Loss: 0.0068
2026-01-28 15:13:46 | INFO | Epoch 11 | Batch 300/764 | Loss: 0.0117
2026-01-28 15:14:00 | INFO | Epoch 11 | Batch 400/764 | Loss: 0.0120
2026-01-28 15:14:14 | INFO | Epoch 11 | Batch 500/764 | Loss: 0.0121
2026-01-28 15:14:26 | INFO | Epoch 11 | Batch 600/764 | Loss: 0.0104
2026-01-28 15:14:38 | INFO | Epoch 11 | Batch 700/764 | Loss: 0.0128
2026-01-28 15:14:52 | INFO | Epoch 11 | Train Loss: 0.0108 | Val Loss: 0.0347
2026-01-28 15:14:52 | INFO | Val F1: 0.2899 | Prec: 0.3643 | Rec: 0.2407 | AUC: 0.7861
2026-01-28 15:14:52 | INFO | Epoch 12 | Batch 0/764 | Loss: 0.0124
2026-01-28 15:15:04 | INFO | Epoch 12 | Batch 100/764 | Loss: 0.0091
2026-01-28 15:15:16 | INFO | Epoch 12 | Batch 200/764 | Loss: 0.0112
2026-01-28 15:15:27 | INFO | Epoch 12 | Batch 300/764 | Loss: 0.0116
2026-01-28 15:15:39 | INFO | Epoch 12 | Batch 400/764 | Loss: 0.0118
2026-01-28 15:15:50 | INFO | Epoch 12 | Batch 500/764 | Loss: 0.0076
2026-01-28 15:16:02 | INFO | Epoch 12 | Batch 600/764 | Loss: 0.0126
2026-01-28 15:16:14 | INFO | Epoch 12 | Batch 700/764 | Loss: 0.0124
2026-01-28 15:16:29 | INFO | Epoch 12 | Train Loss: 0.0101 | Val Loss: 0.0369
2026-01-28 15:16:29 | INFO | Val F1: 0.2864 | Prec: 0.3314 | Rec: 0.2521 | AUC: 0.7866
2026-01-28 15:16:29 | INFO | Epoch 13 | Batch 0/764 | Loss: 0.0080
2026-01-28 15:16:42 | INFO | Epoch 13 | Batch 100/764 | Loss: 0.0117
2026-01-28 15:16:55 | INFO | Epoch 13 | Batch 200/764 | Loss: 0.0111
2026-01-28 15:17:07 | INFO | Epoch 13 | Batch 300/764 | Loss: 0.0108
2026-01-28 15:17:19 | INFO | Epoch 13 | Batch 400/764 | Loss: 0.0106
2026-01-28 15:17:32 | INFO | Epoch 13 | Batch 500/764 | Loss: 0.0078
2026-01-28 15:17:44 | INFO | Epoch 13 | Batch 600/764 | Loss: 0.0107
2026-01-28 15:17:57 | INFO | Epoch 13 | Batch 700/764 | Loss: 0.0097
2026-01-28 15:18:12 | INFO | Epoch 13 | Train Loss: 0.0095 | Val Loss: 0.0391
2026-01-28 15:18:12 | INFO | Val F1: 0.2852 | Prec: 0.3243 | Rec: 0.2544 | AUC: 0.7821
2026-01-28 15:18:12 | INFO | Epoch 14 | Batch 0/764 | Loss: 0.0089
2026-01-28 15:18:25 | INFO | Epoch 14 | Batch 100/764 | Loss: 0.0107
2026-01-28 15:18:38 | INFO | Epoch 14 | Batch 200/764 | Loss: 0.0106
2026-01-28 15:18:51 | INFO | Epoch 14 | Batch 300/764 | Loss: 0.0118
2026-01-28 15:19:05 | INFO | Epoch 14 | Batch 400/764 | Loss: 0.0083
2026-01-28 15:19:17 | INFO | Epoch 14 | Batch 500/764 | Loss: 0.0099
2026-01-28 15:19:30 | INFO | Epoch 14 | Batch 600/764 | Loss: 0.0091
2026-01-28 15:19:43 | INFO | Epoch 14 | Batch 700/764 | Loss: 0.0127
2026-01-28 15:19:57 | INFO | Epoch 14 | Train Loss: 0.0089 | Val Loss: 0.0466
2026-01-28 15:19:57 | INFO | Val F1: 0.2825 | Prec: 0.3433 | Rec: 0.2400 | AUC: 0.7836
2026-01-28 15:19:57 | INFO | Epoch 15 | Batch 0/764 | Loss: 0.0090
2026-01-28 15:20:09 | INFO | Epoch 15 | Batch 100/764 | Loss: 0.0060
2026-01-28 15:20:22 | INFO | Epoch 15 | Batch 200/764 | Loss: 0.0061
2026-01-28 15:20:34 | INFO | Epoch 15 | Batch 300/764 | Loss: 0.0074
2026-01-28 15:20:47 | INFO | Epoch 15 | Batch 400/764 | Loss: 0.0080
2026-01-28 15:21:00 | INFO | Epoch 15 | Batch 500/764 | Loss: 0.0105
2026-01-28 15:21:12 | INFO | Epoch 15 | Batch 600/764 | Loss: 0.0071
2026-01-28 15:21:24 | INFO | Epoch 15 | Batch 700/764 | Loss: 0.0108
2026-01-28 15:21:39 | INFO | Epoch 15 | Train Loss: 0.0085 | Val Loss: 0.0494
2026-01-28 15:21:39 | INFO | Val F1: 0.2768 | Prec: 0.3181 | Rec: 0.2450 | AUC: 0.7812
2026-01-28 15:21:39 | INFO | Epoch 16 | Batch 0/764 | Loss: 0.0070
2026-01-28 15:21:52 | INFO | Epoch 16 | Batch 100/764 | Loss: 0.0066
2026-01-28 15:22:05 | INFO | Epoch 16 | Batch 200/764 | Loss: 0.0060
2026-01-28 15:22:19 | INFO | Epoch 16 | Batch 300/764 | Loss: 0.0094
2026-01-28 15:22:31 | INFO | Epoch 16 | Batch 400/764 | Loss: 0.0045
2026-01-28 15:22:44 | INFO | Epoch 16 | Batch 500/764 | Loss: 0.0087
2026-01-28 15:22:58 | INFO | Epoch 16 | Batch 600/764 | Loss: 0.0061
2026-01-28 15:23:10 | INFO | Epoch 16 | Batch 700/764 | Loss: 0.0108
2026-01-28 15:23:26 | INFO | Epoch 16 | Train Loss: 0.0075 | Val Loss: 0.0591
2026-01-28 15:23:26 | INFO | Val F1: 0.2901 | Prec: 0.3228 | Rec: 0.2635 | AUC: 0.7829
2026-01-28 15:23:26 | INFO | Epoch 17 | Batch 0/764 | Loss: 0.0064
2026-01-28 15:23:38 | INFO | Epoch 17 | Batch 100/764 | Loss: 0.0080
2026-01-28 15:23:51 | INFO | Epoch 17 | Batch 200/764 | Loss: 0.0071
2026-01-28 15:24:09 | INFO | Epoch 17 | Batch 300/764 | Loss: 0.0054
2026-01-28 15:24:28 | INFO | Epoch 17 | Batch 400/764 | Loss: 0.0079
2026-01-28 15:24:46 | INFO | Epoch 17 | Batch 500/764 | Loss: 0.0054
2026-01-28 15:25:05 | INFO | Epoch 17 | Batch 600/764 | Loss: 0.0053
2026-01-28 15:25:24 | INFO | Epoch 17 | Batch 700/764 | Loss: 0.0089
2026-01-28 15:25:45 | INFO | Epoch 17 | Train Loss: 0.0070 | Val Loss: 0.0628
2026-01-28 15:25:45 | INFO | Val F1: 0.2833 | Prec: 0.3268 | Rec: 0.2501 | AUC: 0.7782
2026-01-28 15:25:45 | INFO | Epoch 18 | Batch 0/764 | Loss: 0.0083
2026-01-28 15:26:04 | INFO | Epoch 18 | Batch 100/764 | Loss: 0.0052
2026-01-28 15:26:24 | INFO | Epoch 18 | Batch 200/764 | Loss: 0.0089
2026-01-28 15:26:43 | INFO | Epoch 18 | Batch 300/764 | Loss: 0.0056
2026-01-28 15:27:02 | INFO | Epoch 18 | Batch 400/764 | Loss: 0.0053
2026-01-28 15:27:21 | INFO | Epoch 18 | Batch 500/764 | Loss: 0.0069
2026-01-28 15:27:40 | INFO | Epoch 18 | Batch 600/764 | Loss: 0.0057
2026-01-28 15:27:59 | INFO | Epoch 18 | Batch 700/764 | Loss: 0.0069
2026-01-28 15:28:22 | INFO | Epoch 18 | Train Loss: 0.0067 | Val Loss: 0.0658
2026-01-28 15:28:22 | INFO | Val F1: 0.3003 | Prec: 0.3102 | Rec: 0.2910 | AUC: 0.7826
2026-01-28 15:28:22 | INFO | Early stopping at epoch 18
2026-01-28 15:28:37 | INFO | ==================================================
2026-01-28 15:28:37 | INFO | TEST RESULTS (Sequence LSTM)
2026-01-28 15:28:37 | INFO | ==================================================
2026-01-28 15:28:37 | INFO | F1: 0.2839
2026-01-28 15:28:37 | INFO | Precision: 0.3381
2026-01-28 15:28:37 | INFO | Recall: 0.2447
2026-01-28 15:28:37 | INFO | AUC: 0.7811
